{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8872dc2-1bd8-4314-9fa7-0b5179ac8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e4a741-79c3-4ed8-ab78-97fa0526e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./csv/dummyData-1.csv', header=None, names=['date', 'avail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c8ffcc-d7b7-46fd-8ffc-97b28edf20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10723/4147684296.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['date'] = pd.to_datetime(data['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "data = data.dropna(subset=['date'])\n",
    "\n",
    "# Sort the data by date\n",
    "data = data.sort_values('date')\n",
    "\n",
    "# Ensure 'avail' is numeric\n",
    "data['avail'] = pd.to_numeric(data['avail'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in 'avail'\n",
    "data = data.dropna(subset=['avail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c02824-233c-4246-9305-1b902c8257ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract additional time features\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day_of_year'] = data['date'].dt.dayofyear / 365.0\n",
    "data['year'] = data['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bbb524-e29f-40b1-9c02-0fc6b1ebf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 'avail' column\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['avail'] = scaler.fit_transform(data[['avail']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a38689-bf42-46ad-8267-bd8fb0b036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data.iloc[i:i + seq_length][['avail', 'day_of_year']].values\n",
    "        y = data.iloc[i + seq_length]['avail']\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "# Create sequences\n",
    "sequence_length = 7\n",
    "X, y = create_sequences(data, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7e92e3-64b1-48a6-bc02-c3bb7f09772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374ef805-5c1e-485e-a606-d8d7eda92670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvailabilityDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "dataset = AvailabilityDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cd17be-7838-419b-a114-fe338f568c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=50, output_size=1, num_layers=2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = RNNModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1d6aa4-14e2-4e41-a878-3c23e7f39ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.7449\n",
      "Epoch [20/1000], Loss: 0.8008\n",
      "Epoch [30/1000], Loss: 0.5528\n",
      "Epoch [40/1000], Loss: 0.5775\n",
      "Epoch [50/1000], Loss: 0.6151\n",
      "Epoch [60/1000], Loss: 0.6795\n",
      "Epoch [70/1000], Loss: 0.9092\n",
      "Epoch [80/1000], Loss: 0.2739\n",
      "Epoch [90/1000], Loss: 0.3890\n",
      "Epoch [100/1000], Loss: 0.4067\n",
      "Epoch [110/1000], Loss: 0.3237\n",
      "Epoch [120/1000], Loss: 0.9138\n",
      "Epoch [130/1000], Loss: 0.5318\n",
      "Epoch [140/1000], Loss: 0.6633\n",
      "Epoch [150/1000], Loss: 0.2747\n",
      "Epoch [160/1000], Loss: 0.5029\n",
      "Epoch [170/1000], Loss: 0.9228\n",
      "Epoch [180/1000], Loss: 0.4354\n",
      "Epoch [190/1000], Loss: 0.2662\n",
      "Epoch [200/1000], Loss: 0.4791\n",
      "Epoch [210/1000], Loss: 0.2734\n",
      "Epoch [220/1000], Loss: 0.2343\n",
      "Epoch [230/1000], Loss: 0.4636\n",
      "Epoch [240/1000], Loss: 0.1368\n",
      "Epoch [250/1000], Loss: 0.4953\n",
      "Epoch [260/1000], Loss: 0.2313\n",
      "Epoch [270/1000], Loss: 0.6863\n",
      "Epoch [280/1000], Loss: 0.3105\n",
      "Epoch [290/1000], Loss: 0.1796\n",
      "Epoch [300/1000], Loss: 0.2613\n",
      "Epoch [310/1000], Loss: 0.4442\n",
      "Epoch [320/1000], Loss: 0.2242\n",
      "Epoch [330/1000], Loss: 0.1155\n",
      "Epoch [340/1000], Loss: 0.1194\n",
      "Epoch [350/1000], Loss: 0.2874\n",
      "Epoch [360/1000], Loss: 0.3607\n",
      "Epoch [370/1000], Loss: 0.1783\n",
      "Epoch [380/1000], Loss: 0.3680\n",
      "Epoch [390/1000], Loss: 0.2071\n",
      "Epoch [400/1000], Loss: 0.2947\n",
      "Epoch [410/1000], Loss: 0.1493\n",
      "Epoch [420/1000], Loss: 0.3482\n",
      "Epoch [430/1000], Loss: 0.1874\n",
      "Epoch [440/1000], Loss: 0.4364\n",
      "Epoch [450/1000], Loss: 0.1958\n",
      "Epoch [460/1000], Loss: 0.2886\n",
      "Epoch [470/1000], Loss: 0.3262\n",
      "Epoch [480/1000], Loss: 0.1798\n",
      "Epoch [490/1000], Loss: 0.6716\n",
      "Epoch [500/1000], Loss: 0.1822\n",
      "Epoch [510/1000], Loss: 0.4176\n",
      "Epoch [520/1000], Loss: 0.2509\n",
      "Epoch [530/1000], Loss: 0.0184\n",
      "Epoch [540/1000], Loss: 0.1478\n",
      "Epoch [550/1000], Loss: 0.2851\n",
      "Epoch [560/1000], Loss: 0.0874\n",
      "Epoch [570/1000], Loss: 0.3039\n",
      "Epoch [580/1000], Loss: 0.2266\n",
      "Epoch [590/1000], Loss: 0.0541\n",
      "Epoch [600/1000], Loss: 0.0897\n",
      "Epoch [610/1000], Loss: 0.1057\n",
      "Epoch [620/1000], Loss: 0.3971\n",
      "Epoch [630/1000], Loss: 0.0967\n",
      "Epoch [640/1000], Loss: 0.1365\n",
      "Epoch [650/1000], Loss: 0.2856\n",
      "Epoch [660/1000], Loss: 0.2038\n",
      "Epoch [670/1000], Loss: 0.2162\n",
      "Epoch [680/1000], Loss: 0.3499\n",
      "Epoch [690/1000], Loss: 0.4164\n",
      "Epoch [700/1000], Loss: 0.2126\n",
      "Epoch [710/1000], Loss: 0.3603\n",
      "Epoch [720/1000], Loss: 0.4682\n",
      "Epoch [730/1000], Loss: 0.0732\n",
      "Epoch [740/1000], Loss: 0.1779\n",
      "Epoch [750/1000], Loss: 0.3023\n",
      "Epoch [760/1000], Loss: 0.3921\n",
      "Epoch [770/1000], Loss: 0.2602\n",
      "Epoch [780/1000], Loss: 0.1715\n",
      "Epoch [790/1000], Loss: 0.2399\n",
      "Epoch [800/1000], Loss: 0.1222\n",
      "Epoch [810/1000], Loss: 0.6085\n",
      "Epoch [820/1000], Loss: 0.3378\n",
      "Epoch [830/1000], Loss: 0.6527\n",
      "Epoch [840/1000], Loss: 0.1592\n",
      "Epoch [850/1000], Loss: 0.2591\n",
      "Epoch [860/1000], Loss: 0.0421\n",
      "Epoch [870/1000], Loss: 0.3057\n",
      "Epoch [880/1000], Loss: 0.2015\n",
      "Epoch [890/1000], Loss: 0.2685\n",
      "Epoch [900/1000], Loss: 0.4287\n",
      "Epoch [910/1000], Loss: 0.0979\n",
      "Epoch [920/1000], Loss: 0.1329\n",
      "Epoch [930/1000], Loss: 0.1509\n",
      "Epoch [940/1000], Loss: 0.1525\n",
      "Epoch [950/1000], Loss: 0.1020\n",
      "Epoch [960/1000], Loss: 0.0275\n",
      "Epoch [970/1000], Loss: 0.0119\n",
      "Epoch [980/1000], Loss: 0.1425\n",
      "Epoch [990/1000], Loss: 0.2837\n",
      "Epoch [1000/1000], Loss: 0.1649\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        # print(outputs.squeeze())\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6865a7e9-0cce-495a-90f1-d50496fbacd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.98356164]\n",
      " [1.         0.98630137]\n",
      " [0.         0.9890411 ]\n",
      " [1.         0.99178082]\n",
      " [0.         0.99452055]\n",
      " [0.         0.99726027]\n",
      " [0.         1.        ]]\n",
      "Predicted availability for the next day: 0\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        prediction = model(X)\n",
    "        return prediction.item()\n",
    "\n",
    "# Example usage\n",
    "last_sequence = data.iloc[-sequence_length:][['avail', 'day_of_year']].values\n",
    "next_day_avail = predict(model, last_sequence.reshape(1, sequence_length, 2))\n",
    "print(last_sequence)\n",
    "print(f'Predicted availability for the next day: {round(next_day_avail)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9131884-6627-4736-8b89-7c21e99b02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = np.array([334,335,336,337,338,339,340]) / 365.0\n",
    "avail = np.array([0,1,0,1,0,1,0])\n",
    "last_sequence= np.vstack(( avail,last_day)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01de0b53-76c2-4379-9f25-9e964ddad20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.91506849]\n",
      " [1.         0.91780822]\n",
      " [0.         0.92054795]\n",
      " [1.         0.92328767]\n",
      " [0.         0.9260274 ]\n",
      " [1.         0.92876712]\n",
      " [0.         0.93150685]]\n"
     ]
    }
   ],
   "source": [
    "print(last_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ee75142-1c24-445d-b7d1-00dc158bf4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.91506849]\n",
      " [1.         0.91780822]\n",
      " [0.         0.92054795]\n",
      " [1.         0.92328767]\n",
      " [0.         0.9260274 ]\n",
      " [1.         0.92876712]\n",
      " [0.         0.93150685]]\n",
      "Predicted availability for the next day: 1\n"
     ]
    }
   ],
   "source": [
    "next_day_avail = predict(model, last_sequence.reshape(1, sequence_length, 2))\n",
    "print(last_sequence)\n",
    "print(f'Predicted availability for the next day: {round(next_day_avail)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e9ae2c0-765f-4e76-9e6b-c0c47da0a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"./model/RNNmodelDummySet-1-Loss_%16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806926d1-fe98-4425-a0bd-126f2a329fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
