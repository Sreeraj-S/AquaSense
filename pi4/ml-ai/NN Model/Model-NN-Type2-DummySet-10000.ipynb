{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cdca49-29ba-4787-9a03-f336a52d04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914e140a-7122-4d55-909b-88ad88f0f17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acee9fcf-2f26-4048-9c19-63a731e7bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dummyDataTopBottom0-10000.csv\",header = None)\n",
    "x=data.iloc[1:,1:5].astype('float32')\n",
    "y=data.iloc[1:,-1].astype('float32')\n",
    "x.iloc[:, 2] = x.iloc[:, 2] / 100\n",
    "x.iloc[:, 3] = x.iloc[:, 3] / 100\n",
    "y = y/max(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0698a6-34b6-4e5c-8ab6-0421c8a483cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        0.266667\n",
       "2        0.400000\n",
       "3        0.000000\n",
       "4        0.066667\n",
       "5        0.000000\n",
       "           ...   \n",
       "9996     0.000000\n",
       "9997     0.433333\n",
       "9998     0.533333\n",
       "9999     0.000000\n",
       "10000    0.966667\n",
       "Name: 5, Length: 10000, dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f1eeb6-6aa8-4a79-aa7b-08d93ef67df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterLevelDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x= torch.tensor(x,dtype=torch.float32)\n",
    "        y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "\n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.Y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c52ff6-e488-4a62-9a26-90b04e65a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaterLevelDataset(x.values,y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd20883d-4498-471e-bc0a-06945c1b6f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba89f5a9-8ce4-481a-b711-74578a1b6260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000, 0.9300, 0.3500],\n",
       "        [0.0000, 0.0000, 0.6000, 0.6300],\n",
       "        [0.0000, 1.0000, 0.2500, 0.3800],\n",
       "        ...,\n",
       "        [1.0000, 0.0000, 0.6700, 0.3200],\n",
       "        [1.0000, 0.0000, 0.0900, 0.9800],\n",
       "        [1.0000, 1.0000, 0.8000, 0.5400]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42caba1f-ac2f-40e5-8edc-3fb19eabed4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2667, 0.4000, 0.0000,  ..., 0.5333, 0.0000, 0.9667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e76441-4d81-4a5b-b2e0-613a136c1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(dataset, [int(len(dataset.X)*0.8),int(len(dataset.X)*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410066c6-b6a4-45ea-bcb9-22cf28ee244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741cfaa-4da6-413a-a69c-a38b83367392",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "- Dataset used here is a dummy data with if top level more then 70 then predition should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a6b1345-27dc-4087-87d7-f62c311e6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer = nn.Linear(4, 10)\n",
    "        self.layer2 = nn.Linear(10,1)\n",
    "        self.activation = nn.Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = torch.relu(self.layer(X))\n",
    "        X=self.layer2(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57e7749-e3cb-40e7-8845-f8133d0a00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3d6145-5f80-4351-9107-ae7ae7b9a17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 19.477706\n",
      "Epoch [2/250], Loss: 13.862148\n",
      "Epoch [3/250], Loss: 17.388648\n",
      "Epoch [4/250], Loss: 12.003325\n",
      "Epoch [5/250], Loss: 12.196782\n",
      "Epoch [6/250], Loss: 12.286762\n",
      "Epoch [7/250], Loss: 16.467601\n",
      "Epoch [8/250], Loss: 12.261640\n",
      "Epoch [9/250], Loss: 11.316510\n",
      "Epoch [10/250], Loss: 13.320109\n",
      "Epoch [11/250], Loss: 17.149219\n",
      "Epoch [12/250], Loss: 14.453503\n",
      "Epoch [13/250], Loss: 14.138693\n",
      "Epoch [14/250], Loss: 15.120921\n",
      "Epoch [15/250], Loss: 11.885679\n",
      "Epoch [16/250], Loss: 11.011324\n",
      "Epoch [17/250], Loss: 7.039240\n",
      "Epoch [18/250], Loss: 11.376508\n",
      "Epoch [19/250], Loss: 13.041957\n",
      "Epoch [20/250], Loss: 12.630534\n",
      "Epoch [21/250], Loss: 7.422644\n",
      "Epoch [22/250], Loss: 7.256553\n",
      "Epoch [23/250], Loss: 7.395019\n",
      "Epoch [24/250], Loss: 8.070824\n",
      "Epoch [25/250], Loss: 13.555643\n",
      "Epoch [26/250], Loss: 10.801074\n",
      "Epoch [27/250], Loss: 9.296586\n",
      "Epoch [28/250], Loss: 10.221875\n",
      "Epoch [29/250], Loss: 12.186247\n",
      "Epoch [30/250], Loss: 7.641509\n",
      "Epoch [31/250], Loss: 12.914790\n",
      "Epoch [32/250], Loss: 12.840353\n",
      "Epoch [33/250], Loss: 11.389945\n",
      "Epoch [34/250], Loss: 7.750640\n",
      "Epoch [35/250], Loss: 7.464917\n",
      "Epoch [36/250], Loss: 10.409341\n",
      "Epoch [37/250], Loss: 7.847796\n",
      "Epoch [38/250], Loss: 14.346635\n",
      "Epoch [39/250], Loss: 8.902259\n",
      "Epoch [40/250], Loss: 7.271411\n",
      "Epoch [41/250], Loss: 10.613866\n",
      "Epoch [42/250], Loss: 8.580738\n",
      "Epoch [43/250], Loss: 14.568582\n",
      "Epoch [44/250], Loss: 8.965289\n",
      "Epoch [45/250], Loss: 10.261068\n",
      "Epoch [46/250], Loss: 10.176205\n",
      "Epoch [47/250], Loss: 8.305387\n",
      "Epoch [48/250], Loss: 20.104009\n",
      "Epoch [49/250], Loss: 9.507084\n",
      "Epoch [50/250], Loss: 13.680793\n",
      "Epoch [51/250], Loss: 13.895760\n",
      "Epoch [52/250], Loss: 6.614307\n",
      "Epoch [53/250], Loss: 10.548504\n",
      "Epoch [54/250], Loss: 12.821154\n",
      "Epoch [55/250], Loss: 13.784464\n",
      "Epoch [56/250], Loss: 11.040826\n",
      "Epoch [57/250], Loss: 8.838096\n",
      "Epoch [58/250], Loss: 10.193823\n",
      "Epoch [59/250], Loss: 11.767983\n",
      "Epoch [60/250], Loss: 4.095167\n",
      "Epoch [61/250], Loss: 6.793919\n",
      "Epoch [62/250], Loss: 8.142215\n",
      "Epoch [63/250], Loss: 9.599845\n",
      "Epoch [64/250], Loss: 4.120771\n",
      "Epoch [65/250], Loss: 7.361740\n",
      "Epoch [66/250], Loss: 9.962404\n",
      "Epoch [67/250], Loss: 13.099183\n",
      "Epoch [68/250], Loss: 7.854096\n",
      "Epoch [69/250], Loss: 11.557347\n",
      "Epoch [70/250], Loss: 11.710776\n",
      "Epoch [71/250], Loss: 7.869320\n",
      "Epoch [72/250], Loss: 10.812569\n",
      "Epoch [73/250], Loss: 6.236702\n",
      "Epoch [74/250], Loss: 7.169534\n",
      "Epoch [75/250], Loss: 9.769601\n",
      "Epoch [76/250], Loss: 12.801972\n",
      "Epoch [77/250], Loss: 8.069799\n",
      "Epoch [78/250], Loss: 4.880011\n",
      "Epoch [79/250], Loss: 8.841128\n",
      "Epoch [80/250], Loss: 9.456012\n",
      "Epoch [81/250], Loss: 10.620032\n",
      "Epoch [82/250], Loss: 5.519486\n",
      "Epoch [83/250], Loss: 9.310162\n",
      "Epoch [84/250], Loss: 13.573980\n",
      "Epoch [85/250], Loss: 10.226507\n",
      "Epoch [86/250], Loss: 18.636402\n",
      "Epoch [87/250], Loss: 8.701583\n",
      "Epoch [88/250], Loss: 9.006301\n",
      "Epoch [89/250], Loss: 4.055037\n",
      "Epoch [90/250], Loss: 9.247750\n",
      "Epoch [91/250], Loss: 9.236110\n",
      "Epoch [92/250], Loss: 9.251466\n",
      "Epoch [93/250], Loss: 10.983759\n",
      "Epoch [94/250], Loss: 7.511815\n",
      "Epoch [95/250], Loss: 11.306769\n",
      "Epoch [96/250], Loss: 9.473872\n",
      "Epoch [97/250], Loss: 17.001863\n",
      "Epoch [98/250], Loss: 6.775308\n",
      "Epoch [99/250], Loss: 11.700147\n",
      "Epoch [100/250], Loss: 7.255363\n",
      "Epoch [101/250], Loss: 7.873914\n",
      "Epoch [102/250], Loss: 11.144409\n",
      "Epoch [103/250], Loss: 12.070227\n",
      "Epoch [104/250], Loss: 6.170500\n",
      "Epoch [105/250], Loss: 10.978950\n",
      "Epoch [106/250], Loss: 10.904065\n",
      "Epoch [107/250], Loss: 6.192373\n",
      "Epoch [108/250], Loss: 5.797147\n",
      "Epoch [109/250], Loss: 13.449748\n",
      "Epoch [110/250], Loss: 8.671565\n",
      "Epoch [111/250], Loss: 8.375306\n",
      "Epoch [112/250], Loss: 13.048744\n",
      "Epoch [113/250], Loss: 6.455649\n",
      "Epoch [114/250], Loss: 9.823805\n",
      "Epoch [115/250], Loss: 8.777914\n",
      "Epoch [116/250], Loss: 10.727867\n",
      "Epoch [117/250], Loss: 5.426504\n",
      "Epoch [118/250], Loss: 4.012342\n",
      "Epoch [119/250], Loss: 5.354252\n",
      "Epoch [120/250], Loss: 9.803704\n",
      "Epoch [121/250], Loss: 8.964384\n",
      "Epoch [122/250], Loss: 8.534257\n",
      "Epoch [123/250], Loss: 15.595390\n",
      "Epoch [124/250], Loss: 7.006513\n",
      "Epoch [125/250], Loss: 16.406861\n",
      "Epoch [126/250], Loss: 9.190492\n",
      "Epoch [127/250], Loss: 10.529689\n",
      "Epoch [128/250], Loss: 10.386532\n",
      "Epoch [129/250], Loss: 5.896770\n",
      "Epoch [130/250], Loss: 8.266826\n",
      "Epoch [131/250], Loss: 12.205353\n",
      "Epoch [132/250], Loss: 7.693490\n",
      "Epoch [133/250], Loss: 6.521749\n",
      "Epoch [134/250], Loss: 12.224911\n",
      "Epoch [135/250], Loss: 3.893725\n",
      "Epoch [136/250], Loss: 10.408332\n",
      "Epoch [137/250], Loss: 11.013105\n",
      "Epoch [138/250], Loss: 14.192021\n",
      "Epoch [139/250], Loss: 6.138108\n",
      "Epoch [140/250], Loss: 9.843636\n",
      "Epoch [141/250], Loss: 4.776872\n",
      "Epoch [142/250], Loss: 8.258972\n",
      "Epoch [143/250], Loss: 7.484666\n",
      "Epoch [144/250], Loss: 12.487670\n",
      "Epoch [145/250], Loss: 6.525205\n",
      "Epoch [146/250], Loss: 11.447605\n",
      "Epoch [147/250], Loss: 8.756894\n",
      "Epoch [148/250], Loss: 8.147806\n",
      "Epoch [149/250], Loss: 10.653651\n",
      "Epoch [150/250], Loss: 10.257648\n",
      "Epoch [151/250], Loss: 6.155435\n",
      "Epoch [152/250], Loss: 8.655326\n",
      "Epoch [153/250], Loss: 5.591892\n",
      "Epoch [154/250], Loss: 4.826869\n",
      "Epoch [155/250], Loss: 5.128689\n",
      "Epoch [156/250], Loss: 7.959017\n",
      "Epoch [157/250], Loss: 12.732241\n",
      "Epoch [158/250], Loss: 9.185651\n",
      "Epoch [159/250], Loss: 8.351246\n",
      "Epoch [160/250], Loss: 9.674526\n",
      "Epoch [161/250], Loss: 5.569124\n",
      "Epoch [162/250], Loss: 4.854719\n",
      "Epoch [163/250], Loss: 4.906198\n",
      "Epoch [164/250], Loss: 13.136610\n",
      "Epoch [165/250], Loss: 11.138330\n",
      "Epoch [166/250], Loss: 14.788492\n",
      "Epoch [167/250], Loss: 8.831894\n",
      "Epoch [168/250], Loss: 5.480441\n",
      "Epoch [169/250], Loss: 10.478577\n",
      "Epoch [170/250], Loss: 7.572191\n",
      "Epoch [171/250], Loss: 14.863116\n",
      "Epoch [172/250], Loss: 11.016576\n",
      "Epoch [173/250], Loss: 6.413937\n",
      "Epoch [174/250], Loss: 15.251386\n",
      "Epoch [175/250], Loss: 6.579383\n",
      "Epoch [176/250], Loss: 12.627816\n",
      "Epoch [177/250], Loss: 11.678444\n",
      "Epoch [178/250], Loss: 7.854138\n",
      "Epoch [179/250], Loss: 9.321286\n",
      "Epoch [180/250], Loss: 7.239172\n",
      "Epoch [181/250], Loss: 8.759827\n",
      "Epoch [182/250], Loss: 9.980404\n",
      "Epoch [183/250], Loss: 4.300067\n",
      "Epoch [184/250], Loss: 10.264603\n",
      "Epoch [185/250], Loss: 11.989288\n",
      "Epoch [186/250], Loss: 9.185468\n",
      "Epoch [187/250], Loss: 7.137036\n",
      "Epoch [188/250], Loss: 5.669859\n",
      "Epoch [189/250], Loss: 7.238495\n",
      "Epoch [190/250], Loss: 8.944601\n",
      "Epoch [191/250], Loss: 7.862051\n",
      "Epoch [192/250], Loss: 6.899211\n",
      "Epoch [193/250], Loss: 6.860421\n",
      "Epoch [194/250], Loss: 12.203927\n",
      "Epoch [195/250], Loss: 9.356371\n",
      "Epoch [196/250], Loss: 8.374683\n",
      "Epoch [197/250], Loss: 5.155056\n",
      "Epoch [198/250], Loss: 14.868103\n",
      "Epoch [199/250], Loss: 7.353111\n",
      "Epoch [200/250], Loss: 3.976382\n",
      "Epoch [201/250], Loss: 11.045986\n",
      "Epoch [202/250], Loss: 7.374013\n",
      "Epoch [203/250], Loss: 9.403897\n",
      "Epoch [204/250], Loss: 4.997065\n",
      "Epoch [205/250], Loss: 5.215940\n",
      "Epoch [206/250], Loss: 12.224942\n",
      "Epoch [207/250], Loss: 13.286550\n",
      "Epoch [208/250], Loss: 7.016167\n",
      "Epoch [209/250], Loss: 13.325410\n",
      "Epoch [210/250], Loss: 3.501714\n",
      "Epoch [211/250], Loss: 6.189032\n",
      "Epoch [212/250], Loss: 12.980440\n",
      "Epoch [213/250], Loss: 8.531399\n",
      "Epoch [214/250], Loss: 7.952988\n",
      "Epoch [215/250], Loss: 7.597724\n",
      "Epoch [216/250], Loss: 13.232626\n",
      "Epoch [217/250], Loss: 11.723351\n",
      "Epoch [218/250], Loss: 6.225511\n",
      "Epoch [219/250], Loss: 7.120511\n",
      "Epoch [220/250], Loss: 6.590474\n",
      "Epoch [221/250], Loss: 4.208222\n",
      "Epoch [222/250], Loss: 8.569479\n",
      "Epoch [223/250], Loss: 7.624018\n",
      "Epoch [224/250], Loss: 8.493973\n",
      "Epoch [225/250], Loss: 8.843721\n",
      "Epoch [226/250], Loss: 10.121883\n",
      "Epoch [227/250], Loss: 13.263042\n",
      "Epoch [228/250], Loss: 8.142068\n",
      "Epoch [229/250], Loss: 5.396606\n",
      "Epoch [230/250], Loss: 6.782929\n",
      "Epoch [231/250], Loss: 10.994761\n",
      "Epoch [232/250], Loss: 3.472739\n",
      "Epoch [233/250], Loss: 9.227633\n",
      "Epoch [234/250], Loss: 5.568234\n",
      "Epoch [235/250], Loss: 8.907668\n",
      "Epoch [236/250], Loss: 8.740386\n",
      "Epoch [237/250], Loss: 8.140528\n",
      "Epoch [238/250], Loss: 10.981710\n",
      "Epoch [239/250], Loss: 13.939887\n",
      "Epoch [240/250], Loss: 7.957652\n",
      "Epoch [241/250], Loss: 12.086341\n",
      "Epoch [242/250], Loss: 5.213222\n",
      "Epoch [243/250], Loss: 4.429049\n",
      "Epoch [244/250], Loss: 11.978958\n",
      "Epoch [245/250], Loss: 8.511646\n",
      "Epoch [246/250], Loss: 4.654160\n",
      "Epoch [247/250], Loss: 4.878994\n",
      "Epoch [248/250], Loss: 4.008606\n",
      "Epoch [249/250], Loss: 8.429095\n",
      "Epoch [250/250], Loss: 6.810462\n",
      "Epoch [251/250], Loss: 11.950430\n",
      "Epoch [252/250], Loss: 5.150554\n",
      "Epoch [253/250], Loss: 5.377095\n",
      "Epoch [254/250], Loss: 9.602024\n",
      "Epoch [255/250], Loss: 8.408026\n",
      "Epoch [256/250], Loss: 9.708390\n",
      "Epoch [257/250], Loss: 5.517287\n",
      "Epoch [258/250], Loss: 8.657555\n",
      "Epoch [259/250], Loss: 7.497728\n",
      "Epoch [260/250], Loss: 7.367821\n",
      "Epoch [261/250], Loss: 6.463099\n",
      "Epoch [262/250], Loss: 6.468438\n",
      "Epoch [263/250], Loss: 5.120508\n",
      "Epoch [264/250], Loss: 8.704942\n",
      "Epoch [265/250], Loss: 4.447926\n",
      "Epoch [266/250], Loss: 12.489047\n",
      "Epoch [267/250], Loss: 5.607012\n",
      "Epoch [268/250], Loss: 5.425440\n",
      "Epoch [269/250], Loss: 5.051087\n",
      "Epoch [270/250], Loss: 4.516959\n",
      "Epoch [271/250], Loss: 7.056483\n",
      "Epoch [272/250], Loss: 10.292685\n",
      "Epoch [273/250], Loss: 7.354890\n",
      "Epoch [274/250], Loss: 14.529152\n",
      "Epoch [275/250], Loss: 3.049478\n",
      "Epoch [276/250], Loss: 8.760386\n",
      "Epoch [277/250], Loss: 7.028677\n",
      "Epoch [278/250], Loss: 13.625413\n",
      "Epoch [279/250], Loss: 12.595466\n",
      "Epoch [280/250], Loss: 7.095416\n",
      "Epoch [281/250], Loss: 11.071311\n",
      "Epoch [282/250], Loss: 5.798161\n",
      "Epoch [283/250], Loss: 4.307359\n",
      "Epoch [284/250], Loss: 9.359854\n",
      "Epoch [285/250], Loss: 6.339289\n",
      "Epoch [286/250], Loss: 7.781988\n",
      "Epoch [287/250], Loss: 10.199142\n",
      "Epoch [288/250], Loss: 5.065317\n",
      "Epoch [289/250], Loss: 5.476043\n",
      "Epoch [290/250], Loss: 10.739352\n",
      "Epoch [291/250], Loss: 6.606735\n",
      "Epoch [292/250], Loss: 3.389841\n",
      "Epoch [293/250], Loss: 4.870395\n",
      "Epoch [294/250], Loss: 16.994843\n",
      "Epoch [295/250], Loss: 8.298140\n",
      "Epoch [296/250], Loss: 5.322837\n",
      "Epoch [297/250], Loss: 6.676170\n",
      "Epoch [298/250], Loss: 9.860323\n",
      "Epoch [299/250], Loss: 5.475198\n",
      "Epoch [300/250], Loss: 10.055432\n",
      "Epoch [301/250], Loss: 11.047240\n",
      "Epoch [302/250], Loss: 5.986596\n",
      "Epoch [303/250], Loss: 2.773412\n",
      "Epoch [304/250], Loss: 11.342080\n",
      "Epoch [305/250], Loss: 5.609236\n",
      "Epoch [306/250], Loss: 8.470064\n",
      "Epoch [307/250], Loss: 6.121144\n",
      "Epoch [308/250], Loss: 4.996677\n",
      "Epoch [309/250], Loss: 7.501856\n",
      "Epoch [310/250], Loss: 8.210037\n",
      "Epoch [311/250], Loss: 10.657757\n",
      "Epoch [312/250], Loss: 10.640165\n",
      "Epoch [313/250], Loss: 9.492707\n",
      "Epoch [314/250], Loss: 7.773362\n",
      "Epoch [315/250], Loss: 10.066148\n",
      "Epoch [316/250], Loss: 5.192431\n",
      "Epoch [317/250], Loss: 8.649031\n",
      "Epoch [318/250], Loss: 11.408637\n",
      "Epoch [319/250], Loss: 9.754561\n",
      "Epoch [320/250], Loss: 4.786336\n",
      "Epoch [321/250], Loss: 7.814579\n",
      "Epoch [322/250], Loss: 9.035973\n",
      "Epoch [323/250], Loss: 9.176719\n",
      "Epoch [324/250], Loss: 5.590344\n",
      "Epoch [325/250], Loss: 11.521399\n",
      "Epoch [326/250], Loss: 4.788646\n",
      "Epoch [327/250], Loss: 9.113403\n",
      "Epoch [328/250], Loss: 10.929278\n",
      "Epoch [329/250], Loss: 3.702692\n",
      "Epoch [330/250], Loss: 2.594919\n",
      "Epoch [331/250], Loss: 8.267498\n",
      "Epoch [332/250], Loss: 10.054267\n",
      "Epoch [333/250], Loss: 5.523318\n",
      "Epoch [334/250], Loss: 9.254926\n",
      "Epoch [335/250], Loss: 9.926013\n",
      "Epoch [336/250], Loss: 5.469115\n",
      "Epoch [337/250], Loss: 6.751353\n",
      "Epoch [338/250], Loss: 7.140494\n",
      "Epoch [339/250], Loss: 6.960345\n",
      "Epoch [340/250], Loss: 7.401431\n",
      "Epoch [341/250], Loss: 6.025790\n",
      "Epoch [342/250], Loss: 3.763337\n",
      "Epoch [343/250], Loss: 6.226621\n",
      "Epoch [344/250], Loss: 7.142086\n",
      "Epoch [345/250], Loss: 6.228650\n",
      "Epoch [346/250], Loss: 2.794744\n",
      "Epoch [347/250], Loss: 5.481859\n",
      "Epoch [348/250], Loss: 8.708393\n",
      "Epoch [349/250], Loss: 6.450137\n",
      "Epoch [350/250], Loss: 4.813403\n",
      "Epoch [351/250], Loss: 12.974760\n",
      "Epoch [352/250], Loss: 7.485744\n",
      "Epoch [353/250], Loss: 7.190768\n",
      "Epoch [354/250], Loss: 8.678518\n",
      "Epoch [355/250], Loss: 5.797755\n",
      "Epoch [356/250], Loss: 4.862328\n",
      "Epoch [357/250], Loss: 4.937299\n",
      "Epoch [358/250], Loss: 8.059927\n",
      "Epoch [359/250], Loss: 7.830075\n",
      "Epoch [360/250], Loss: 11.601218\n",
      "Epoch [361/250], Loss: 6.659620\n",
      "Epoch [362/250], Loss: 7.235429\n",
      "Epoch [363/250], Loss: 9.510335\n",
      "Epoch [364/250], Loss: 8.009443\n",
      "Epoch [365/250], Loss: 6.415953\n",
      "Epoch [366/250], Loss: 8.489000\n",
      "Epoch [367/250], Loss: 10.866462\n",
      "Epoch [368/250], Loss: 6.091794\n",
      "Epoch [369/250], Loss: 3.191302\n",
      "Epoch [370/250], Loss: 8.521039\n",
      "Epoch [371/250], Loss: 12.659366\n",
      "Epoch [372/250], Loss: 8.326168\n",
      "Epoch [373/250], Loss: 14.120260\n",
      "Epoch [374/250], Loss: 5.981192\n",
      "Epoch [375/250], Loss: 6.406838\n",
      "Epoch [376/250], Loss: 9.133342\n",
      "Epoch [377/250], Loss: 7.857814\n",
      "Epoch [378/250], Loss: 7.317131\n",
      "Epoch [379/250], Loss: 5.901793\n",
      "Epoch [380/250], Loss: 6.624788\n",
      "Epoch [381/250], Loss: 5.240148\n",
      "Epoch [382/250], Loss: 7.979679\n",
      "Epoch [383/250], Loss: 6.576628\n",
      "Epoch [384/250], Loss: 5.871000\n",
      "Epoch [385/250], Loss: 8.961836\n",
      "Epoch [386/250], Loss: 7.722611\n",
      "Epoch [387/250], Loss: 9.186763\n",
      "Epoch [388/250], Loss: 3.686231\n",
      "Epoch [389/250], Loss: 3.155999\n",
      "Epoch [390/250], Loss: 6.371294\n",
      "Epoch [391/250], Loss: 6.693786\n",
      "Epoch [392/250], Loss: 6.190505\n",
      "Epoch [393/250], Loss: 11.303646\n",
      "Epoch [394/250], Loss: 5.894164\n",
      "Epoch [395/250], Loss: 4.687237\n",
      "Epoch [396/250], Loss: 10.587703\n",
      "Epoch [397/250], Loss: 7.394913\n",
      "Epoch [398/250], Loss: 11.459602\n",
      "Epoch [399/250], Loss: 4.696721\n",
      "Epoch [400/250], Loss: 5.975228\n",
      "Epoch [401/250], Loss: 2.266000\n",
      "Epoch [402/250], Loss: 8.649687\n",
      "Epoch [403/250], Loss: 7.298317\n",
      "Epoch [404/250], Loss: 8.321433\n",
      "Epoch [405/250], Loss: 8.546062\n",
      "Epoch [406/250], Loss: 7.591473\n",
      "Epoch [407/250], Loss: 5.457317\n",
      "Epoch [408/250], Loss: 6.368800\n",
      "Epoch [409/250], Loss: 7.387158\n",
      "Epoch [410/250], Loss: 8.672268\n",
      "Epoch [411/250], Loss: 8.278226\n",
      "Epoch [412/250], Loss: 2.478852\n",
      "Epoch [413/250], Loss: 7.768694\n",
      "Epoch [414/250], Loss: 4.116575\n",
      "Epoch [415/250], Loss: 4.134303\n",
      "Epoch [416/250], Loss: 6.001980\n",
      "Epoch [417/250], Loss: 7.357792\n",
      "Epoch [418/250], Loss: 9.251227\n",
      "Epoch [419/250], Loss: 4.016340\n",
      "Epoch [420/250], Loss: 4.033607\n",
      "Epoch [421/250], Loss: 10.965998\n",
      "Epoch [422/250], Loss: 7.033385\n",
      "Epoch [423/250], Loss: 5.061037\n",
      "Epoch [424/250], Loss: 3.687611\n",
      "Epoch [425/250], Loss: 9.978518\n",
      "Epoch [426/250], Loss: 6.320765\n",
      "Epoch [427/250], Loss: 6.627040\n",
      "Epoch [428/250], Loss: 8.668668\n",
      "Epoch [429/250], Loss: 7.902294\n",
      "Epoch [430/250], Loss: 5.507974\n",
      "Epoch [431/250], Loss: 5.839631\n",
      "Epoch [432/250], Loss: 2.886131\n",
      "Epoch [433/250], Loss: 2.603294\n",
      "Epoch [434/250], Loss: 6.848513\n",
      "Epoch [435/250], Loss: 8.243699\n",
      "Epoch [436/250], Loss: 9.965539\n",
      "Epoch [437/250], Loss: 7.748281\n",
      "Epoch [438/250], Loss: 6.368842\n",
      "Epoch [439/250], Loss: 3.360483\n",
      "Epoch [440/250], Loss: 5.015940\n",
      "Epoch [441/250], Loss: 3.342807\n",
      "Epoch [442/250], Loss: 11.215619\n",
      "Epoch [443/250], Loss: 2.935247\n",
      "Epoch [444/250], Loss: 4.179162\n",
      "Epoch [445/250], Loss: 3.349133\n",
      "Epoch [446/250], Loss: 6.908902\n",
      "Epoch [447/250], Loss: 6.993333\n",
      "Epoch [448/250], Loss: 6.600980\n",
      "Epoch [449/250], Loss: 3.787143\n",
      "Epoch [450/250], Loss: 9.090149\n",
      "Epoch [451/250], Loss: 9.653034\n",
      "Epoch [452/250], Loss: 3.130513\n",
      "Epoch [453/250], Loss: 1.858929\n",
      "Epoch [454/250], Loss: 3.429938\n",
      "Epoch [455/250], Loss: 7.207331\n",
      "Epoch [456/250], Loss: 9.610739\n",
      "Epoch [457/250], Loss: 3.662247\n",
      "Epoch [458/250], Loss: 5.569995\n",
      "Epoch [459/250], Loss: 6.944937\n",
      "Epoch [460/250], Loss: 9.331177\n",
      "Epoch [461/250], Loss: 9.341581\n",
      "Epoch [462/250], Loss: 9.516704\n",
      "Epoch [463/250], Loss: 6.106195\n",
      "Epoch [464/250], Loss: 5.012154\n",
      "Epoch [465/250], Loss: 7.445692\n",
      "Epoch [466/250], Loss: 4.120389\n",
      "Epoch [467/250], Loss: 9.353316\n",
      "Epoch [468/250], Loss: 13.780636\n",
      "Epoch [469/250], Loss: 2.803968\n",
      "Epoch [470/250], Loss: 6.610309\n",
      "Epoch [471/250], Loss: 10.232280\n",
      "Epoch [472/250], Loss: 6.028793\n",
      "Epoch [473/250], Loss: 6.236680\n",
      "Epoch [474/250], Loss: 15.015468\n",
      "Epoch [475/250], Loss: 5.221459\n",
      "Epoch [476/250], Loss: 10.809932\n",
      "Epoch [477/250], Loss: 9.889024\n",
      "Epoch [478/250], Loss: 9.539440\n",
      "Epoch [479/250], Loss: 8.709399\n",
      "Epoch [480/250], Loss: 4.747735\n",
      "Epoch [481/250], Loss: 9.521469\n",
      "Epoch [482/250], Loss: 8.993599\n",
      "Epoch [483/250], Loss: 7.936374\n",
      "Epoch [484/250], Loss: 8.525157\n",
      "Epoch [485/250], Loss: 5.949768\n",
      "Epoch [486/250], Loss: 5.244893\n",
      "Epoch [487/250], Loss: 5.461361\n",
      "Epoch [488/250], Loss: 7.474730\n",
      "Epoch [489/250], Loss: 12.437262\n",
      "Epoch [490/250], Loss: 13.385056\n",
      "Epoch [491/250], Loss: 6.964621\n",
      "Epoch [492/250], Loss: 8.878149\n",
      "Epoch [493/250], Loss: 6.853134\n",
      "Epoch [494/250], Loss: 11.621695\n",
      "Epoch [495/250], Loss: 12.802386\n",
      "Epoch [496/250], Loss: 5.558904\n",
      "Epoch [497/250], Loss: 4.921010\n",
      "Epoch [498/250], Loss: 7.664192\n",
      "Epoch [499/250], Loss: 9.325927\n",
      "Epoch [500/250], Loss: 5.995860\n",
      "Epoch [501/250], Loss: 13.384545\n",
      "Epoch [502/250], Loss: 5.203223\n",
      "Epoch [503/250], Loss: 5.544170\n",
      "Epoch [504/250], Loss: 6.282584\n",
      "Epoch [505/250], Loss: 5.013409\n",
      "Epoch [506/250], Loss: 6.810726\n",
      "Epoch [507/250], Loss: 10.171559\n",
      "Epoch [508/250], Loss: 9.276146\n",
      "Epoch [509/250], Loss: 7.550602\n",
      "Epoch [510/250], Loss: 7.344850\n",
      "Epoch [511/250], Loss: 5.352686\n",
      "Epoch [512/250], Loss: 4.879327\n",
      "Epoch [513/250], Loss: 13.665839\n",
      "Epoch [514/250], Loss: 9.901496\n",
      "Epoch [515/250], Loss: 7.636470\n",
      "Epoch [516/250], Loss: 6.638001\n",
      "Epoch [517/250], Loss: 7.028160\n",
      "Epoch [518/250], Loss: 6.293126\n",
      "Epoch [519/250], Loss: 7.133949\n",
      "Epoch [520/250], Loss: 7.617886\n",
      "Epoch [521/250], Loss: 9.593621\n",
      "Epoch [522/250], Loss: 6.972769\n",
      "Epoch [523/250], Loss: 5.807809\n",
      "Epoch [524/250], Loss: 14.238712\n",
      "Epoch [525/250], Loss: 5.075833\n",
      "Epoch [526/250], Loss: 6.158313\n",
      "Epoch [527/250], Loss: 7.145844\n",
      "Epoch [528/250], Loss: 6.545976\n",
      "Epoch [529/250], Loss: 9.181033\n",
      "Epoch [530/250], Loss: 2.601408\n",
      "Epoch [531/250], Loss: 6.507844\n",
      "Epoch [532/250], Loss: 4.424609\n",
      "Epoch [533/250], Loss: 4.512406\n",
      "Epoch [534/250], Loss: 6.263480\n",
      "Epoch [535/250], Loss: 6.366873\n",
      "Epoch [536/250], Loss: 16.666390\n",
      "Epoch [537/250], Loss: 8.039448\n",
      "Epoch [538/250], Loss: 7.264826\n",
      "Epoch [539/250], Loss: 6.977985\n",
      "Epoch [540/250], Loss: 4.645505\n",
      "Epoch [541/250], Loss: 3.978564\n",
      "Epoch [542/250], Loss: 8.771285\n",
      "Epoch [543/250], Loss: 11.770722\n",
      "Epoch [544/250], Loss: 3.894709\n",
      "Epoch [545/250], Loss: 6.576357\n",
      "Epoch [546/250], Loss: 4.308699\n",
      "Epoch [547/250], Loss: 8.590094\n",
      "Epoch [548/250], Loss: 8.785964\n",
      "Epoch [549/250], Loss: 6.387667\n",
      "Epoch [550/250], Loss: 8.589743\n",
      "Epoch [551/250], Loss: 9.876695\n",
      "Epoch [552/250], Loss: 7.640987\n",
      "Epoch [553/250], Loss: 10.354896\n",
      "Epoch [554/250], Loss: 7.242522\n",
      "Epoch [555/250], Loss: 10.543091\n",
      "Epoch [556/250], Loss: 4.079949\n",
      "Epoch [557/250], Loss: 6.819328\n",
      "Epoch [558/250], Loss: 5.413499\n",
      "Epoch [559/250], Loss: 4.642946\n",
      "Epoch [560/250], Loss: 5.670084\n",
      "Epoch [561/250], Loss: 4.951479\n",
      "Epoch [562/250], Loss: 4.465261\n",
      "Epoch [563/250], Loss: 3.079927\n",
      "Epoch [564/250], Loss: 5.657519\n",
      "Epoch [565/250], Loss: 4.610860\n",
      "Epoch [566/250], Loss: 4.177069\n",
      "Epoch [567/250], Loss: 4.621785\n",
      "Epoch [568/250], Loss: 7.275522\n",
      "Epoch [569/250], Loss: 9.252730\n",
      "Epoch [570/250], Loss: 10.566968\n",
      "Epoch [571/250], Loss: 6.763504\n",
      "Epoch [572/250], Loss: 4.734364\n",
      "Epoch [573/250], Loss: 6.394438\n",
      "Epoch [574/250], Loss: 6.765215\n",
      "Epoch [575/250], Loss: 4.758073\n",
      "Epoch [576/250], Loss: 1.548659\n",
      "Epoch [577/250], Loss: 6.699602\n",
      "Epoch [578/250], Loss: 7.228360\n",
      "Epoch [579/250], Loss: 7.715620\n",
      "Epoch [580/250], Loss: 6.238707\n",
      "Epoch [581/250], Loss: 4.963124\n",
      "Epoch [582/250], Loss: 2.331468\n",
      "Epoch [583/250], Loss: 4.863637\n",
      "Epoch [584/250], Loss: 9.361836\n",
      "Epoch [585/250], Loss: 2.785888\n",
      "Epoch [586/250], Loss: 5.241012\n",
      "Epoch [587/250], Loss: 8.421922\n",
      "Epoch [588/250], Loss: 2.716428\n",
      "Epoch [589/250], Loss: 6.982644\n",
      "Epoch [590/250], Loss: 3.895589\n",
      "Epoch [591/250], Loss: 8.960691\n",
      "Epoch [592/250], Loss: 9.452561\n",
      "Epoch [593/250], Loss: 9.774811\n",
      "Epoch [594/250], Loss: 10.021335\n",
      "Epoch [595/250], Loss: 7.214065\n",
      "Epoch [596/250], Loss: 14.299810\n",
      "Epoch [597/250], Loss: 2.843104\n",
      "Epoch [598/250], Loss: 1.897602\n",
      "Epoch [599/250], Loss: 3.857596\n",
      "Epoch [600/250], Loss: 10.689809\n",
      "Epoch [601/250], Loss: 6.820454\n",
      "Epoch [602/250], Loss: 12.845428\n",
      "Epoch [603/250], Loss: 7.924749\n",
      "Epoch [604/250], Loss: 5.795988\n",
      "Epoch [605/250], Loss: 4.673871\n",
      "Epoch [606/250], Loss: 4.566157\n",
      "Epoch [607/250], Loss: 4.633071\n",
      "Epoch [608/250], Loss: 9.487612\n",
      "Epoch [609/250], Loss: 10.372461\n",
      "Epoch [610/250], Loss: 6.468153\n",
      "Epoch [611/250], Loss: 9.637839\n",
      "Epoch [612/250], Loss: 14.670946\n",
      "Epoch [613/250], Loss: 6.664167\n",
      "Epoch [614/250], Loss: 8.054399\n",
      "Epoch [615/250], Loss: 7.126092\n",
      "Epoch [616/250], Loss: 7.203520\n",
      "Epoch [617/250], Loss: 7.533090\n",
      "Epoch [618/250], Loss: 6.885610\n",
      "Epoch [619/250], Loss: 4.641384\n",
      "Epoch [620/250], Loss: 3.409343\n",
      "Epoch [621/250], Loss: 6.808870\n",
      "Epoch [622/250], Loss: 5.498264\n",
      "Epoch [623/250], Loss: 11.526215\n",
      "Epoch [624/250], Loss: 8.202390\n",
      "Epoch [625/250], Loss: 3.716660\n",
      "Epoch [626/250], Loss: 3.080885\n",
      "Epoch [627/250], Loss: 7.561923\n",
      "Epoch [628/250], Loss: 7.765737\n",
      "Epoch [629/250], Loss: 3.480495\n",
      "Epoch [630/250], Loss: 12.081666\n",
      "Epoch [631/250], Loss: 7.824237\n",
      "Epoch [632/250], Loss: 6.685075\n",
      "Epoch [633/250], Loss: 3.588447\n",
      "Epoch [634/250], Loss: 4.342904\n",
      "Epoch [635/250], Loss: 8.248638\n",
      "Epoch [636/250], Loss: 3.141864\n",
      "Epoch [637/250], Loss: 6.978729\n",
      "Epoch [638/250], Loss: 10.761873\n",
      "Epoch [639/250], Loss: 5.075158\n",
      "Epoch [640/250], Loss: 6.496066\n",
      "Epoch [641/250], Loss: 4.981669\n",
      "Epoch [642/250], Loss: 10.238675\n",
      "Epoch [643/250], Loss: 5.082589\n",
      "Epoch [644/250], Loss: 8.717563\n",
      "Epoch [645/250], Loss: 7.598656\n",
      "Epoch [646/250], Loss: 6.837378\n",
      "Epoch [647/250], Loss: 8.612715\n",
      "Epoch [648/250], Loss: 4.414766\n",
      "Epoch [649/250], Loss: 6.500243\n",
      "Epoch [650/250], Loss: 9.420875\n",
      "Epoch [651/250], Loss: 9.788565\n",
      "Epoch [652/250], Loss: 9.834900\n",
      "Epoch [653/250], Loss: 9.145961\n",
      "Epoch [654/250], Loss: 5.915175\n",
      "Epoch [655/250], Loss: 4.214999\n",
      "Epoch [656/250], Loss: 13.834882\n",
      "Epoch [657/250], Loss: 4.482596\n",
      "Epoch [658/250], Loss: 13.017067\n",
      "Epoch [659/250], Loss: 7.408346\n",
      "Epoch [660/250], Loss: 10.007358\n",
      "Epoch [661/250], Loss: 6.895112\n",
      "Epoch [662/250], Loss: 6.439697\n",
      "Epoch [663/250], Loss: 7.385002\n",
      "Epoch [664/250], Loss: 14.612046\n",
      "Epoch [665/250], Loss: 10.298823\n",
      "Epoch [666/250], Loss: 4.303078\n",
      "Epoch [667/250], Loss: 7.774357\n",
      "Epoch [668/250], Loss: 4.936673\n",
      "Epoch [669/250], Loss: 9.441533\n",
      "Epoch [670/250], Loss: 7.397554\n",
      "Epoch [671/250], Loss: 5.384882\n",
      "Epoch [672/250], Loss: 8.192625\n",
      "Epoch [673/250], Loss: 8.034969\n",
      "Epoch [674/250], Loss: 8.944766\n",
      "Epoch [675/250], Loss: 7.937061\n",
      "Epoch [676/250], Loss: 7.408019\n",
      "Epoch [677/250], Loss: 9.257787\n",
      "Epoch [678/250], Loss: 3.529825\n",
      "Epoch [679/250], Loss: 7.501451\n",
      "Epoch [680/250], Loss: 10.999162\n",
      "Epoch [681/250], Loss: 6.407512\n",
      "Epoch [682/250], Loss: 4.446325\n",
      "Epoch [683/250], Loss: 6.379087\n",
      "Epoch [684/250], Loss: 4.182002\n",
      "Epoch [685/250], Loss: 4.280588\n",
      "Epoch [686/250], Loss: 2.826529\n",
      "Epoch [687/250], Loss: 7.189528\n",
      "Epoch [688/250], Loss: 8.027884\n",
      "Epoch [689/250], Loss: 6.312498\n",
      "Epoch [690/250], Loss: 12.048393\n",
      "Epoch [691/250], Loss: 2.930275\n",
      "Epoch [692/250], Loss: 8.444013\n",
      "Epoch [693/250], Loss: 5.323777\n",
      "Epoch [694/250], Loss: 7.238033\n",
      "Epoch [695/250], Loss: 7.795794\n",
      "Epoch [696/250], Loss: 9.676518\n",
      "Epoch [697/250], Loss: 5.988573\n",
      "Epoch [698/250], Loss: 2.642883\n",
      "Epoch [699/250], Loss: 7.857098\n",
      "Epoch [700/250], Loss: 4.925457\n",
      "Epoch [701/250], Loss: 6.693756\n",
      "Epoch [702/250], Loss: 4.973323\n",
      "Epoch [703/250], Loss: 5.266150\n",
      "Epoch [704/250], Loss: 3.705587\n",
      "Epoch [705/250], Loss: 4.083457\n",
      "Epoch [706/250], Loss: 6.107104\n",
      "Epoch [707/250], Loss: 7.187001\n",
      "Epoch [708/250], Loss: 7.443866\n",
      "Epoch [709/250], Loss: 5.924588\n",
      "Epoch [710/250], Loss: 7.744891\n",
      "Epoch [711/250], Loss: 6.136556\n",
      "Epoch [712/250], Loss: 3.929517\n",
      "Epoch [713/250], Loss: 9.362812\n",
      "Epoch [714/250], Loss: 6.529614\n",
      "Epoch [715/250], Loss: 3.111112\n",
      "Epoch [716/250], Loss: 3.685586\n",
      "Epoch [717/250], Loss: 13.948397\n",
      "Epoch [718/250], Loss: 7.912290\n",
      "Epoch [719/250], Loss: 5.576401\n",
      "Epoch [720/250], Loss: 9.152755\n",
      "Epoch [721/250], Loss: 7.964577\n",
      "Epoch [722/250], Loss: 5.021802\n",
      "Epoch [723/250], Loss: 5.274954\n",
      "Epoch [724/250], Loss: 9.534597\n",
      "Epoch [725/250], Loss: 8.343346\n",
      "Epoch [726/250], Loss: 11.487774\n",
      "Epoch [727/250], Loss: 11.109856\n",
      "Epoch [728/250], Loss: 6.821493\n",
      "Epoch [729/250], Loss: 6.781200\n",
      "Epoch [730/250], Loss: 8.127822\n",
      "Epoch [731/250], Loss: 12.080391\n",
      "Epoch [732/250], Loss: 9.363918\n",
      "Epoch [733/250], Loss: 5.768944\n",
      "Epoch [734/250], Loss: 5.136994\n",
      "Epoch [735/250], Loss: 7.701151\n",
      "Epoch [736/250], Loss: 11.916424\n",
      "Epoch [737/250], Loss: 3.235981\n",
      "Epoch [738/250], Loss: 4.839703\n",
      "Epoch [739/250], Loss: 11.497975\n",
      "Epoch [740/250], Loss: 10.088348\n",
      "Epoch [741/250], Loss: 6.747228\n",
      "Epoch [742/250], Loss: 6.376039\n",
      "Epoch [743/250], Loss: 5.310733\n",
      "Epoch [744/250], Loss: 7.833385\n",
      "Epoch [745/250], Loss: 3.222791\n",
      "Epoch [746/250], Loss: 3.571932\n",
      "Epoch [747/250], Loss: 5.989321\n",
      "Epoch [748/250], Loss: 10.781951\n",
      "Epoch [749/250], Loss: 7.979365\n",
      "Epoch [750/250], Loss: 7.031979\n",
      "Epoch [751/250], Loss: 12.988903\n",
      "Epoch [752/250], Loss: 9.397094\n",
      "Epoch [753/250], Loss: 7.852437\n",
      "Epoch [754/250], Loss: 8.906696\n",
      "Epoch [755/250], Loss: 6.348329\n",
      "Epoch [756/250], Loss: 12.078416\n",
      "Epoch [757/250], Loss: 4.433131\n",
      "Epoch [758/250], Loss: 5.869831\n",
      "Epoch [759/250], Loss: 4.747033\n",
      "Epoch [760/250], Loss: 3.861960\n",
      "Epoch [761/250], Loss: 7.133080\n",
      "Epoch [762/250], Loss: 6.333152\n",
      "Epoch [763/250], Loss: 7.461499\n",
      "Epoch [764/250], Loss: 8.112494\n",
      "Epoch [765/250], Loss: 4.739808\n",
      "Epoch [766/250], Loss: 10.448095\n",
      "Epoch [767/250], Loss: 5.284022\n",
      "Epoch [768/250], Loss: 13.030797\n",
      "Epoch [769/250], Loss: 4.038730\n",
      "Epoch [770/250], Loss: 9.229681\n",
      "Epoch [771/250], Loss: 8.162559\n",
      "Epoch [772/250], Loss: 5.104831\n",
      "Epoch [773/250], Loss: 7.342383\n",
      "Epoch [774/250], Loss: 7.232600\n",
      "Epoch [775/250], Loss: 8.347018\n",
      "Epoch [776/250], Loss: 9.270913\n",
      "Epoch [777/250], Loss: 10.743935\n",
      "Epoch [778/250], Loss: 6.022923\n",
      "Epoch [779/250], Loss: 6.530204\n",
      "Epoch [780/250], Loss: 7.682645\n",
      "Epoch [781/250], Loss: 7.858967\n",
      "Epoch [782/250], Loss: 12.908758\n",
      "Epoch [783/250], Loss: 7.715806\n",
      "Epoch [784/250], Loss: 9.277134\n",
      "Epoch [785/250], Loss: 5.974802\n",
      "Epoch [786/250], Loss: 3.237324\n",
      "Epoch [787/250], Loss: 6.363416\n",
      "Epoch [788/250], Loss: 5.701277\n",
      "Epoch [789/250], Loss: 7.548577\n",
      "Epoch [790/250], Loss: 9.979148\n",
      "Epoch [791/250], Loss: 3.622432\n",
      "Epoch [792/250], Loss: 7.426260\n",
      "Epoch [793/250], Loss: 4.707070\n",
      "Epoch [794/250], Loss: 6.717696\n",
      "Epoch [795/250], Loss: 8.348910\n",
      "Epoch [796/250], Loss: 4.214600\n",
      "Epoch [797/250], Loss: 7.756182\n",
      "Epoch [798/250], Loss: 6.220101\n",
      "Epoch [799/250], Loss: 11.103696\n",
      "Epoch [800/250], Loss: 11.539532\n",
      "Epoch [801/250], Loss: 6.823236\n",
      "Epoch [802/250], Loss: 7.785618\n",
      "Epoch [803/250], Loss: 3.871981\n",
      "Epoch [804/250], Loss: 5.763113\n",
      "Epoch [805/250], Loss: 1.938353\n",
      "Epoch [806/250], Loss: 12.141015\n",
      "Epoch [807/250], Loss: 11.879533\n",
      "Epoch [808/250], Loss: 3.408578\n",
      "Epoch [809/250], Loss: 10.397507\n",
      "Epoch [810/250], Loss: 4.063287\n",
      "Epoch [811/250], Loss: 7.237262\n",
      "Epoch [812/250], Loss: 4.765584\n",
      "Epoch [813/250], Loss: 6.031813\n",
      "Epoch [814/250], Loss: 7.560758\n",
      "Epoch [815/250], Loss: 9.626658\n",
      "Epoch [816/250], Loss: 6.830151\n",
      "Epoch [817/250], Loss: 5.804345\n",
      "Epoch [818/250], Loss: 3.875750\n",
      "Epoch [819/250], Loss: 5.088334\n",
      "Epoch [820/250], Loss: 6.751428\n",
      "Epoch [821/250], Loss: 4.165400\n",
      "Epoch [822/250], Loss: 7.395077\n",
      "Epoch [823/250], Loss: 3.068031\n",
      "Epoch [824/250], Loss: 4.840542\n",
      "Epoch [825/250], Loss: 2.282622\n",
      "Epoch [826/250], Loss: 2.786541\n",
      "Epoch [827/250], Loss: 5.623328\n",
      "Epoch [828/250], Loss: 7.649528\n",
      "Epoch [829/250], Loss: 6.549865\n",
      "Epoch [830/250], Loss: 6.803062\n",
      "Epoch [831/250], Loss: 6.939765\n",
      "Epoch [832/250], Loss: 4.662386\n",
      "Epoch [833/250], Loss: 3.535770\n",
      "Epoch [834/250], Loss: 7.228346\n",
      "Epoch [835/250], Loss: 6.533944\n",
      "Epoch [836/250], Loss: 7.607890\n",
      "Epoch [837/250], Loss: 3.575255\n",
      "Epoch [838/250], Loss: 5.166959\n",
      "Epoch [839/250], Loss: 8.580969\n",
      "Epoch [840/250], Loss: 7.087487\n",
      "Epoch [841/250], Loss: 7.678361\n",
      "Epoch [842/250], Loss: 6.646064\n",
      "Epoch [843/250], Loss: 13.231240\n",
      "Epoch [844/250], Loss: 6.527612\n",
      "Epoch [845/250], Loss: 7.669606\n",
      "Epoch [846/250], Loss: 4.723527\n",
      "Epoch [847/250], Loss: 12.543976\n",
      "Epoch [848/250], Loss: 5.622641\n",
      "Epoch [849/250], Loss: 7.297906\n",
      "Epoch [850/250], Loss: 11.398447\n",
      "Epoch [851/250], Loss: 8.030155\n",
      "Epoch [852/250], Loss: 7.033797\n",
      "Epoch [853/250], Loss: 2.312858\n",
      "Epoch [854/250], Loss: 5.108663\n",
      "Epoch [855/250], Loss: 10.033984\n",
      "Epoch [856/250], Loss: 4.576394\n",
      "Epoch [857/250], Loss: 6.159075\n",
      "Epoch [858/250], Loss: 5.225791\n",
      "Epoch [859/250], Loss: 3.267841\n",
      "Epoch [860/250], Loss: 6.506867\n",
      "Epoch [861/250], Loss: 14.624433\n",
      "Epoch [862/250], Loss: 7.889505\n",
      "Epoch [863/250], Loss: 8.711517\n",
      "Epoch [864/250], Loss: 17.046116\n",
      "Epoch [865/250], Loss: 5.264246\n",
      "Epoch [866/250], Loss: 9.693640\n",
      "Epoch [867/250], Loss: 5.109238\n",
      "Epoch [868/250], Loss: 9.552307\n",
      "Epoch [869/250], Loss: 4.390302\n",
      "Epoch [870/250], Loss: 10.349274\n",
      "Epoch [871/250], Loss: 2.120267\n",
      "Epoch [872/250], Loss: 6.204503\n",
      "Epoch [873/250], Loss: 4.369985\n",
      "Epoch [874/250], Loss: 10.448527\n",
      "Epoch [875/250], Loss: 8.191051\n",
      "Epoch [876/250], Loss: 6.879668\n",
      "Epoch [877/250], Loss: 9.127744\n",
      "Epoch [878/250], Loss: 4.573550\n",
      "Epoch [879/250], Loss: 3.164630\n",
      "Epoch [880/250], Loss: 3.836295\n",
      "Epoch [881/250], Loss: 5.562958\n",
      "Epoch [882/250], Loss: 5.876188\n",
      "Epoch [883/250], Loss: 5.154447\n",
      "Epoch [884/250], Loss: 2.047498\n",
      "Epoch [885/250], Loss: 8.150110\n",
      "Epoch [886/250], Loss: 4.840544\n",
      "Epoch [887/250], Loss: 5.608712\n",
      "Epoch [888/250], Loss: 6.307150\n",
      "Epoch [889/250], Loss: 11.761747\n",
      "Epoch [890/250], Loss: 4.914032\n",
      "Epoch [891/250], Loss: 9.174298\n",
      "Epoch [892/250], Loss: 11.552256\n",
      "Epoch [893/250], Loss: 6.700825\n",
      "Epoch [894/250], Loss: 4.243286\n",
      "Epoch [895/250], Loss: 4.333818\n",
      "Epoch [896/250], Loss: 7.327386\n",
      "Epoch [897/250], Loss: 6.202030\n",
      "Epoch [898/250], Loss: 5.317245\n",
      "Epoch [899/250], Loss: 5.729270\n",
      "Epoch [900/250], Loss: 7.435881\n",
      "Epoch [901/250], Loss: 4.574115\n",
      "Epoch [902/250], Loss: 2.421598\n",
      "Epoch [903/250], Loss: 3.422073\n",
      "Epoch [904/250], Loss: 7.345620\n",
      "Epoch [905/250], Loss: 4.704681\n",
      "Epoch [906/250], Loss: 3.869554\n",
      "Epoch [907/250], Loss: 5.794350\n",
      "Epoch [908/250], Loss: 9.895040\n",
      "Epoch [909/250], Loss: 13.118808\n",
      "Epoch [910/250], Loss: 7.498764\n",
      "Epoch [911/250], Loss: 7.344899\n",
      "Epoch [912/250], Loss: 12.481362\n",
      "Epoch [913/250], Loss: 2.721359\n",
      "Epoch [914/250], Loss: 10.577247\n",
      "Epoch [915/250], Loss: 4.635662\n",
      "Epoch [916/250], Loss: 11.916170\n",
      "Epoch [917/250], Loss: 4.814963\n",
      "Epoch [918/250], Loss: 6.676245\n",
      "Epoch [919/250], Loss: 5.005603\n",
      "Epoch [920/250], Loss: 2.061339\n",
      "Epoch [921/250], Loss: 7.249243\n",
      "Epoch [922/250], Loss: 8.981180\n",
      "Epoch [923/250], Loss: 8.124812\n",
      "Epoch [924/250], Loss: 5.920302\n",
      "Epoch [925/250], Loss: 10.595211\n",
      "Epoch [926/250], Loss: 6.826054\n",
      "Epoch [927/250], Loss: 5.707914\n",
      "Epoch [928/250], Loss: 4.091385\n",
      "Epoch [929/250], Loss: 9.543454\n",
      "Epoch [930/250], Loss: 3.856186\n",
      "Epoch [931/250], Loss: 3.627164\n",
      "Epoch [932/250], Loss: 8.753425\n",
      "Epoch [933/250], Loss: 5.202051\n",
      "Epoch [934/250], Loss: 5.189168\n",
      "Epoch [935/250], Loss: 6.987392\n",
      "Epoch [936/250], Loss: 11.573494\n",
      "Epoch [937/250], Loss: 9.244686\n",
      "Epoch [938/250], Loss: 2.592836\n",
      "Epoch [939/250], Loss: 12.957713\n",
      "Epoch [940/250], Loss: 6.175263\n",
      "Epoch [941/250], Loss: 4.893764\n",
      "Epoch [942/250], Loss: 6.527786\n",
      "Epoch [943/250], Loss: 7.896598\n",
      "Epoch [944/250], Loss: 3.437089\n",
      "Epoch [945/250], Loss: 8.745928\n",
      "Epoch [946/250], Loss: 6.450187\n",
      "Epoch [947/250], Loss: 13.106379\n",
      "Epoch [948/250], Loss: 5.535732\n",
      "Epoch [949/250], Loss: 8.335366\n",
      "Epoch [950/250], Loss: 1.813287\n",
      "Epoch [951/250], Loss: 5.265234\n",
      "Epoch [952/250], Loss: 6.501766\n",
      "Epoch [953/250], Loss: 8.842885\n",
      "Epoch [954/250], Loss: 3.887720\n",
      "Epoch [955/250], Loss: 6.193148\n",
      "Epoch [956/250], Loss: 3.981174\n",
      "Epoch [957/250], Loss: 9.569556\n",
      "Epoch [958/250], Loss: 7.108181\n",
      "Epoch [959/250], Loss: 6.792342\n",
      "Epoch [960/250], Loss: 4.850174\n",
      "Epoch [961/250], Loss: 8.907920\n",
      "Epoch [962/250], Loss: 5.470424\n",
      "Epoch [963/250], Loss: 4.078690\n",
      "Epoch [964/250], Loss: 11.405841\n",
      "Epoch [965/250], Loss: 3.267298\n",
      "Epoch [966/250], Loss: 6.467711\n",
      "Epoch [967/250], Loss: 11.978517\n",
      "Epoch [968/250], Loss: 8.220952\n",
      "Epoch [969/250], Loss: 13.120662\n",
      "Epoch [970/250], Loss: 9.164362\n",
      "Epoch [971/250], Loss: 2.553555\n",
      "Epoch [972/250], Loss: 9.805071\n",
      "Epoch [973/250], Loss: 9.486882\n",
      "Epoch [974/250], Loss: 2.878757\n",
      "Epoch [975/250], Loss: 6.892197\n",
      "Epoch [976/250], Loss: 11.323655\n",
      "Epoch [977/250], Loss: 4.305713\n",
      "Epoch [978/250], Loss: 6.747588\n",
      "Epoch [979/250], Loss: 7.927138\n",
      "Epoch [980/250], Loss: 7.660528\n",
      "Epoch [981/250], Loss: 7.997552\n",
      "Epoch [982/250], Loss: 9.604408\n",
      "Epoch [983/250], Loss: 5.745696\n",
      "Epoch [984/250], Loss: 3.904862\n",
      "Epoch [985/250], Loss: 9.503330\n",
      "Epoch [986/250], Loss: 9.538241\n",
      "Epoch [987/250], Loss: 4.429882\n",
      "Epoch [988/250], Loss: 7.559586\n",
      "Epoch [989/250], Loss: 4.092158\n",
      "Epoch [990/250], Loss: 12.832031\n",
      "Epoch [991/250], Loss: 2.630488\n",
      "Epoch [992/250], Loss: 5.144365\n",
      "Epoch [993/250], Loss: 7.576177\n",
      "Epoch [994/250], Loss: 5.968159\n",
      "Epoch [995/250], Loss: 4.564802\n",
      "Epoch [996/250], Loss: 6.472044\n",
      "Epoch [997/250], Loss: 8.994871\n",
      "Epoch [998/250], Loss: 4.570687\n",
      "Epoch [999/250], Loss: 3.170900\n",
      "Epoch [1000/250], Loss: 10.327095\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):  # Number of epochs\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), targets.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/1000], Loss: {loss.item()*100:0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c90326-eb80-4253-8947-1eb58be63856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 11.17, Actual: 2.00\n",
      "Predicted: 3.62, Actual: 0.00\n",
      "Predicted: 12.37, Actual: 16.00\n",
      "Predicted: 2.35, Actual: 0.00\n",
      "Predicted: 3.16, Actual: 0.00\n",
      "Predicted: 7.46, Actual: 0.00\n",
      "Predicted: 19.04, Actual: 13.00\n",
      "Predicted: 3.75, Actual: 0.00\n",
      "Predicted: 11.82, Actual: 4.00\n",
      "Predicted: 11.81, Actual: 8.00\n",
      "Predicted: 3.33, Actual: 0.00\n",
      "Predicted: 16.44, Actual: 17.00\n",
      "Predicted: 4.04, Actual: 0.00\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "Predicted: 7.64, Actual: 0.00\n",
      "Predicted: 4.80, Actual: 0.00\n",
      "Average loss on the testing dataset: 2.9191\n",
      "Predicted: 10.00, Actual: 18.00\n",
      "Predicted: 4.00, Actual: 0.00\n",
      "Predicted: 4.80, Actual: 26.00\n",
      "Predicted: 1.44, Actual: 0.00\n",
      "Predicted: 7.54, Actual: 14.00\n",
      "Predicted: 1.34, Actual: 0.00\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "Predicted: 0.47, Actual: 0.00\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "Predicted: 2.41, Actual: 0.00\n",
      "Predicted: 1.02, Actual: 0.00\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "Predicted: 11.46, Actual: 23.00\n",
      "Predicted: 6.46, Actual: 19.00\n",
      "Predicted: 5.39, Actual: 5.00\n",
      "Predicted: 2.93, Actual: 0.00\n",
      "Average loss on the testing dataset: 4.5926\n",
      "Predicted: 7.13, Actual: 23.00\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "Predicted: 1.66, Actual: 0.00\n",
      "Predicted: 15.34, Actual: 0.00\n",
      "Predicted: 3.54, Actual: 0.00\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "Predicted: 3.11, Actual: 0.00\n",
      "Predicted: 7.32, Actual: 30.00\n",
      "Predicted: 8.93, Actual: 0.00\n",
      "Predicted: 15.35, Actual: 7.00\n",
      "Predicted: 1.40, Actual: 0.00\n",
      "Predicted: 4.70, Actual: 0.00\n",
      "Predicted: 4.28, Actual: 19.00\n",
      "Predicted: 4.97, Actual: 0.00\n",
      "Predicted: 8.64, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.5877\n",
      "Predicted: 8.15, Actual: 0.00\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "Predicted: 13.49, Actual: 26.00\n",
      "Predicted: 5.87, Actual: 0.00\n",
      "Predicted: 17.69, Actual: 27.00\n",
      "Predicted: 3.53, Actual: 0.00\n",
      "Predicted: 10.27, Actual: 28.00\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "Predicted: 1.78, Actual: 0.00\n",
      "Predicted: 8.47, Actual: 0.00\n",
      "Predicted: 4.84, Actual: 0.00\n",
      "Predicted: 7.98, Actual: 19.00\n",
      "Predicted: 4.45, Actual: 0.00\n",
      "Predicted: 13.62, Actual: 24.00\n",
      "Predicted: 1.60, Actual: 0.00\n",
      "Predicted: 0.88, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.7199\n",
      "Predicted: 8.71, Actual: 0.00\n",
      "Predicted: 5.63, Actual: 0.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 2.24, Actual: 0.00\n",
      "Predicted: 4.47, Actual: 17.00\n",
      "Predicted: 9.84, Actual: 20.00\n",
      "Predicted: 12.64, Actual: 5.00\n",
      "Predicted: 3.71, Actual: 0.00\n",
      "Predicted: 13.18, Actual: 3.00\n",
      "Predicted: 12.85, Actual: 4.00\n",
      "Predicted: 4.68, Actual: 9.00\n",
      "Predicted: 11.90, Actual: 30.00\n",
      "Predicted: 5.63, Actual: 0.00\n",
      "Predicted: 19.80, Actual: 12.00\n",
      "Predicted: 5.00, Actual: 0.00\n",
      "Predicted: 13.44, Actual: 4.00\n",
      "Average loss on the testing dataset: 7.0210\n",
      "Predicted: 1.39, Actual: 0.00\n",
      "Predicted: 6.26, Actual: 17.00\n",
      "Predicted: 5.84, Actual: 0.00\n",
      "Predicted: 18.73, Actual: 1.00\n",
      "Predicted: 8.59, Actual: 0.00\n",
      "Predicted: 12.00, Actual: 7.00\n",
      "Predicted: 1.13, Actual: 0.00\n",
      "Predicted: 14.77, Actual: 8.00\n",
      "Predicted: 14.84, Actual: 25.00\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "Predicted: 1.78, Actual: 0.00\n",
      "Predicted: 16.10, Actual: 12.00\n",
      "Predicted: 14.70, Actual: 4.00\n",
      "Predicted: 2.14, Actual: 0.00\n",
      "Predicted: 13.74, Actual: 29.00\n",
      "Predicted: 14.51, Actual: 3.00\n",
      "Average loss on the testing dataset: 7.2631\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "Predicted: 2.15, Actual: 0.00\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "Predicted: 16.50, Actual: 6.00\n",
      "Predicted: 2.24, Actual: 0.00\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 9.01, Actual: 22.00\n",
      "Predicted: 11.00, Actual: 25.00\n",
      "Predicted: 3.50, Actual: 0.00\n",
      "Predicted: 18.36, Actual: 11.00\n",
      "Predicted: 16.53, Actual: 5.00\n",
      "Predicted: 1.42, Actual: 0.00\n",
      "Predicted: 13.26, Actual: 29.00\n",
      "Predicted: 18.29, Actual: 28.00\n",
      "Predicted: 6.79, Actual: 9.00\n",
      "Predicted: 4.22, Actual: 10.00\n",
      "Average loss on the testing dataset: 7.2924\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "Predicted: 12.14, Actual: 20.00\n",
      "Predicted: 7.13, Actual: 0.00\n",
      "Predicted: 3.09, Actual: 0.00\n",
      "Predicted: 5.77, Actual: 19.00\n",
      "Predicted: 3.47, Actual: 0.00\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "Predicted: 4.33, Actual: 2.00\n",
      "Predicted: 18.80, Actual: 12.00\n",
      "Predicted: 6.16, Actual: 0.00\n",
      "Predicted: 7.77, Actual: 1.00\n",
      "Predicted: 10.50, Actual: 7.00\n",
      "Predicted: 16.75, Actual: 16.00\n",
      "Predicted: 8.93, Actual: 18.00\n",
      "Predicted: 11.93, Actual: 19.00\n",
      "Predicted: 8.10, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9538\n",
      "Predicted: 10.99, Actual: 18.00\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "Predicted: 0.94, Actual: 0.00\n",
      "Predicted: 13.49, Actual: 8.00\n",
      "Predicted: 3.10, Actual: 0.00\n",
      "Predicted: 8.93, Actual: 1.00\n",
      "Predicted: 9.15, Actual: 28.00\n",
      "Predicted: 5.56, Actual: 0.00\n",
      "Predicted: 6.62, Actual: 0.00\n",
      "Predicted: 6.02, Actual: 22.00\n",
      "Predicted: 14.85, Actual: 7.00\n",
      "Predicted: 2.52, Actual: 0.00\n",
      "Predicted: 15.63, Actual: 8.00\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "Predicted: 12.02, Actual: 1.00\n",
      "Predicted: 2.98, Actual: 4.00\n",
      "Average loss on the testing dataset: 7.0230\n",
      "Predicted: 7.69, Actual: 0.00\n",
      "Predicted: 8.73, Actual: 17.00\n",
      "Predicted: 0.93, Actual: 0.00\n",
      "Predicted: 16.62, Actual: 29.00\n",
      "Predicted: 12.61, Actual: 4.00\n",
      "Predicted: 2.26, Actual: 0.00\n",
      "Predicted: 17.46, Actual: 28.00\n",
      "Predicted: 0.59, Actual: 0.00\n",
      "Predicted: 9.88, Actual: 1.00\n",
      "Predicted: 19.52, Actual: 25.00\n",
      "Predicted: 3.24, Actual: 0.00\n",
      "Predicted: 17.69, Actual: 7.00\n",
      "Predicted: 3.87, Actual: 0.00\n",
      "Predicted: 9.00, Actual: 0.00\n",
      "Predicted: 3.72, Actual: 0.00\n",
      "Predicted: 12.91, Actual: 2.00\n",
      "Average loss on the testing dataset: 6.9700\n",
      "Predicted: 9.00, Actual: 0.00\n",
      "Predicted: 3.23, Actual: 0.00\n",
      "Predicted: 13.48, Actual: 2.00\n",
      "Predicted: 7.60, Actual: 18.00\n",
      "Predicted: 8.22, Actual: 21.00\n",
      "Predicted: 17.81, Actual: 19.00\n",
      "Predicted: 5.96, Actual: 9.00\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "Predicted: 9.31, Actual: 24.00\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "Predicted: 2.46, Actual: 0.00\n",
      "Predicted: 1.82, Actual: 0.00\n",
      "Predicted: 5.21, Actual: 0.00\n",
      "Predicted: 12.02, Actual: 2.00\n",
      "Predicted: 18.91, Actual: 23.00\n",
      "Predicted: 5.91, Actual: 4.00\n",
      "Average loss on the testing dataset: 6.8942\n",
      "Predicted: 6.44, Actual: 15.00\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "Predicted: 18.09, Actual: 23.00\n",
      "Predicted: 0.58, Actual: 0.00\n",
      "Predicted: 1.71, Actual: 0.00\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "Predicted: 1.95, Actual: 0.00\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "Predicted: 5.59, Actual: 29.00\n",
      "Predicted: 15.35, Actual: 5.00\n",
      "Predicted: 4.37, Actual: 0.00\n",
      "Predicted: 8.49, Actual: 0.00\n",
      "Predicted: 13.63, Actual: 7.00\n",
      "Predicted: 4.16, Actual: 0.00\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.8517\n",
      "Predicted: 3.43, Actual: 0.00\n",
      "Predicted: 12.81, Actual: 21.00\n",
      "Predicted: 12.77, Actual: 14.00\n",
      "Predicted: 6.86, Actual: 0.00\n",
      "Predicted: 12.93, Actual: 16.00\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "Predicted: 5.61, Actual: 0.00\n",
      "Predicted: 7.48, Actual: 9.00\n",
      "Predicted: 1.92, Actual: 0.00\n",
      "Predicted: 9.65, Actual: 0.00\n",
      "Predicted: 17.65, Actual: 23.00\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "Predicted: 10.96, Actual: 15.00\n",
      "Predicted: 15.60, Actual: 17.00\n",
      "Predicted: 5.29, Actual: 0.00\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.5091\n",
      "Predicted: 14.85, Actual: 7.00\n",
      "Predicted: 5.75, Actual: 15.00\n",
      "Predicted: 9.28, Actual: 6.00\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "Predicted: 12.68, Actual: 8.00\n",
      "Predicted: 0.81, Actual: 0.00\n",
      "Predicted: 12.79, Actual: 2.00\n",
      "Predicted: 9.92, Actual: 0.00\n",
      "Predicted: 15.70, Actual: 1.00\n",
      "Predicted: 2.14, Actual: 0.00\n",
      "Predicted: 8.52, Actual: 0.00\n",
      "Predicted: 6.21, Actual: 0.00\n",
      "Predicted: 15.11, Actual: 16.00\n",
      "Predicted: 2.30, Actual: 0.00\n",
      "Predicted: 15.73, Actual: 28.00\n",
      "Predicted: 18.34, Actual: 24.00\n",
      "Average loss on the testing dataset: 6.4991\n",
      "Predicted: 15.41, Actual: 1.00\n",
      "Predicted: 6.17, Actual: 0.00\n",
      "Predicted: 5.09, Actual: 18.00\n",
      "Predicted: 6.70, Actual: 0.00\n",
      "Predicted: 2.08, Actual: 0.00\n",
      "Predicted: 1.77, Actual: 0.00\n",
      "Predicted: 6.66, Actual: 0.00\n",
      "Predicted: 7.91, Actual: 0.00\n",
      "Predicted: 4.74, Actual: 0.00\n",
      "Predicted: 14.60, Actual: 25.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 3.49, Actual: 0.00\n",
      "Predicted: 7.94, Actual: 30.00\n",
      "Predicted: 1.89, Actual: 0.00\n",
      "Predicted: 14.30, Actual: 26.00\n",
      "Predicted: 5.05, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.7009\n",
      "Predicted: 17.58, Actual: 16.00\n",
      "Predicted: 2.80, Actual: 0.00\n",
      "Predicted: 13.09, Actual: 10.00\n",
      "Predicted: 5.92, Actual: 21.00\n",
      "Predicted: 4.56, Actual: 15.00\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 5.62, Actual: 20.00\n",
      "Predicted: 6.87, Actual: 17.00\n",
      "Predicted: 3.26, Actual: 29.00\n",
      "Predicted: 1.63, Actual: 0.00\n",
      "Predicted: 3.81, Actual: 0.00\n",
      "Predicted: 1.52, Actual: 0.00\n",
      "Predicted: 3.43, Actual: 0.00\n",
      "Predicted: 5.22, Actual: 0.00\n",
      "Predicted: 3.07, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.8903\n",
      "Predicted: 1.43, Actual: 0.00\n",
      "Predicted: 3.33, Actual: 0.00\n",
      "Predicted: 7.25, Actual: 12.00\n",
      "Predicted: 4.63, Actual: 0.00\n",
      "Predicted: 13.61, Actual: 6.00\n",
      "Predicted: 8.02, Actual: 25.00\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 13.77, Actual: 20.00\n",
      "Predicted: 11.17, Actual: 30.00\n",
      "Predicted: 9.15, Actual: 8.00\n",
      "Predicted: 6.11, Actual: 0.00\n",
      "Predicted: 2.84, Actual: 0.00\n",
      "Predicted: 4.74, Actual: 9.00\n",
      "Predicted: 11.28, Actual: 9.00\n",
      "Predicted: 9.28, Actual: 20.00\n",
      "Predicted: 16.64, Actual: 12.00\n",
      "Average loss on the testing dataset: 6.8956\n",
      "Predicted: 7.94, Actual: 0.00\n",
      "Predicted: 3.46, Actual: 0.00\n",
      "Predicted: 0.77, Actual: 0.00\n",
      "Predicted: 9.58, Actual: 12.00\n",
      "Predicted: 11.03, Actual: 23.00\n",
      "Predicted: 5.86, Actual: 15.00\n",
      "Predicted: 12.91, Actual: 6.00\n",
      "Predicted: 2.32, Actual: 0.00\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "Predicted: 14.77, Actual: 26.00\n",
      "Predicted: 15.66, Actual: 27.00\n",
      "Predicted: 4.35, Actual: 0.00\n",
      "Predicted: 17.57, Actual: 9.00\n",
      "Predicted: 14.71, Actual: 2.00\n",
      "Average loss on the testing dataset: 6.8505\n",
      "Predicted: 9.92, Actual: 12.00\n",
      "Predicted: 13.49, Actual: 20.00\n",
      "Predicted: 10.81, Actual: 7.00\n",
      "Predicted: 2.10, Actual: 0.00\n",
      "Predicted: 12.73, Actual: 24.00\n",
      "Predicted: 20.94, Actual: 26.00\n",
      "Predicted: 13.75, Actual: 8.00\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "Predicted: 6.22, Actual: 0.00\n",
      "Predicted: 8.33, Actual: 12.00\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "Predicted: 14.78, Actual: 16.00\n",
      "Predicted: 4.11, Actual: 5.00\n",
      "Predicted: 13.19, Actual: 26.00\n",
      "Predicted: 3.39, Actual: 0.00\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.6695\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "Predicted: 5.10, Actual: 0.00\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "Predicted: 8.06, Actual: 19.00\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "Predicted: 1.45, Actual: 0.00\n",
      "Predicted: 0.95, Actual: 0.00\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "Predicted: 9.86, Actual: 19.00\n",
      "Predicted: 1.43, Actual: 0.00\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "Predicted: 8.50, Actual: 0.00\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "Predicted: 3.48, Actual: 0.00\n",
      "Predicted: 1.01, Actual: 0.00\n",
      "Predicted: 12.62, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.5112\n",
      "Predicted: 17.24, Actual: 1.00\n",
      "Predicted: 4.24, Actual: 0.00\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "Predicted: 4.94, Actual: 0.00\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "Predicted: 8.00, Actual: 0.00\n",
      "Predicted: 7.56, Actual: 8.00\n",
      "Predicted: 2.75, Actual: 16.00\n",
      "Predicted: 3.28, Actual: 0.00\n",
      "Predicted: 6.26, Actual: 0.00\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "Predicted: 13.28, Actual: 27.00\n",
      "Predicted: 3.30, Actual: 4.00\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "Predicted: 13.30, Actual: 17.00\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4787\n",
      "Predicted: 5.31, Actual: 23.00\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "Predicted: 2.24, Actual: 0.00\n",
      "Predicted: 13.54, Actual: 7.00\n",
      "Predicted: 3.22, Actual: 19.00\n",
      "Predicted: 14.79, Actual: 22.00\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "Predicted: 0.75, Actual: 0.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 5.08, Actual: 0.00\n",
      "Predicted: 6.88, Actual: 0.00\n",
      "Predicted: 13.41, Actual: 25.00\n",
      "Predicted: 6.88, Actual: 0.00\n",
      "Predicted: 2.76, Actual: 0.00\n",
      "Predicted: 3.33, Actual: 0.00\n",
      "Predicted: 2.28, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4849\n",
      "Predicted: 2.35, Actual: 0.00\n",
      "Predicted: 1.27, Actual: 0.00\n",
      "Predicted: 4.86, Actual: 0.00\n",
      "Predicted: 7.11, Actual: 19.00\n",
      "Predicted: 1.85, Actual: 0.00\n",
      "Predicted: 8.40, Actual: 1.00\n",
      "Predicted: 12.56, Actual: 27.00\n",
      "Predicted: 5.47, Actual: 10.00\n",
      "Predicted: 6.69, Actual: 5.00\n",
      "Predicted: 9.79, Actual: 10.00\n",
      "Predicted: 4.93, Actual: 0.00\n",
      "Predicted: 7.64, Actual: 23.00\n",
      "Predicted: 4.35, Actual: 0.00\n",
      "Predicted: 2.76, Actual: 0.00\n",
      "Predicted: 3.06, Actual: 0.00\n",
      "Predicted: 10.50, Actual: 16.00\n",
      "Average loss on the testing dataset: 6.4410\n",
      "Predicted: 8.26, Actual: 30.00\n",
      "Predicted: 4.96, Actual: 0.00\n",
      "Predicted: 6.93, Actual: 0.00\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "Predicted: 4.87, Actual: 11.00\n",
      "Predicted: 19.66, Actual: 4.00\n",
      "Predicted: 14.39, Actual: 16.00\n",
      "Predicted: 6.06, Actual: 0.00\n",
      "Predicted: 6.65, Actual: 3.00\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "Predicted: 7.08, Actual: 0.00\n",
      "Predicted: 3.50, Actual: 29.00\n",
      "Predicted: 16.88, Actual: 29.00\n",
      "Predicted: 1.91, Actual: 0.00\n",
      "Predicted: 5.50, Actual: 0.00\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.6843\n",
      "Predicted: 2.03, Actual: 0.00\n",
      "Predicted: 2.83, Actual: 30.00\n",
      "Predicted: 18.51, Actual: 27.00\n",
      "Predicted: 2.28, Actual: 0.00\n",
      "Predicted: 0.70, Actual: 0.00\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "Predicted: 4.23, Actual: 12.00\n",
      "Predicted: 16.68, Actual: 6.00\n",
      "Predicted: 1.44, Actual: 0.00\n",
      "Predicted: 16.58, Actual: 9.00\n",
      "Predicted: 3.07, Actual: 0.00\n",
      "Predicted: 6.52, Actual: 0.00\n",
      "Predicted: 8.43, Actual: 0.00\n",
      "Predicted: 8.95, Actual: 0.00\n",
      "Predicted: 12.13, Actual: 30.00\n",
      "Predicted: 18.58, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9511\n",
      "Predicted: 2.40, Actual: 0.00\n",
      "Predicted: 16.88, Actual: 30.00\n",
      "Predicted: 8.11, Actual: 0.00\n",
      "Predicted: 9.10, Actual: 9.00\n",
      "Predicted: 3.84, Actual: 0.00\n",
      "Predicted: 10.80, Actual: 28.00\n",
      "Predicted: 12.21, Actual: 8.00\n",
      "Predicted: 12.33, Actual: 21.00\n",
      "Predicted: 1.20, Actual: 0.00\n",
      "Predicted: 3.10, Actual: 0.00\n",
      "Predicted: 17.51, Actual: 22.00\n",
      "Predicted: 6.35, Actual: 17.00\n",
      "Predicted: 17.54, Actual: 3.00\n",
      "Predicted: 5.36, Actual: 0.00\n",
      "Predicted: 5.21, Actual: 4.00\n",
      "Predicted: 17.88, Actual: 26.00\n",
      "Average loss on the testing dataset: 6.9774\n",
      "Predicted: 12.42, Actual: 4.00\n",
      "Predicted: 8.41, Actual: 0.00\n",
      "Predicted: 4.48, Actual: 3.00\n",
      "Predicted: 2.67, Actual: 0.00\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "Predicted: 15.83, Actual: 3.00\n",
      "Predicted: 5.46, Actual: 0.00\n",
      "Predicted: 17.32, Actual: 22.00\n",
      "Predicted: 13.76, Actual: 17.00\n",
      "Predicted: 11.77, Actual: 0.00\n",
      "Predicted: 17.29, Actual: 7.00\n",
      "Predicted: 13.80, Actual: 20.00\n",
      "Predicted: 6.78, Actual: 0.00\n",
      "Predicted: 6.55, Actual: 7.00\n",
      "Predicted: 2.91, Actual: 0.00\n",
      "Predicted: 5.53, Actual: 30.00\n",
      "Average loss on the testing dataset: 7.0575\n",
      "Predicted: 0.70, Actual: 0.00\n",
      "Predicted: 14.92, Actual: 27.00\n",
      "Predicted: 7.20, Actual: 0.00\n",
      "Predicted: 2.65, Actual: 0.00\n",
      "Predicted: 16.71, Actual: 1.00\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 8.07, Actual: 0.00\n",
      "Predicted: 1.03, Actual: 0.00\n",
      "Predicted: 14.45, Actual: 6.00\n",
      "Predicted: 12.70, Actual: 28.00\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "Predicted: 13.92, Actual: 1.00\n",
      "Predicted: 13.43, Actual: 5.00\n",
      "Predicted: 7.87, Actual: 0.00\n",
      "Predicted: 8.23, Actual: 22.00\n",
      "Predicted: 0.41, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1323\n",
      "Predicted: 19.41, Actual: 3.00\n",
      "Predicted: 16.67, Actual: 17.00\n",
      "Predicted: 5.22, Actual: 0.00\n",
      "Predicted: 3.41, Actual: 23.00\n",
      "Predicted: 7.76, Actual: 0.00\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "Predicted: 16.86, Actual: 25.00\n",
      "Predicted: 3.86, Actual: 0.00\n",
      "Predicted: 20.54, Actual: 6.00\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "Predicted: 7.01, Actual: 11.00\n",
      "Predicted: 5.43, Actual: 16.00\n",
      "Predicted: 1.76, Actual: 0.00\n",
      "Predicted: 8.36, Actual: 17.00\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "Predicted: 6.21, Actual: 13.00\n",
      "Average loss on the testing dataset: 7.1949\n",
      "Predicted: 6.66, Actual: 0.00\n",
      "Predicted: 12.97, Actual: 15.00\n",
      "Predicted: 17.67, Actual: 23.00\n",
      "Predicted: 8.14, Actual: 2.00\n",
      "Predicted: 14.41, Actual: 21.00\n",
      "Predicted: 2.20, Actual: 0.00\n",
      "Predicted: 16.03, Actual: 29.00\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 11.26, Actual: 30.00\n",
      "Predicted: 1.36, Actual: 0.00\n",
      "Predicted: 2.17, Actual: 0.00\n",
      "Predicted: 11.05, Actual: 13.00\n",
      "Predicted: 5.38, Actual: 0.00\n",
      "Predicted: 4.32, Actual: 0.00\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "Predicted: 0.59, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1270\n",
      "Predicted: 12.25, Actual: 23.00\n",
      "Predicted: 2.12, Actual: 0.00\n",
      "Predicted: 0.68, Actual: 0.00\n",
      "Predicted: 17.61, Actual: 14.00\n",
      "Predicted: 2.95, Actual: 0.00\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "Predicted: 18.21, Actual: 0.00\n",
      "Predicted: 17.10, Actual: 9.00\n",
      "Predicted: 7.56, Actual: 3.00\n",
      "Predicted: 5.71, Actual: 0.00\n",
      "Predicted: 13.03, Actual: 27.00\n",
      "Predicted: 11.04, Actual: 0.00\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "Predicted: 14.92, Actual: 26.00\n",
      "Predicted: 2.54, Actual: 0.00\n",
      "Predicted: 16.17, Actual: 27.00\n",
      "Average loss on the testing dataset: 7.1607\n",
      "Predicted: 5.07, Actual: 0.00\n",
      "Predicted: 16.83, Actual: 16.00\n",
      "Predicted: 16.48, Actual: 5.00\n",
      "Predicted: 18.22, Actual: 3.00\n",
      "Predicted: 12.72, Actual: 11.00\n",
      "Predicted: 19.57, Actual: 19.00\n",
      "Predicted: 4.33, Actual: 0.00\n",
      "Predicted: 6.21, Actual: 1.00\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "Predicted: 5.88, Actual: 0.00\n",
      "Predicted: 11.06, Actual: 5.00\n",
      "Predicted: 13.30, Actual: 27.00\n",
      "Predicted: 4.24, Actual: 0.00\n",
      "Predicted: 8.24, Actual: 24.00\n",
      "Predicted: 9.70, Actual: 0.00\n",
      "Predicted: 4.19, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1706\n",
      "Predicted: 1.72, Actual: 0.00\n",
      "Predicted: 2.65, Actual: 0.00\n",
      "Predicted: 13.54, Actual: 18.00\n",
      "Predicted: 13.57, Actual: 30.00\n",
      "Predicted: 12.50, Actual: 5.00\n",
      "Predicted: 5.58, Actual: 19.00\n",
      "Predicted: 4.21, Actual: 26.00\n",
      "Predicted: 13.30, Actual: 6.00\n",
      "Predicted: 4.38, Actual: 0.00\n",
      "Predicted: 18.12, Actual: 23.00\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "Predicted: 4.50, Actual: 12.00\n",
      "Predicted: 9.42, Actual: 0.00\n",
      "Predicted: 15.97, Actual: 23.00\n",
      "Predicted: 4.78, Actual: 0.00\n",
      "Predicted: 5.06, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2380\n",
      "Predicted: 1.19, Actual: 0.00\n",
      "Predicted: 10.82, Actual: 0.00\n",
      "Predicted: 1.34, Actual: 0.00\n",
      "Predicted: 4.13, Actual: 0.00\n",
      "Predicted: 9.65, Actual: 17.00\n",
      "Predicted: 16.21, Actual: 12.00\n",
      "Predicted: 16.42, Actual: 17.00\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "Predicted: 5.82, Actual: 0.00\n",
      "Predicted: 21.07, Actual: 13.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 10.67, Actual: 23.00\n",
      "Predicted: 12.36, Actual: 14.00\n",
      "Predicted: 14.39, Actual: 12.00\n",
      "Predicted: 19.21, Actual: 29.00\n",
      "Predicted: 4.95, Actual: 12.00\n",
      "Average loss on the testing dataset: 7.1512\n",
      "Predicted: 7.91, Actual: 9.00\n",
      "Predicted: 4.16, Actual: 0.00\n",
      "Predicted: 19.74, Actual: 30.00\n",
      "Predicted: 3.68, Actual: 0.00\n",
      "Predicted: 10.27, Actual: 26.00\n",
      "Predicted: 5.63, Actual: 16.00\n",
      "Predicted: 15.95, Actual: 14.00\n",
      "Predicted: 10.22, Actual: 0.00\n",
      "Predicted: 15.67, Actual: 3.00\n",
      "Predicted: 8.17, Actual: 1.00\n",
      "Predicted: 2.73, Actual: 0.00\n",
      "Predicted: 3.55, Actual: 0.00\n",
      "Predicted: 1.49, Actual: 0.00\n",
      "Predicted: 7.35, Actual: 0.00\n",
      "Predicted: 15.07, Actual: 17.00\n",
      "Predicted: 1.24, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1243\n",
      "Predicted: 8.00, Actual: 2.00\n",
      "Predicted: 13.92, Actual: 15.00\n",
      "Predicted: 15.81, Actual: 23.00\n",
      "Predicted: 7.31, Actual: 0.00\n",
      "Predicted: 7.35, Actual: 0.00\n",
      "Predicted: 12.49, Actual: 17.00\n",
      "Predicted: 1.68, Actual: 0.00\n",
      "Predicted: 2.41, Actual: 0.00\n",
      "Predicted: 20.55, Actual: 17.00\n",
      "Predicted: 8.99, Actual: 11.00\n",
      "Predicted: 5.49, Actual: 0.00\n",
      "Predicted: 11.74, Actual: 15.00\n",
      "Predicted: 8.74, Actual: 0.00\n",
      "Predicted: 13.18, Actual: 17.00\n",
      "Predicted: 3.03, Actual: 0.00\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0004\n",
      "Predicted: 6.57, Actual: 9.00\n",
      "Predicted: 9.03, Actual: 18.00\n",
      "Predicted: 1.39, Actual: 0.00\n",
      "Predicted: 2.97, Actual: 7.00\n",
      "Predicted: 3.81, Actual: 0.00\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "Predicted: 1.90, Actual: 0.00\n",
      "Predicted: 6.08, Actual: 0.00\n",
      "Predicted: 18.54, Actual: 26.00\n",
      "Predicted: 10.85, Actual: 30.00\n",
      "Predicted: 3.21, Actual: 0.00\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "Predicted: 15.12, Actual: 13.00\n",
      "Predicted: 12.12, Actual: 24.00\n",
      "Predicted: 5.79, Actual: 26.00\n",
      "Predicted: 16.66, Actual: 22.00\n",
      "Average loss on the testing dataset: 7.0344\n",
      "Predicted: 6.07, Actual: 0.00\n",
      "Predicted: 8.36, Actual: 5.00\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "Predicted: 11.47, Actual: 27.00\n",
      "Predicted: 4.73, Actual: 2.00\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 10.50, Actual: 5.00\n",
      "Predicted: 13.60, Actual: 17.00\n",
      "Predicted: 1.74, Actual: 0.00\n",
      "Predicted: 16.25, Actual: 12.00\n",
      "Predicted: 8.59, Actual: 24.00\n",
      "Predicted: 9.48, Actual: 27.00\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "Predicted: 6.49, Actual: 0.00\n",
      "Predicted: 13.65, Actual: 4.00\n",
      "Predicted: 8.61, Actual: 8.00\n",
      "Average loss on the testing dataset: 7.0409\n",
      "Predicted: 4.48, Actual: 0.00\n",
      "Predicted: 9.36, Actual: 7.00\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "Predicted: 20.21, Actual: 25.00\n",
      "Predicted: 4.36, Actual: 0.00\n",
      "Predicted: 5.34, Actual: 0.00\n",
      "Predicted: 7.46, Actual: 7.00\n",
      "Predicted: 6.00, Actual: 29.00\n",
      "Predicted: 4.94, Actual: 0.00\n",
      "Predicted: 5.26, Actual: 9.00\n",
      "Predicted: 2.62, Actual: 0.00\n",
      "Predicted: 13.22, Actual: 27.00\n",
      "Predicted: 4.97, Actual: 0.00\n",
      "Predicted: 2.05, Actual: 0.00\n",
      "Predicted: 13.16, Actual: 21.00\n",
      "Predicted: 0.88, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0317\n",
      "Predicted: 2.36, Actual: 0.00\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "Predicted: 5.36, Actual: 0.00\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "Predicted: 17.14, Actual: 0.00\n",
      "Predicted: 15.55, Actual: 30.00\n",
      "Predicted: 12.86, Actual: 30.00\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "Predicted: 7.87, Actual: 0.00\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "Predicted: 12.96, Actual: 30.00\n",
      "Predicted: 14.78, Actual: 18.00\n",
      "Predicted: 3.13, Actual: 3.00\n",
      "Predicted: 2.87, Actual: 0.00\n",
      "Predicted: 17.45, Actual: 22.00\n",
      "Average loss on the testing dataset: 7.0749\n",
      "Predicted: 4.24, Actual: 0.00\n",
      "Predicted: 14.09, Actual: 23.00\n",
      "Predicted: 3.01, Actual: 0.00\n",
      "Predicted: 2.68, Actual: 0.00\n",
      "Predicted: 4.85, Actual: 0.00\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "Predicted: 11.24, Actual: 17.00\n",
      "Predicted: 0.60, Actual: 0.00\n",
      "Predicted: 5.78, Actual: 0.00\n",
      "Predicted: 9.28, Actual: 9.00\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "Predicted: 8.12, Actual: 0.00\n",
      "Predicted: 7.41, Actual: 0.00\n",
      "Predicted: 12.62, Actual: 15.00\n",
      "Predicted: 17.67, Actual: 27.00\n",
      "Predicted: 10.87, Actual: 20.00\n",
      "Average loss on the testing dataset: 6.9875\n",
      "Predicted: 14.36, Actual: 9.00\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "Predicted: 13.46, Actual: 27.00\n",
      "Predicted: 3.85, Actual: 17.00\n",
      "Predicted: 3.47, Actual: 0.00\n",
      "Predicted: 2.60, Actual: 0.00\n",
      "Predicted: 3.12, Actual: 23.00\n",
      "Predicted: 7.62, Actual: 11.00\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "Predicted: 4.07, Actual: 0.00\n",
      "Predicted: 15.00, Actual: 2.00\n",
      "Predicted: 3.08, Actual: 0.00\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "Predicted: 3.96, Actual: 0.00\n",
      "Predicted: 16.26, Actual: 25.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0042\n",
      "Predicted: 14.39, Actual: 26.00\n",
      "Predicted: 15.40, Actual: 16.00\n",
      "Predicted: 15.05, Actual: 7.00\n",
      "Predicted: 1.36, Actual: 0.00\n",
      "Predicted: 13.77, Actual: 27.00\n",
      "Predicted: 2.32, Actual: 0.00\n",
      "Predicted: 9.63, Actual: 1.00\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 5.20, Actual: 8.00\n",
      "Predicted: 12.02, Actual: 9.00\n",
      "Predicted: 4.86, Actual: 0.00\n",
      "Predicted: 17.32, Actual: 6.00\n",
      "Predicted: 0.75, Actual: 0.00\n",
      "Predicted: 5.09, Actual: 0.00\n",
      "Predicted: 12.94, Actual: 29.00\n",
      "Predicted: 14.34, Actual: 14.00\n",
      "Average loss on the testing dataset: 6.9885\n",
      "Predicted: 4.87, Actual: 0.00\n",
      "Predicted: 16.11, Actual: 28.00\n",
      "Predicted: 10.26, Actual: 2.00\n",
      "Predicted: 9.95, Actual: 3.00\n",
      "Predicted: 1.81, Actual: 0.00\n",
      "Predicted: 18.27, Actual: 27.00\n",
      "Predicted: 7.12, Actual: 30.00\n",
      "Predicted: 5.60, Actual: 10.00\n",
      "Predicted: 3.12, Actual: 0.00\n",
      "Predicted: 6.22, Actual: 21.00\n",
      "Predicted: 4.55, Actual: 0.00\n",
      "Predicted: 5.82, Actual: 28.00\n",
      "Predicted: 10.87, Actual: 28.00\n",
      "Predicted: 3.04, Actual: 0.00\n",
      "Predicted: 19.09, Actual: 14.00\n",
      "Predicted: 4.70, Actual: 14.00\n",
      "Average loss on the testing dataset: 7.1548\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "Predicted: 0.54, Actual: 0.00\n",
      "Predicted: 1.85, Actual: 0.00\n",
      "Predicted: 5.85, Actual: 0.00\n",
      "Predicted: 2.54, Actual: 0.00\n",
      "Predicted: 12.62, Actual: 12.00\n",
      "Predicted: 15.20, Actual: 21.00\n",
      "Predicted: 4.02, Actual: 0.00\n",
      "Predicted: 2.47, Actual: 0.00\n",
      "Predicted: 15.81, Actual: 5.00\n",
      "Predicted: 3.16, Actual: 0.00\n",
      "Predicted: 7.41, Actual: 6.00\n",
      "Predicted: 1.76, Actual: 0.00\n",
      "Predicted: 3.25, Actual: 14.00\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0514\n",
      "Predicted: 2.16, Actual: 0.00\n",
      "Predicted: 2.28, Actual: 0.00\n",
      "Predicted: 7.45, Actual: 21.00\n",
      "Predicted: 7.83, Actual: 0.00\n",
      "Predicted: 15.66, Actual: 29.00\n",
      "Predicted: 9.25, Actual: 11.00\n",
      "Predicted: 16.36, Actual: 1.00\n",
      "Predicted: 4.66, Actual: 0.00\n",
      "Predicted: 13.86, Actual: 9.00\n",
      "Predicted: 5.43, Actual: 0.00\n",
      "Predicted: 5.10, Actual: 0.00\n",
      "Predicted: 6.15, Actual: 0.00\n",
      "Predicted: 11.22, Actual: 16.00\n",
      "Predicted: 15.39, Actual: 21.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 1.33, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0293\n",
      "Predicted: 3.63, Actual: 5.00\n",
      "Predicted: 8.50, Actual: 15.00\n",
      "Predicted: 15.91, Actual: 4.00\n",
      "Predicted: 3.55, Actual: 7.00\n",
      "Predicted: 8.50, Actual: 2.00\n",
      "Predicted: 12.03, Actual: 19.00\n",
      "Predicted: 11.43, Actual: 11.00\n",
      "Predicted: 18.49, Actual: 26.00\n",
      "Predicted: 5.13, Actual: 0.00\n",
      "Predicted: 9.14, Actual: 4.00\n",
      "Predicted: 6.47, Actual: 22.00\n",
      "Predicted: 2.12, Actual: 0.00\n",
      "Predicted: 16.60, Actual: 5.00\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "Predicted: 1.02, Actual: 0.00\n",
      "Predicted: 14.61, Actual: 30.00\n",
      "Average loss on the testing dataset: 7.0301\n",
      "Predicted: 13.96, Actual: 11.00\n",
      "Predicted: 19.45, Actual: 5.00\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "Predicted: 18.68, Actual: 2.00\n",
      "Predicted: 4.30, Actual: 22.00\n",
      "Predicted: 3.58, Actual: 0.00\n",
      "Predicted: 14.19, Actual: 12.00\n",
      "Predicted: 7.80, Actual: 27.00\n",
      "Predicted: 5.66, Actual: 0.00\n",
      "Predicted: 11.36, Actual: 28.00\n",
      "Predicted: 14.67, Actual: 4.00\n",
      "Predicted: 18.76, Actual: 0.00\n",
      "Predicted: 6.03, Actual: 12.00\n",
      "Predicted: 11.75, Actual: 0.00\n",
      "Predicted: 0.74, Actual: 0.00\n",
      "Predicted: 4.57, Actual: 27.00\n",
      "Average loss on the testing dataset: 7.2672\n",
      "Predicted: 16.77, Actual: 16.00\n",
      "Predicted: 12.34, Actual: 29.00\n",
      "Predicted: 5.77, Actual: 0.00\n",
      "Predicted: 11.97, Actual: 0.00\n",
      "Predicted: 11.83, Actual: 17.00\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "Predicted: 7.30, Actual: 11.00\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "Predicted: 20.29, Actual: 16.00\n",
      "Predicted: 5.39, Actual: 0.00\n",
      "Predicted: 1.90, Actual: 0.00\n",
      "Predicted: 4.86, Actual: 0.00\n",
      "Predicted: 4.02, Actual: 0.00\n",
      "Predicted: 7.35, Actual: 0.00\n",
      "Predicted: 1.07, Actual: 0.00\n",
      "Predicted: 6.51, Actual: 25.00\n",
      "Average loss on the testing dataset: 7.2588\n",
      "Predicted: 5.28, Actual: 27.00\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "Predicted: 12.24, Actual: 20.00\n",
      "Predicted: 16.02, Actual: 12.00\n",
      "Predicted: 2.77, Actual: 0.00\n",
      "Predicted: 9.25, Actual: 0.00\n",
      "Predicted: 7.90, Actual: 0.00\n",
      "Predicted: 2.90, Actual: 0.00\n",
      "Predicted: 5.72, Actual: 0.00\n",
      "Predicted: 3.16, Actual: 0.00\n",
      "Predicted: 10.61, Actual: 0.00\n",
      "Predicted: 4.53, Actual: 0.00\n",
      "Predicted: 6.86, Actual: 0.00\n",
      "Predicted: 0.49, Actual: 0.00\n",
      "Predicted: 12.25, Actual: 18.00\n",
      "Predicted: 18.27, Actual: 30.00\n",
      "Average loss on the testing dataset: 7.2679\n",
      "Predicted: 2.63, Actual: 0.00\n",
      "Predicted: 11.89, Actual: 0.00\n",
      "Predicted: 8.23, Actual: 29.00\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "Predicted: 4.52, Actual: 0.00\n",
      "Predicted: 4.95, Actual: 0.00\n",
      "Predicted: 15.91, Actual: 8.00\n",
      "Predicted: 1.34, Actual: 0.00\n",
      "Predicted: 12.96, Actual: 5.00\n",
      "Predicted: 7.68, Actual: 30.00\n",
      "Predicted: 1.77, Actual: 0.00\n",
      "Predicted: 10.52, Actual: 1.00\n",
      "Predicted: 14.78, Actual: 18.00\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "Predicted: 12.91, Actual: 25.00\n",
      "Predicted: 14.78, Actual: 25.00\n",
      "Average loss on the testing dataset: 7.3445\n",
      "Predicted: 8.63, Actual: 25.00\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "Predicted: 17.02, Actual: 22.00\n",
      "Predicted: 5.94, Actual: 0.00\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 4.41, Actual: 0.00\n",
      "Predicted: 9.52, Actual: 0.00\n",
      "Predicted: 19.01, Actual: 21.00\n",
      "Predicted: 4.62, Actual: 0.00\n",
      "Predicted: 12.50, Actual: 28.00\n",
      "Predicted: 1.28, Actual: 0.00\n",
      "Predicted: 14.16, Actual: 1.00\n",
      "Predicted: 4.21, Actual: 0.00\n",
      "Predicted: 0.53, Actual: 0.00\n",
      "Predicted: 9.95, Actual: 25.00\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.3542\n",
      "Predicted: 7.21, Actual: 0.00\n",
      "Predicted: 6.49, Actual: 0.00\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "Predicted: 8.10, Actual: 2.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 17.54, Actual: 25.00\n",
      "Predicted: 5.48, Actual: 0.00\n",
      "Predicted: 15.69, Actual: 12.00\n",
      "Predicted: 0.73, Actual: 0.00\n",
      "Predicted: 5.40, Actual: 0.00\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "Predicted: 3.93, Actual: 0.00\n",
      "Predicted: 14.50, Actual: 5.00\n",
      "Predicted: 5.71, Actual: 0.00\n",
      "Predicted: 2.99, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2695\n",
      "Predicted: 19.70, Actual: 5.00\n",
      "Predicted: 2.31, Actual: 0.00\n",
      "Predicted: 12.78, Actual: 13.00\n",
      "Predicted: 8.31, Actual: 8.00\n",
      "Predicted: 6.12, Actual: 30.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 2.59, Actual: 0.00\n",
      "Predicted: 11.91, Actual: 2.00\n",
      "Predicted: 5.19, Actual: 0.00\n",
      "Predicted: 4.73, Actual: 9.00\n",
      "Predicted: 3.44, Actual: 0.00\n",
      "Predicted: 15.80, Actual: 8.00\n",
      "Predicted: 4.68, Actual: 24.00\n",
      "Predicted: 3.11, Actual: 0.00\n",
      "Predicted: 2.50, Actual: 6.00\n",
      "Predicted: 6.14, Actual: 14.00\n",
      "Average loss on the testing dataset: 7.3242\n",
      "Predicted: 18.56, Actual: 7.00\n",
      "Predicted: 6.36, Actual: 0.00\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "Predicted: 9.69, Actual: 5.00\n",
      "Predicted: 4.23, Actual: 0.00\n",
      "Predicted: 12.64, Actual: 0.00\n",
      "Predicted: 4.87, Actual: 0.00\n",
      "Predicted: 6.62, Actual: 29.00\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "Predicted: 1.35, Actual: 0.00\n",
      "Predicted: 16.55, Actual: 29.00\n",
      "Predicted: 16.36, Actual: 21.00\n",
      "Predicted: 13.65, Actual: 28.00\n",
      "Predicted: 7.03, Actual: 16.00\n",
      "Predicted: 6.46, Actual: 0.00\n",
      "Predicted: 2.89, Actual: 23.00\n",
      "Average loss on the testing dataset: 7.4197\n",
      "Predicted: 6.48, Actual: 0.00\n",
      "Predicted: 12.38, Actual: 30.00\n",
      "Predicted: 1.91, Actual: 0.00\n",
      "Predicted: 2.66, Actual: 0.00\n",
      "Predicted: 4.30, Actual: 0.00\n",
      "Predicted: 6.28, Actual: 0.00\n",
      "Predicted: 5.67, Actual: 28.00\n",
      "Predicted: 7.01, Actual: 0.00\n",
      "Predicted: 1.46, Actual: 0.00\n",
      "Predicted: 13.79, Actual: 24.00\n",
      "Predicted: 18.11, Actual: 11.00\n",
      "Predicted: 6.26, Actual: 0.00\n",
      "Predicted: 14.80, Actual: 2.00\n",
      "Predicted: 14.00, Actual: 9.00\n",
      "Predicted: 7.20, Actual: 0.00\n",
      "Predicted: 3.50, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4631\n",
      "Predicted: 12.21, Actual: 7.00\n",
      "Predicted: 14.97, Actual: 6.00\n",
      "Predicted: 11.83, Actual: 3.00\n",
      "Predicted: 2.31, Actual: 0.00\n",
      "Predicted: 17.34, Actual: 7.00\n",
      "Predicted: 2.85, Actual: 0.00\n",
      "Predicted: 12.25, Actual: 28.00\n",
      "Predicted: 14.81, Actual: 3.00\n",
      "Predicted: 2.00, Actual: 0.00\n",
      "Predicted: 14.46, Actual: 26.00\n",
      "Predicted: 7.05, Actual: 0.00\n",
      "Predicted: 18.44, Actual: 9.00\n",
      "Predicted: 2.44, Actual: 0.00\n",
      "Predicted: 5.32, Actual: 0.00\n",
      "Predicted: 7.14, Actual: 0.00\n",
      "Predicted: 3.72, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4623\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "Predicted: 11.64, Actual: 21.00\n",
      "Predicted: 8.69, Actual: 9.00\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "Predicted: 14.68, Actual: 1.00\n",
      "Predicted: 15.28, Actual: 30.00\n",
      "Predicted: 1.95, Actual: 0.00\n",
      "Predicted: 2.85, Actual: 0.00\n",
      "Predicted: 17.16, Actual: 17.00\n",
      "Predicted: 13.67, Actual: 17.00\n",
      "Predicted: 7.55, Actual: 0.00\n",
      "Predicted: 17.13, Actual: 6.00\n",
      "Predicted: 15.74, Actual: 21.00\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "Predicted: 14.98, Actual: 12.00\n",
      "Average loss on the testing dataset: 7.4263\n",
      "Predicted: 1.71, Actual: 0.00\n",
      "Predicted: 4.35, Actual: 22.00\n",
      "Predicted: 5.02, Actual: 0.00\n",
      "Predicted: 13.17, Actual: 10.00\n",
      "Predicted: 7.70, Actual: 0.00\n",
      "Predicted: 17.38, Actual: 22.00\n",
      "Predicted: 17.98, Actual: 26.00\n",
      "Predicted: 6.13, Actual: 0.00\n",
      "Predicted: 13.51, Actual: 26.00\n",
      "Predicted: 14.39, Actual: 10.00\n",
      "Predicted: 3.21, Actual: 0.00\n",
      "Predicted: 17.78, Actual: 30.00\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "Predicted: 6.57, Actual: 17.00\n",
      "Predicted: 6.87, Actual: 0.00\n",
      "Predicted: 12.31, Actual: 2.00\n",
      "Average loss on the testing dataset: 7.4334\n",
      "Predicted: 8.56, Actual: 5.00\n",
      "Predicted: 6.70, Actual: 0.00\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "Predicted: 7.60, Actual: 0.00\n",
      "Predicted: 4.07, Actual: 0.00\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "Predicted: 5.25, Actual: 8.00\n",
      "Predicted: 3.39, Actual: 0.00\n",
      "Predicted: 5.88, Actual: 0.00\n",
      "Predicted: 7.63, Actual: 0.00\n",
      "Predicted: 6.96, Actual: 24.00\n",
      "Predicted: 4.84, Actual: 27.00\n",
      "Predicted: 8.87, Actual: 28.00\n",
      "Predicted: 2.66, Actual: 0.00\n",
      "Predicted: 8.02, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4810\n",
      "Predicted: 10.94, Actual: 7.00\n",
      "Predicted: 2.20, Actual: 0.00\n",
      "Predicted: 6.86, Actual: 0.00\n",
      "Predicted: 13.97, Actual: 21.00\n",
      "Predicted: 5.47, Actual: 29.00\n",
      "Predicted: 8.77, Actual: 2.00\n",
      "Predicted: 3.37, Actual: 0.00\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "Predicted: 7.41, Actual: 30.00\n",
      "Predicted: 2.22, Actual: 0.00\n",
      "Predicted: 6.60, Actual: 26.00\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "Predicted: 13.92, Actual: 25.00\n",
      "Predicted: 2.56, Actual: 0.00\n",
      "Predicted: 4.34, Actual: 0.00\n",
      "Predicted: 11.38, Actual: 2.00\n",
      "Average loss on the testing dataset: 7.5697\n",
      "Predicted: 1.72, Actual: 0.00\n",
      "Predicted: 4.84, Actual: 0.00\n",
      "Predicted: 20.48, Actual: 26.00\n",
      "Predicted: 4.60, Actual: 22.00\n",
      "Predicted: 10.43, Actual: 0.00\n",
      "Predicted: 3.04, Actual: 0.00\n",
      "Predicted: 4.20, Actual: 0.00\n",
      "Predicted: 1.59, Actual: 0.00\n",
      "Predicted: 15.62, Actual: 7.00\n",
      "Predicted: 7.05, Actual: 0.00\n",
      "Predicted: 2.18, Actual: 0.00\n",
      "Predicted: 10.96, Actual: 23.00\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "Predicted: 12.68, Actual: 23.00\n",
      "Predicted: 2.34, Actual: 0.00\n",
      "Predicted: 3.06, Actual: 26.00\n",
      "Average loss on the testing dataset: 7.6060\n",
      "Predicted: 10.03, Actual: 0.00\n",
      "Predicted: 15.95, Actual: 21.00\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 7.16, Actual: 1.00\n",
      "Predicted: 4.36, Actual: 0.00\n",
      "Predicted: 18.97, Actual: 27.00\n",
      "Predicted: 5.36, Actual: 10.00\n",
      "Predicted: 15.50, Actual: 22.00\n",
      "Predicted: 6.60, Actual: 0.00\n",
      "Predicted: 0.98, Actual: 0.00\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 15.04, Actual: 8.00\n",
      "Predicted: 11.66, Actual: 26.00\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.5540\n",
      "Predicted: 17.06, Actual: 30.00\n",
      "Predicted: 9.88, Actual: 0.00\n",
      "Predicted: 9.09, Actual: 22.00\n",
      "Predicted: 12.60, Actual: 5.00\n",
      "Predicted: 10.33, Actual: 26.00\n",
      "Predicted: 17.08, Actual: 25.00\n",
      "Predicted: 3.89, Actual: 0.00\n",
      "Predicted: 5.98, Actual: 0.00\n",
      "Predicted: 8.89, Actual: 3.00\n",
      "Predicted: 8.28, Actual: 0.00\n",
      "Predicted: 14.55, Actual: 30.00\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "Predicted: 8.22, Actual: 0.00\n",
      "Predicted: 13.64, Actual: 9.00\n",
      "Predicted: 15.76, Actual: 10.00\n",
      "Predicted: 13.14, Actual: 17.00\n",
      "Average loss on the testing dataset: 7.5802\n",
      "Predicted: 7.66, Actual: 0.00\n",
      "Predicted: 13.01, Actual: 15.00\n",
      "Predicted: 4.28, Actual: 0.00\n",
      "Predicted: 8.63, Actual: 14.00\n",
      "Predicted: 8.10, Actual: 9.00\n",
      "Predicted: 3.15, Actual: 0.00\n",
      "Predicted: 16.26, Actual: 8.00\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 10.07, Actual: 3.00\n",
      "Predicted: 7.66, Actual: 20.00\n",
      "Predicted: 8.12, Actual: 9.00\n",
      "Predicted: 14.48, Actual: 8.00\n",
      "Predicted: 0.94, Actual: 0.00\n",
      "Predicted: 0.52, Actual: 0.00\n",
      "Predicted: 14.03, Actual: 4.00\n",
      "Predicted: 8.62, Actual: 30.00\n",
      "Average loss on the testing dataset: 7.5697\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "Predicted: 3.36, Actual: 0.00\n",
      "Predicted: 8.67, Actual: 0.00\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "Predicted: 11.19, Actual: 17.00\n",
      "Predicted: 6.99, Actual: 0.00\n",
      "Predicted: 11.90, Actual: 14.00\n",
      "Predicted: 8.14, Actual: 0.00\n",
      "Predicted: 9.74, Actual: 0.00\n",
      "Predicted: 14.85, Actual: 13.00\n",
      "Predicted: 13.51, Actual: 20.00\n",
      "Predicted: 3.52, Actual: 0.00\n",
      "Predicted: 14.60, Actual: 11.00\n",
      "Predicted: 7.73, Actual: 3.00\n",
      "Predicted: 9.27, Actual: 13.00\n",
      "Predicted: 12.67, Actual: 26.00\n",
      "Average loss on the testing dataset: 7.5208\n",
      "Predicted: 6.45, Actual: 0.00\n",
      "Predicted: 9.38, Actual: 0.00\n",
      "Predicted: 2.44, Actual: 0.00\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "Predicted: 2.88, Actual: 0.00\n",
      "Predicted: 16.77, Actual: 18.00\n",
      "Predicted: 11.80, Actual: 19.00\n",
      "Predicted: 14.37, Actual: 12.00\n",
      "Predicted: 3.96, Actual: 0.00\n",
      "Predicted: 14.14, Actual: 1.00\n",
      "Predicted: 10.57, Actual: 10.00\n",
      "Predicted: 5.29, Actual: 0.00\n",
      "Predicted: 19.20, Actual: 5.00\n",
      "Predicted: 6.98, Actual: 17.00\n",
      "Predicted: 4.26, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4857\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "Predicted: 1.33, Actual: 0.00\n",
      "Predicted: 5.55, Actual: 0.00\n",
      "Predicted: 6.47, Actual: 4.00\n",
      "Predicted: 11.34, Actual: 22.00\n",
      "Predicted: 19.71, Actual: 6.00\n",
      "Predicted: 8.81, Actual: 3.00\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "Predicted: 4.26, Actual: 0.00\n",
      "Predicted: 2.08, Actual: 0.00\n",
      "Predicted: 5.00, Actual: 0.00\n",
      "Predicted: 5.89, Actual: 0.00\n",
      "Predicted: 6.00, Actual: 15.00\n",
      "Predicted: 15.00, Actual: 19.00\n",
      "Predicted: 14.81, Actual: 0.00\n",
      "Predicted: 4.64, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4576\n",
      "Predicted: 12.03, Actual: 16.00\n",
      "Predicted: 6.71, Actual: 20.00\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "Predicted: 14.49, Actual: 5.00\n",
      "Predicted: 10.41, Actual: 8.00\n",
      "Predicted: 5.60, Actual: 0.00\n",
      "Predicted: 18.26, Actual: 2.00\n",
      "Predicted: 7.84, Actual: 20.00\n",
      "Predicted: 11.26, Actual: 7.00\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "Predicted: 13.61, Actual: 20.00\n",
      "Predicted: 3.07, Actual: 0.00\n",
      "Predicted: 14.62, Actual: 16.00\n",
      "Predicted: 20.05, Actual: 15.00\n",
      "Predicted: 10.65, Actual: 2.00\n",
      "Predicted: 4.20, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4427\n",
      "Predicted: 14.75, Actual: 22.00\n",
      "Predicted: 16.55, Actual: 21.00\n",
      "Predicted: 16.81, Actual: 27.00\n",
      "Predicted: 5.55, Actual: 0.00\n",
      "Predicted: 4.07, Actual: 0.00\n",
      "Predicted: 4.67, Actual: 0.00\n",
      "Predicted: 11.78, Actual: 5.00\n",
      "Predicted: 3.31, Actual: 8.00\n",
      "Predicted: 1.70, Actual: 0.00\n",
      "Predicted: 5.84, Actual: 0.00\n",
      "Predicted: 10.60, Actual: 0.00\n",
      "Predicted: 7.78, Actual: 26.00\n",
      "Predicted: 11.69, Actual: 7.00\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "Predicted: 3.15, Actual: 0.00\n",
      "Predicted: 3.55, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.4198\n",
      "Predicted: 17.21, Actual: 9.00\n",
      "Predicted: 14.63, Actual: 19.00\n",
      "Predicted: 11.86, Actual: 16.00\n",
      "Predicted: 4.93, Actual: 0.00\n",
      "Predicted: 14.17, Actual: 20.00\n",
      "Predicted: 2.64, Actual: 0.00\n",
      "Predicted: 17.12, Actual: 17.00\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "Predicted: 4.90, Actual: 7.00\n",
      "Predicted: 14.27, Actual: 15.00\n",
      "Predicted: 12.51, Actual: 9.00\n",
      "Predicted: 3.64, Actual: 7.00\n",
      "Predicted: 11.55, Actual: 27.00\n",
      "Predicted: 7.17, Actual: 10.00\n",
      "Predicted: 10.24, Actual: 0.00\n",
      "Predicted: 12.33, Actual: 13.00\n",
      "Average loss on the testing dataset: 7.3691\n",
      "Predicted: 9.91, Actual: 16.00\n",
      "Predicted: 4.66, Actual: 21.00\n",
      "Predicted: 1.41, Actual: 0.00\n",
      "Predicted: 16.05, Actual: 16.00\n",
      "Predicted: 8.02, Actual: 19.00\n",
      "Predicted: 4.07, Actual: 0.00\n",
      "Predicted: 4.33, Actual: 0.00\n",
      "Predicted: 5.96, Actual: 17.00\n",
      "Predicted: 11.63, Actual: 4.00\n",
      "Predicted: 15.17, Actual: 21.00\n",
      "Predicted: 5.01, Actual: 0.00\n",
      "Predicted: 10.29, Actual: 22.00\n",
      "Predicted: 7.81, Actual: 4.00\n",
      "Predicted: 12.82, Actual: 29.00\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "Predicted: 10.09, Actual: 23.00\n",
      "Average loss on the testing dataset: 7.3903\n",
      "Predicted: 6.70, Actual: 0.00\n",
      "Predicted: 9.45, Actual: 0.00\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "Predicted: 4.87, Actual: 0.00\n",
      "Predicted: 2.59, Actual: 0.00\n",
      "Predicted: 10.34, Actual: 23.00\n",
      "Predicted: 4.22, Actual: 0.00\n",
      "Predicted: 2.42, Actual: 0.00\n",
      "Predicted: 10.91, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "Predicted: 3.28, Actual: 0.00\n",
      "Predicted: 2.58, Actual: 20.00\n",
      "Predicted: 17.28, Actual: 13.00\n",
      "Predicted: 0.95, Actual: 0.00\n",
      "Predicted: 11.60, Actual: 23.00\n",
      "Predicted: 10.62, Actual: 4.00\n",
      "Average loss on the testing dataset: 7.3820\n",
      "Predicted: 1.16, Actual: 0.00\n",
      "Predicted: 5.14, Actual: 0.00\n",
      "Predicted: 2.54, Actual: 0.00\n",
      "Predicted: 9.05, Actual: 0.00\n",
      "Predicted: 13.94, Actual: 19.00\n",
      "Predicted: 1.39, Actual: 0.00\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "Predicted: 2.24, Actual: 0.00\n",
      "Predicted: 7.28, Actual: 22.00\n",
      "Predicted: 14.33, Actual: 2.00\n",
      "Predicted: 4.57, Actual: 0.00\n",
      "Predicted: 2.68, Actual: 0.00\n",
      "Predicted: 15.91, Actual: 27.00\n",
      "Predicted: 6.26, Actual: 0.00\n",
      "Predicted: 6.60, Actual: 21.00\n",
      "Predicted: 2.12, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.3688\n",
      "Predicted: 4.80, Actual: 0.00\n",
      "Predicted: 4.12, Actual: 6.00\n",
      "Predicted: 7.09, Actual: 0.00\n",
      "Predicted: 2.61, Actual: 0.00\n",
      "Predicted: 11.54, Actual: 23.00\n",
      "Predicted: 5.37, Actual: 0.00\n",
      "Predicted: 13.98, Actual: 16.00\n",
      "Predicted: 12.05, Actual: 7.00\n",
      "Predicted: 3.88, Actual: 0.00\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "Predicted: 15.41, Actual: 25.00\n",
      "Predicted: 8.19, Actual: 0.00\n",
      "Predicted: 11.64, Actual: 17.00\n",
      "Predicted: 14.72, Actual: 29.00\n",
      "Predicted: 4.10, Actual: 0.00\n",
      "Predicted: 15.78, Actual: 28.00\n",
      "Average loss on the testing dataset: 7.3491\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "Predicted: 11.04, Actual: 7.00\n",
      "Predicted: 7.28, Actual: 2.00\n",
      "Predicted: 8.26, Actual: 0.00\n",
      "Predicted: 2.55, Actual: 0.00\n",
      "Predicted: 6.43, Actual: 0.00\n",
      "Predicted: 4.40, Actual: 0.00\n",
      "Predicted: 1.27, Actual: 0.00\n",
      "Predicted: 17.18, Actual: 30.00\n",
      "Predicted: 13.01, Actual: 23.00\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "Predicted: 0.76, Actual: 0.00\n",
      "Predicted: 16.47, Actual: 0.00\n",
      "Predicted: 13.14, Actual: 23.00\n",
      "Predicted: 4.94, Actual: 0.00\n",
      "Predicted: 13.80, Actual: 7.00\n",
      "Average loss on the testing dataset: 7.3349\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "Predicted: 16.71, Actual: 18.00\n",
      "Predicted: 13.10, Actual: 26.00\n",
      "Predicted: 3.84, Actual: 7.00\n",
      "Predicted: 11.20, Actual: 2.00\n",
      "Predicted: 18.01, Actual: 18.00\n",
      "Predicted: 0.47, Actual: 0.00\n",
      "Predicted: 4.72, Actual: 13.00\n",
      "Predicted: 0.52, Actual: 0.00\n",
      "Predicted: 13.39, Actual: 17.00\n",
      "Predicted: 16.01, Actual: 23.00\n",
      "Predicted: 10.47, Actual: 14.00\n",
      "Predicted: 0.85, Actual: 0.00\n",
      "Predicted: 10.63, Actual: 0.00\n",
      "Predicted: 0.85, Actual: 0.00\n",
      "Predicted: 3.36, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2877\n",
      "Predicted: 12.79, Actual: 6.00\n",
      "Predicted: 0.81, Actual: 0.00\n",
      "Predicted: 16.24, Actual: 28.00\n",
      "Predicted: 1.39, Actual: 0.00\n",
      "Predicted: 15.39, Actual: 21.00\n",
      "Predicted: 18.51, Actual: 4.00\n",
      "Predicted: 9.31, Actual: 19.00\n",
      "Predicted: 8.67, Actual: 0.00\n",
      "Predicted: 17.18, Actual: 30.00\n",
      "Predicted: 3.50, Actual: 0.00\n",
      "Predicted: 1.70, Actual: 0.00\n",
      "Predicted: 4.59, Actual: 5.00\n",
      "Predicted: 9.96, Actual: 5.00\n",
      "Predicted: 4.39, Actual: 0.00\n",
      "Predicted: 0.94, Actual: 0.00\n",
      "Predicted: 3.45, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2685\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 6.30, Actual: 25.00\n",
      "Predicted: 0.66, Actual: 0.00\n",
      "Predicted: 1.47, Actual: 0.00\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "Predicted: 13.88, Actual: 8.00\n",
      "Predicted: 3.79, Actual: 0.00\n",
      "Predicted: 6.73, Actual: 1.00\n",
      "Predicted: 3.94, Actual: 15.00\n",
      "Predicted: 13.08, Actual: 26.00\n",
      "Predicted: 0.94, Actual: 0.00\n",
      "Predicted: 2.82, Actual: 0.00\n",
      "Predicted: 17.36, Actual: 17.00\n",
      "Predicted: 9.39, Actual: 8.00\n",
      "Predicted: 3.81, Actual: 0.00\n",
      "Predicted: 7.12, Actual: 28.00\n",
      "Average loss on the testing dataset: 7.2826\n",
      "Predicted: 3.93, Actual: 0.00\n",
      "Predicted: 1.56, Actual: 0.00\n",
      "Predicted: 5.10, Actual: 0.00\n",
      "Predicted: 5.18, Actual: 0.00\n",
      "Predicted: 18.31, Actual: 26.00\n",
      "Predicted: 9.28, Actual: 17.00\n",
      "Predicted: 7.06, Actual: 19.00\n",
      "Predicted: 2.97, Actual: 0.00\n",
      "Predicted: 1.36, Actual: 0.00\n",
      "Predicted: 10.39, Actual: 23.00\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "Predicted: 7.33, Actual: 4.00\n",
      "Predicted: 4.20, Actual: 0.00\n",
      "Predicted: 1.95, Actual: 0.00\n",
      "Predicted: 1.13, Actual: 0.00\n",
      "Predicted: 7.87, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2453\n",
      "Predicted: 11.17, Actual: 20.00\n",
      "Predicted: 6.83, Actual: 0.00\n",
      "Predicted: 1.02, Actual: 0.00\n",
      "Predicted: 5.05, Actual: 0.00\n",
      "Predicted: 2.57, Actual: 20.00\n",
      "Predicted: 5.30, Actual: 3.00\n",
      "Predicted: 15.02, Actual: 9.00\n",
      "Predicted: 15.20, Actual: 6.00\n",
      "Predicted: 7.85, Actual: 17.00\n",
      "Predicted: 3.89, Actual: 8.00\n",
      "Predicted: 12.05, Actual: 28.00\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "Predicted: 13.78, Actual: 12.00\n",
      "Predicted: 1.14, Actual: 0.00\n",
      "Predicted: 7.79, Actual: 20.00\n",
      "Predicted: 15.25, Actual: 8.00\n",
      "Average loss on the testing dataset: 7.2539\n",
      "Predicted: 11.54, Actual: 25.00\n",
      "Predicted: 9.28, Actual: 21.00\n",
      "Predicted: 11.16, Actual: 7.00\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "Predicted: 7.99, Actual: 0.00\n",
      "Predicted: 17.92, Actual: 11.00\n",
      "Predicted: 10.50, Actual: 1.00\n",
      "Predicted: 4.41, Actual: 0.00\n",
      "Predicted: 14.33, Actual: 8.00\n",
      "Predicted: 16.97, Actual: 21.00\n",
      "Predicted: 9.26, Actual: 15.00\n",
      "Predicted: 18.84, Actual: 13.00\n",
      "Predicted: 1.87, Actual: 0.00\n",
      "Predicted: 1.49, Actual: 0.00\n",
      "Predicted: 14.88, Actual: 0.00\n",
      "Predicted: 11.68, Actual: 10.00\n",
      "Average loss on the testing dataset: 7.2429\n",
      "Predicted: 11.65, Actual: 28.00\n",
      "Predicted: 5.20, Actual: 0.00\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "Predicted: 8.35, Actual: 0.00\n",
      "Predicted: 5.10, Actual: 0.00\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "Predicted: 4.92, Actual: 0.00\n",
      "Predicted: 4.12, Actual: 0.00\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "Predicted: 7.49, Actual: 0.00\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "Predicted: 6.73, Actual: 23.00\n",
      "Predicted: 13.63, Actual: 24.00\n",
      "Predicted: 10.66, Actual: 8.00\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2306\n",
      "Predicted: 10.29, Actual: 11.00\n",
      "Predicted: 2.69, Actual: 0.00\n",
      "Predicted: 2.65, Actual: 16.00\n",
      "Predicted: 19.19, Actual: 24.00\n",
      "Predicted: 18.06, Actual: 3.00\n",
      "Predicted: 4.50, Actual: 0.00\n",
      "Predicted: 7.68, Actual: 0.00\n",
      "Predicted: 0.76, Actual: 0.00\n",
      "Predicted: 6.62, Actual: 0.00\n",
      "Predicted: 4.69, Actual: 14.00\n",
      "Predicted: 12.29, Actual: 9.00\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "Predicted: 6.34, Actual: 3.00\n",
      "Predicted: 1.81, Actual: 0.00\n",
      "Predicted: 2.71, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2009\n",
      "Predicted: 4.54, Actual: 0.00\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "Predicted: 18.69, Actual: 21.00\n",
      "Predicted: 1.32, Actual: 0.00\n",
      "Predicted: 2.83, Actual: 0.00\n",
      "Predicted: 1.85, Actual: 0.00\n",
      "Predicted: 1.14, Actual: 0.00\n",
      "Predicted: 7.28, Actual: 13.00\n",
      "Predicted: 9.35, Actual: 7.00\n",
      "Predicted: 13.49, Actual: 14.00\n",
      "Predicted: 6.65, Actual: 0.00\n",
      "Predicted: 6.84, Actual: 25.00\n",
      "Predicted: 5.51, Actual: 13.00\n",
      "Predicted: 9.22, Actual: 15.00\n",
      "Predicted: 5.31, Actual: 0.00\n",
      "Predicted: 10.49, Actual: 24.00\n",
      "Average loss on the testing dataset: 7.1783\n",
      "Predicted: 8.31, Actual: 0.00\n",
      "Predicted: 12.07, Actual: 2.00\n",
      "Predicted: 15.17, Actual: 13.00\n",
      "Predicted: 9.67, Actual: 27.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 5.41, Actual: 26.00\n",
      "Predicted: 4.00, Actual: 0.00\n",
      "Predicted: 3.49, Actual: 25.00\n",
      "Predicted: 5.60, Actual: 0.00\n",
      "Predicted: 11.87, Actual: 17.00\n",
      "Predicted: 2.26, Actual: 0.00\n",
      "Predicted: 10.84, Actual: 1.00\n",
      "Predicted: 0.65, Actual: 0.00\n",
      "Predicted: 10.06, Actual: 0.00\n",
      "Predicted: 1.63, Actual: 0.00\n",
      "Predicted: 4.48, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2290\n",
      "Predicted: 15.66, Actual: 12.00\n",
      "Predicted: 11.85, Actual: 18.00\n",
      "Predicted: 16.21, Actual: 11.00\n",
      "Predicted: 15.11, Actual: 19.00\n",
      "Predicted: 13.83, Actual: 20.00\n",
      "Predicted: 13.53, Actual: 5.00\n",
      "Predicted: 1.66, Actual: 0.00\n",
      "Predicted: 18.94, Actual: 18.00\n",
      "Predicted: 5.21, Actual: 0.00\n",
      "Predicted: 5.01, Actual: 25.00\n",
      "Predicted: 3.22, Actual: 0.00\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "Predicted: 13.15, Actual: 26.00\n",
      "Predicted: 13.26, Actual: 3.00\n",
      "Predicted: 3.52, Actual: 0.00\n",
      "Predicted: 9.45, Actual: 23.00\n",
      "Average loss on the testing dataset: 7.2347\n",
      "Predicted: 3.38, Actual: 0.00\n",
      "Predicted: 11.80, Actual: 27.00\n",
      "Predicted: 5.61, Actual: 12.00\n",
      "Predicted: 14.29, Actual: 15.00\n",
      "Predicted: 17.98, Actual: 20.00\n",
      "Predicted: 6.21, Actual: 4.00\n",
      "Predicted: 4.03, Actual: 0.00\n",
      "Predicted: 3.93, Actual: 0.00\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "Predicted: 10.17, Actual: 0.00\n",
      "Predicted: 14.40, Actual: 17.00\n",
      "Predicted: 13.84, Actual: 26.00\n",
      "Predicted: 6.40, Actual: 10.00\n",
      "Predicted: 15.66, Actual: 1.00\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2172\n",
      "Predicted: 17.43, Actual: 3.00\n",
      "Predicted: 19.09, Actual: 16.00\n",
      "Predicted: 13.53, Actual: 29.00\n",
      "Predicted: 9.19, Actual: 5.00\n",
      "Predicted: 4.72, Actual: 19.00\n",
      "Predicted: 2.74, Actual: 0.00\n",
      "Predicted: 3.95, Actual: 0.00\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "Predicted: 4.67, Actual: 0.00\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "Predicted: 7.27, Actual: 0.00\n",
      "Predicted: 3.05, Actual: 0.00\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "Predicted: 2.49, Actual: 0.00\n",
      "Predicted: 12.53, Actual: 5.00\n",
      "Predicted: 1.60, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2030\n",
      "Predicted: 11.46, Actual: 28.00\n",
      "Predicted: 2.09, Actual: 0.00\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "Predicted: 11.86, Actual: 23.00\n",
      "Predicted: 10.53, Actual: 0.00\n",
      "Predicted: 19.13, Actual: 12.00\n",
      "Predicted: 1.51, Actual: 0.00\n",
      "Predicted: 19.78, Actual: 25.00\n",
      "Predicted: 4.74, Actual: 0.00\n",
      "Predicted: 6.22, Actual: 0.00\n",
      "Predicted: 16.39, Actual: 5.00\n",
      "Predicted: 3.64, Actual: 0.00\n",
      "Predicted: 20.33, Actual: 5.00\n",
      "Predicted: 14.65, Actual: 17.00\n",
      "Predicted: 10.00, Actual: 3.00\n",
      "Predicted: 18.94, Actual: 23.00\n",
      "Average loss on the testing dataset: 7.2082\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "Predicted: 9.09, Actual: 18.00\n",
      "Predicted: 5.93, Actual: 19.00\n",
      "Predicted: 9.12, Actual: 6.00\n",
      "Predicted: 9.58, Actual: 22.00\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "Predicted: 16.67, Actual: 29.00\n",
      "Predicted: 6.12, Actual: 24.00\n",
      "Predicted: 9.33, Actual: 0.00\n",
      "Predicted: 8.25, Actual: 19.00\n",
      "Predicted: 5.62, Actual: 0.00\n",
      "Predicted: 9.83, Actual: 0.00\n",
      "Predicted: 4.38, Actual: 0.00\n",
      "Predicted: 10.24, Actual: 19.00\n",
      "Predicted: 9.52, Actual: 25.00\n",
      "Average loss on the testing dataset: 7.2483\n",
      "Predicted: 15.39, Actual: 30.00\n",
      "Predicted: 6.38, Actual: 0.00\n",
      "Predicted: 1.56, Actual: 0.00\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "Predicted: 9.36, Actual: 0.00\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "Predicted: 5.16, Actual: 0.00\n",
      "Predicted: 5.00, Actual: 0.00\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "Predicted: 18.20, Actual: 6.00\n",
      "Predicted: 10.51, Actual: 17.00\n",
      "Predicted: 7.31, Actual: 26.00\n",
      "Predicted: 0.53, Actual: 0.00\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "Predicted: 11.59, Actual: 13.00\n",
      "Predicted: 1.71, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2421\n",
      "Predicted: 2.90, Actual: 0.00\n",
      "Predicted: 7.83, Actual: 0.00\n",
      "Predicted: 2.14, Actual: 0.00\n",
      "Predicted: 8.24, Actual: 0.00\n",
      "Predicted: 1.20, Actual: 0.00\n",
      "Predicted: 13.99, Actual: 19.00\n",
      "Predicted: 11.49, Actual: 20.00\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "Predicted: 13.54, Actual: 11.00\n",
      "Predicted: 1.53, Actual: 0.00\n",
      "Predicted: 1.31, Actual: 0.00\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 4.07, Actual: 0.00\n",
      "Predicted: 12.75, Actual: 20.00\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1889\n",
      "Predicted: 19.40, Actual: 18.00\n",
      "Predicted: 8.10, Actual: 23.00\n",
      "Predicted: 12.01, Actual: 25.00\n",
      "Predicted: 5.07, Actual: 0.00\n",
      "Predicted: 0.81, Actual: 0.00\n",
      "Predicted: 4.66, Actual: 16.00\n",
      "Predicted: 20.28, Actual: 24.00\n",
      "Predicted: 16.64, Actual: 17.00\n",
      "Predicted: 5.48, Actual: 0.00\n",
      "Predicted: 11.65, Actual: 30.00\n",
      "Predicted: 7.28, Actual: 5.00\n",
      "Predicted: 14.64, Actual: 4.00\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "Predicted: 4.76, Actual: 0.00\n",
      "Predicted: 17.17, Actual: 10.00\n",
      "Predicted: 4.64, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1969\n",
      "Predicted: 5.54, Actual: 0.00\n",
      "Predicted: 8.37, Actual: 3.00\n",
      "Predicted: 7.53, Actual: 23.00\n",
      "Predicted: 12.67, Actual: 10.00\n",
      "Predicted: 10.14, Actual: 28.00\n",
      "Predicted: 11.66, Actual: 20.00\n",
      "Predicted: 15.13, Actual: 16.00\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "Predicted: 18.10, Actual: 18.00\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "Predicted: 11.03, Actual: 17.00\n",
      "Predicted: 4.01, Actual: 0.00\n",
      "Predicted: 5.04, Actual: 18.00\n",
      "Predicted: 1.47, Actual: 0.00\n",
      "Predicted: 8.12, Actual: 0.00\n",
      "Predicted: 12.05, Actual: 25.00\n",
      "Average loss on the testing dataset: 7.2054\n",
      "Predicted: 19.69, Actual: 18.00\n",
      "Predicted: 1.66, Actual: 0.00\n",
      "Predicted: 1.24, Actual: 0.00\n",
      "Predicted: 5.27, Actual: 0.00\n",
      "Predicted: 4.79, Actual: 6.00\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "Predicted: 9.99, Actual: 0.00\n",
      "Predicted: 5.89, Actual: 0.00\n",
      "Predicted: 4.71, Actual: 10.00\n",
      "Predicted: 4.37, Actual: 0.00\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 8.14, Actual: 0.00\n",
      "Predicted: 9.85, Actual: 26.00\n",
      "Predicted: 5.61, Actual: 1.00\n",
      "Predicted: 11.91, Actual: 30.00\n",
      "Predicted: 12.44, Actual: 4.00\n",
      "Average loss on the testing dataset: 7.2006\n",
      "Predicted: 6.07, Actual: 0.00\n",
      "Predicted: 1.80, Actual: 0.00\n",
      "Predicted: 19.53, Actual: 3.00\n",
      "Predicted: 18.19, Actual: 12.00\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "Predicted: 17.74, Actual: 6.00\n",
      "Predicted: 8.75, Actual: 0.00\n",
      "Predicted: 5.69, Actual: 15.00\n",
      "Predicted: 2.23, Actual: 0.00\n",
      "Predicted: 6.68, Actual: 0.00\n",
      "Predicted: 13.38, Actual: 21.00\n",
      "Predicted: 13.35, Actual: 12.00\n",
      "Predicted: 7.95, Actual: 21.00\n",
      "Predicted: 11.92, Actual: 18.00\n",
      "Predicted: 4.18, Actual: 17.00\n",
      "Predicted: 13.10, Actual: 19.00\n",
      "Average loss on the testing dataset: 7.2102\n",
      "Predicted: 17.50, Actual: 30.00\n",
      "Predicted: 3.57, Actual: 0.00\n",
      "Predicted: 5.18, Actual: 0.00\n",
      "Predicted: 9.95, Actual: 0.00\n",
      "Predicted: 7.30, Actual: 29.00\n",
      "Predicted: 3.18, Actual: 0.00\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 14.14, Actual: 20.00\n",
      "Predicted: 1.28, Actual: 0.00\n",
      "Predicted: 3.44, Actual: 0.00\n",
      "Predicted: 5.89, Actual: 0.00\n",
      "Predicted: 3.23, Actual: 0.00\n",
      "Predicted: 7.42, Actual: 0.00\n",
      "Predicted: 4.48, Actual: 0.00\n",
      "Predicted: 10.76, Actual: 11.00\n",
      "Predicted: 12.20, Actual: 3.00\n",
      "Average loss on the testing dataset: 7.2098\n",
      "Predicted: 9.42, Actual: 0.00\n",
      "Predicted: 1.95, Actual: 0.00\n",
      "Predicted: 14.43, Actual: 9.00\n",
      "Predicted: 2.50, Actual: 0.00\n",
      "Predicted: 6.89, Actual: 22.00\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "Predicted: 9.36, Actual: 26.00\n",
      "Predicted: 13.65, Actual: 18.00\n",
      "Predicted: 14.15, Actual: 0.00\n",
      "Predicted: 4.53, Actual: 0.00\n",
      "Predicted: 4.59, Actual: 0.00\n",
      "Predicted: 8.43, Actual: 0.00\n",
      "Predicted: 2.31, Actual: 0.00\n",
      "Predicted: 6.22, Actual: 0.00\n",
      "Predicted: 5.30, Actual: 0.00\n",
      "Predicted: 6.86, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2131\n",
      "Predicted: 17.71, Actual: 20.00\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "Predicted: 6.58, Actual: 19.00\n",
      "Predicted: 4.01, Actual: 0.00\n",
      "Predicted: 13.62, Actual: 27.00\n",
      "Predicted: 20.83, Actual: 28.00\n",
      "Predicted: 17.13, Actual: 4.00\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "Predicted: 2.13, Actual: 0.00\n",
      "Predicted: 8.38, Actual: 0.00\n",
      "Predicted: 6.56, Actual: 20.00\n",
      "Predicted: 2.93, Actual: 0.00\n",
      "Predicted: 9.72, Actual: 0.00\n",
      "Predicted: 6.41, Actual: 0.00\n",
      "Predicted: 14.12, Actual: 1.00\n",
      "Predicted: 17.66, Actual: 24.00\n",
      "Average loss on the testing dataset: 7.2240\n",
      "Predicted: 4.92, Actual: 28.00\n",
      "Predicted: 12.41, Actual: 17.00\n",
      "Predicted: 13.68, Actual: 15.00\n",
      "Predicted: 1.87, Actual: 0.00\n",
      "Predicted: 9.95, Actual: 26.00\n",
      "Predicted: 4.02, Actual: 0.00\n",
      "Predicted: 17.89, Actual: 15.00\n",
      "Predicted: 3.40, Actual: 28.00\n",
      "Predicted: 5.15, Actual: 0.00\n",
      "Predicted: 2.82, Actual: 6.00\n",
      "Predicted: 2.29, Actual: 0.00\n",
      "Predicted: 5.15, Actual: 0.00\n",
      "Predicted: 13.68, Actual: 24.00\n",
      "Predicted: 1.51, Actual: 0.00\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "Predicted: 2.00, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2646\n",
      "Predicted: 14.24, Actual: 7.00\n",
      "Predicted: 6.48, Actual: 0.00\n",
      "Predicted: 10.89, Actual: 20.00\n",
      "Predicted: 5.64, Actual: 0.00\n",
      "Predicted: 12.70, Actual: 15.00\n",
      "Predicted: 5.64, Actual: 0.00\n",
      "Predicted: 4.96, Actual: 0.00\n",
      "Predicted: 9.33, Actual: 10.00\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "Predicted: 2.50, Actual: 7.00\n",
      "Predicted: 2.65, Actual: 0.00\n",
      "Predicted: 8.23, Actual: 0.00\n",
      "Predicted: 6.86, Actual: 0.00\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "Predicted: 2.80, Actual: 0.00\n",
      "Predicted: 7.26, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.2258\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "Predicted: 2.55, Actual: 0.00\n",
      "Predicted: 3.52, Actual: 0.00\n",
      "Predicted: 4.69, Actual: 1.00\n",
      "Predicted: 7.99, Actual: 0.00\n",
      "Predicted: 18.56, Actual: 21.00\n",
      "Predicted: 17.34, Actual: 24.00\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "Predicted: 19.96, Actual: 24.00\n",
      "Predicted: 5.02, Actual: 0.00\n",
      "Predicted: 3.01, Actual: 0.00\n",
      "Predicted: 3.16, Actual: 0.00\n",
      "Predicted: 14.90, Actual: 3.00\n",
      "Predicted: 3.84, Actual: 0.00\n",
      "Predicted: 13.85, Actual: 4.00\n",
      "Predicted: 7.23, Actual: 8.00\n",
      "Average loss on the testing dataset: 7.1868\n",
      "Predicted: 5.33, Actual: 16.00\n",
      "Predicted: 3.89, Actual: 0.00\n",
      "Predicted: 5.12, Actual: 0.00\n",
      "Predicted: 19.77, Actual: 14.00\n",
      "Predicted: 17.36, Actual: 23.00\n",
      "Predicted: 5.26, Actual: 0.00\n",
      "Predicted: 7.82, Actual: 2.00\n",
      "Predicted: 15.97, Actual: 17.00\n",
      "Predicted: 4.67, Actual: 0.00\n",
      "Predicted: 3.03, Actual: 0.00\n",
      "Predicted: 1.99, Actual: 0.00\n",
      "Predicted: 6.43, Actual: 0.00\n",
      "Predicted: 3.67, Actual: 0.00\n",
      "Predicted: 5.77, Actual: 0.00\n",
      "Predicted: 12.09, Actual: 18.00\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.1474\n",
      "Predicted: 6.85, Actual: 0.00\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "Predicted: 2.37, Actual: 0.00\n",
      "Predicted: 4.98, Actual: 0.00\n",
      "Predicted: 2.40, Actual: 0.00\n",
      "Predicted: 17.37, Actual: 19.00\n",
      "Predicted: 11.86, Actual: 21.00\n",
      "Predicted: 6.92, Actual: 9.00\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 0.88, Actual: 0.00\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "Predicted: 2.08, Actual: 0.00\n",
      "Predicted: 3.13, Actual: 0.00\n",
      "Predicted: 2.90, Actual: 0.00\n",
      "Predicted: 6.76, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0960\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "Predicted: 9.77, Actual: 0.00\n",
      "Predicted: 12.65, Actual: 20.00\n",
      "Predicted: 7.83, Actual: 0.00\n",
      "Predicted: 3.15, Actual: 0.00\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "Predicted: 14.01, Actual: 17.00\n",
      "Predicted: 5.45, Actual: 20.00\n",
      "Predicted: 5.73, Actual: 0.00\n",
      "Predicted: 8.80, Actual: 9.00\n",
      "Predicted: 1.66, Actual: 0.00\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "Predicted: 8.73, Actual: 0.00\n",
      "Predicted: 2.15, Actual: 0.00\n",
      "Predicted: 3.81, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0668\n",
      "Predicted: 4.91, Actual: 0.00\n",
      "Predicted: 19.07, Actual: 25.00\n",
      "Predicted: 18.36, Actual: 5.00\n",
      "Predicted: 3.31, Actual: 0.00\n",
      "Predicted: 6.50, Actual: 0.00\n",
      "Predicted: 6.58, Actual: 26.00\n",
      "Predicted: 11.84, Actual: 16.00\n",
      "Predicted: 14.97, Actual: 3.00\n",
      "Predicted: 12.47, Actual: 12.00\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "Predicted: 6.26, Actual: 0.00\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "Predicted: 2.55, Actual: 0.00\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "Predicted: 5.35, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0611\n",
      "Predicted: 10.98, Actual: 4.00\n",
      "Predicted: 4.29, Actual: 0.00\n",
      "Predicted: 5.15, Actual: 0.00\n",
      "Predicted: 17.32, Actual: 17.00\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "Predicted: 2.30, Actual: 0.00\n",
      "Predicted: 4.13, Actual: 0.00\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "Predicted: 4.34, Actual: 0.00\n",
      "Predicted: 4.44, Actual: 0.00\n",
      "Predicted: 6.24, Actual: 18.00\n",
      "Predicted: 13.00, Actual: 9.00\n",
      "Predicted: 16.07, Actual: 22.00\n",
      "Predicted: 15.30, Actual: 10.00\n",
      "Predicted: 15.66, Actual: 12.00\n",
      "Predicted: 3.03, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0212\n",
      "Predicted: 16.50, Actual: 24.00\n",
      "Predicted: 17.06, Actual: 0.00\n",
      "Predicted: 15.61, Actual: 23.00\n",
      "Predicted: 15.21, Actual: 12.00\n",
      "Predicted: 17.08, Actual: 26.00\n",
      "Predicted: 1.04, Actual: 0.00\n",
      "Predicted: 2.35, Actual: 0.00\n",
      "Predicted: 2.81, Actual: 0.00\n",
      "Predicted: 12.66, Actual: 20.00\n",
      "Predicted: 19.17, Actual: 22.00\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "Predicted: 6.41, Actual: 29.00\n",
      "Predicted: 2.30, Actual: 0.00\n",
      "Predicted: 3.51, Actual: 0.00\n",
      "Predicted: 2.26, Actual: 0.00\n",
      "Predicted: 7.21, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0303\n",
      "Predicted: 9.95, Actual: 0.00\n",
      "Predicted: 15.92, Actual: 12.00\n",
      "Predicted: 8.40, Actual: 0.00\n",
      "Predicted: 6.11, Actual: 9.00\n",
      "Predicted: 6.31, Actual: 26.00\n",
      "Predicted: 8.79, Actual: 1.00\n",
      "Predicted: 4.16, Actual: 0.00\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "Predicted: 2.96, Actual: 0.00\n",
      "Predicted: 5.88, Actual: 16.00\n",
      "Predicted: 9.92, Actual: 17.00\n",
      "Predicted: 7.05, Actual: 0.00\n",
      "Predicted: 10.56, Actual: 15.00\n",
      "Predicted: 5.31, Actual: 0.00\n",
      "Predicted: 13.11, Actual: 11.00\n",
      "Predicted: 11.56, Actual: 4.00\n",
      "Average loss on the testing dataset: 7.0283\n",
      "Predicted: 8.34, Actual: 0.00\n",
      "Predicted: 5.97, Actual: 0.00\n",
      "Predicted: 14.49, Actual: 8.00\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "Predicted: 11.62, Actual: 5.00\n",
      "Predicted: 11.98, Actual: 1.00\n",
      "Predicted: 7.34, Actual: 0.00\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 17.68, Actual: 6.00\n",
      "Predicted: 13.51, Actual: 11.00\n",
      "Predicted: 13.08, Actual: 6.00\n",
      "Predicted: 2.55, Actual: 0.00\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "Predicted: 11.16, Actual: 30.00\n",
      "Predicted: 3.61, Actual: 0.00\n",
      "Predicted: 2.61, Actual: 0.00\n",
      "Average loss on the testing dataset: 7.0251\n",
      "Predicted: 13.22, Actual: 26.00\n",
      "Predicted: 13.11, Actual: 5.00\n",
      "Predicted: 11.19, Actual: 1.00\n",
      "Predicted: 10.32, Actual: 16.00\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "Predicted: 12.72, Actual: 19.00\n",
      "Predicted: 2.30, Actual: 0.00\n",
      "Predicted: 14.61, Actual: 14.00\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "Predicted: 3.37, Actual: 0.00\n",
      "Predicted: 12.15, Actual: 9.00\n",
      "Predicted: 4.47, Actual: 0.00\n",
      "Predicted: 16.81, Actual: 4.00\n",
      "Predicted: 15.19, Actual: 2.00\n",
      "Average loss on the testing dataset: 7.0124\n",
      "Predicted: 11.93, Actual: 2.00\n",
      "Predicted: 13.78, Actual: 10.00\n",
      "Predicted: 3.00, Actual: 0.00\n",
      "Predicted: 13.46, Actual: 2.00\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "Predicted: 12.58, Actual: 20.00\n",
      "Predicted: 19.19, Actual: 25.00\n",
      "Predicted: 7.46, Actual: 19.00\n",
      "Predicted: 9.42, Actual: 11.00\n",
      "Predicted: 4.63, Actual: 0.00\n",
      "Predicted: 4.50, Actual: 0.00\n",
      "Predicted: 1.25, Actual: 0.00\n",
      "Predicted: 5.02, Actual: 16.00\n",
      "Predicted: 11.17, Actual: 9.00\n",
      "Predicted: 8.28, Actual: 0.00\n",
      "Predicted: 5.94, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9967\n",
      "Predicted: 2.86, Actual: 0.00\n",
      "Predicted: 19.28, Actual: 3.00\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "Predicted: 12.46, Actual: 8.00\n",
      "Predicted: 8.38, Actual: 0.00\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "Predicted: 3.26, Actual: 0.00\n",
      "Predicted: 2.43, Actual: 0.00\n",
      "Predicted: 13.47, Actual: 5.00\n",
      "Predicted: 13.75, Actual: 14.00\n",
      "Predicted: 15.30, Actual: 15.00\n",
      "Predicted: 10.18, Actual: 0.00\n",
      "Predicted: 15.81, Actual: 2.00\n",
      "Predicted: 4.12, Actual: 0.00\n",
      "Predicted: 4.48, Actual: 20.00\n",
      "Average loss on the testing dataset: 6.9973\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "Predicted: 8.92, Actual: 0.00\n",
      "Predicted: 5.08, Actual: 0.00\n",
      "Predicted: 10.15, Actual: 14.00\n",
      "Predicted: 13.27, Actual: 7.00\n",
      "Predicted: 20.33, Actual: 12.00\n",
      "Predicted: 8.67, Actual: 0.00\n",
      "Predicted: 14.76, Actual: 21.00\n",
      "Predicted: 19.94, Actual: 23.00\n",
      "Predicted: 4.54, Actual: 0.00\n",
      "Predicted: 4.26, Actual: 0.00\n",
      "Predicted: 6.09, Actual: 0.00\n",
      "Predicted: 14.95, Actual: 14.00\n",
      "Predicted: 15.04, Actual: 18.00\n",
      "Predicted: 15.35, Actual: 12.00\n",
      "Predicted: 4.47, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9650\n",
      "Predicted: 9.86, Actual: 9.00\n",
      "Predicted: 4.32, Actual: 0.00\n",
      "Predicted: 4.40, Actual: 0.00\n",
      "Predicted: 2.60, Actual: 0.00\n",
      "Predicted: 10.40, Actual: 0.00\n",
      "Predicted: 14.47, Actual: 9.00\n",
      "Predicted: 12.77, Actual: 12.00\n",
      "Predicted: 6.62, Actual: 0.00\n",
      "Predicted: 14.39, Actual: 25.00\n",
      "Predicted: 1.27, Actual: 0.00\n",
      "Predicted: 10.76, Actual: 1.00\n",
      "Predicted: 10.92, Actual: 10.00\n",
      "Predicted: 6.49, Actual: 0.00\n",
      "Predicted: 7.38, Actual: 13.00\n",
      "Predicted: 6.48, Actual: 0.00\n",
      "Predicted: 4.79, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9395\n",
      "Predicted: 12.68, Actual: 8.00\n",
      "Predicted: 12.26, Actual: 27.00\n",
      "Predicted: 11.17, Actual: 11.00\n",
      "Predicted: 6.33, Actual: 0.00\n",
      "Predicted: 4.52, Actual: 0.00\n",
      "Predicted: 10.40, Actual: 0.00\n",
      "Predicted: 2.61, Actual: 0.00\n",
      "Predicted: 18.76, Actual: 3.00\n",
      "Predicted: 17.44, Actual: 23.00\n",
      "Predicted: 2.18, Actual: 0.00\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "Predicted: 4.77, Actual: 0.00\n",
      "Predicted: 2.23, Actual: 0.00\n",
      "Predicted: 6.80, Actual: 12.00\n",
      "Predicted: 8.87, Actual: 0.00\n",
      "Predicted: 0.66, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9299\n",
      "Predicted: 14.77, Actual: 17.00\n",
      "Predicted: 2.85, Actual: 0.00\n",
      "Predicted: 6.47, Actual: 14.00\n",
      "Predicted: 5.19, Actual: 0.00\n",
      "Predicted: 9.12, Actual: 29.00\n",
      "Predicted: 1.75, Actual: 0.00\n",
      "Predicted: 13.77, Actual: 13.00\n",
      "Predicted: 2.41, Actual: 0.00\n",
      "Predicted: 0.66, Actual: 0.00\n",
      "Predicted: 6.13, Actual: 0.00\n",
      "Predicted: 12.45, Actual: 10.00\n",
      "Predicted: 2.62, Actual: 0.00\n",
      "Predicted: 8.15, Actual: 8.00\n",
      "Predicted: 13.61, Actual: 8.00\n",
      "Predicted: 4.83, Actual: 0.00\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9069\n",
      "Predicted: 14.52, Actual: 10.00\n",
      "Predicted: 12.83, Actual: 11.00\n",
      "Predicted: 5.17, Actual: 0.00\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "Predicted: 14.13, Actual: 23.00\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "Predicted: 15.59, Actual: 7.00\n",
      "Predicted: 8.74, Actual: 6.00\n",
      "Predicted: 4.31, Actual: 0.00\n",
      "Predicted: 16.21, Actual: 25.00\n",
      "Predicted: 4.53, Actual: 23.00\n",
      "Predicted: 10.46, Actual: 25.00\n",
      "Predicted: 6.79, Actual: 21.00\n",
      "Predicted: 6.17, Actual: 0.00\n",
      "Predicted: 14.76, Actual: 1.00\n",
      "Predicted: 2.08, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9245\n",
      "Predicted: 4.76, Actual: 0.00\n",
      "Predicted: 13.56, Actual: 23.00\n",
      "Predicted: 7.58, Actual: 0.00\n",
      "Predicted: 11.78, Actual: 29.00\n",
      "Predicted: 7.70, Actual: 12.00\n",
      "Predicted: 16.96, Actual: 13.00\n",
      "Predicted: 7.08, Actual: 0.00\n",
      "Predicted: 5.96, Actual: 0.00\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "Predicted: 4.26, Actual: 0.00\n",
      "Predicted: 9.70, Actual: 18.00\n",
      "Predicted: 15.03, Actual: 13.00\n",
      "Predicted: 14.08, Actual: 17.00\n",
      "Predicted: 19.21, Actual: 6.00\n",
      "Predicted: 11.26, Actual: 18.00\n",
      "Predicted: 8.31, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9232\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "Predicted: 7.78, Actual: 0.00\n",
      "Predicted: 3.58, Actual: 0.00\n",
      "Predicted: 3.64, Actual: 0.00\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "Predicted: 3.57, Actual: 0.00\n",
      "Predicted: 1.79, Actual: 0.00\n",
      "Predicted: 11.94, Actual: 4.00\n",
      "Predicted: 9.21, Actual: 8.00\n",
      "Predicted: 4.59, Actual: 0.00\n",
      "Predicted: 16.90, Actual: 11.00\n",
      "Predicted: 4.89, Actual: 4.00\n",
      "Predicted: 19.16, Actual: 25.00\n",
      "Predicted: 12.18, Actual: 25.00\n",
      "Predicted: 14.07, Actual: 3.00\n",
      "Predicted: 4.96, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9005\n",
      "Predicted: 8.28, Actual: 0.00\n",
      "Predicted: 12.91, Actual: 10.00\n",
      "Predicted: 16.57, Actual: 15.00\n",
      "Predicted: 15.77, Actual: 3.00\n",
      "Predicted: 14.52, Actual: 2.00\n",
      "Predicted: 5.14, Actual: 0.00\n",
      "Predicted: 4.95, Actual: 0.00\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "Predicted: 0.76, Actual: 0.00\n",
      "Predicted: 6.13, Actual: 0.00\n",
      "Predicted: 8.67, Actual: 29.00\n",
      "Predicted: 4.34, Actual: 0.00\n",
      "Predicted: 5.84, Actual: 0.00\n",
      "Predicted: 2.48, Actual: 0.00\n",
      "Predicted: 10.87, Actual: 0.00\n",
      "Predicted: 4.08, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.9065\n",
      "Predicted: 9.58, Actual: 20.00\n",
      "Predicted: 12.85, Actual: 1.00\n",
      "Predicted: 1.00, Actual: 0.00\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "Predicted: 1.90, Actual: 0.00\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "Predicted: 3.26, Actual: 0.00\n",
      "Predicted: 12.63, Actual: 19.00\n",
      "Predicted: 4.24, Actual: 0.00\n",
      "Predicted: 1.95, Actual: 0.00\n",
      "Predicted: 14.52, Actual: 20.00\n",
      "Predicted: 1.27, Actual: 0.00\n",
      "Predicted: 16.55, Actual: 8.00\n",
      "Predicted: 13.23, Actual: 16.00\n",
      "Predicted: 4.43, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.8768\n",
      "Predicted: 5.86, Actual: 0.00\n",
      "Predicted: 12.27, Actual: 0.00\n",
      "Predicted: 2.42, Actual: 0.00\n",
      "Predicted: 14.51, Actual: 27.00\n",
      "Predicted: 12.99, Actual: 13.00\n",
      "Predicted: 5.97, Actual: 21.00\n",
      "Predicted: 11.49, Actual: 24.00\n",
      "Predicted: 13.58, Actual: 15.00\n",
      "Predicted: 6.10, Actual: 0.00\n",
      "Predicted: 19.15, Actual: 5.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 18.99, Actual: 5.00\n",
      "Predicted: 1.88, Actual: 0.00\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "Predicted: 1.64, Actual: 0.00\n",
      "Predicted: 19.65, Actual: 22.00\n",
      "Average loss on the testing dataset: 6.8874\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "Predicted: 12.55, Actual: 0.00\n",
      "Predicted: 3.18, Actual: 0.00\n",
      "Predicted: 8.38, Actual: 17.00\n",
      "Predicted: 9.25, Actual: 1.00\n",
      "Predicted: 11.52, Actual: 10.00\n",
      "Predicted: 10.50, Actual: 22.00\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "Predicted: 4.13, Actual: 0.00\n",
      "Predicted: 6.98, Actual: 0.00\n",
      "Predicted: 17.62, Actual: 15.00\n",
      "Predicted: 4.14, Actual: 0.00\n",
      "Predicted: 7.34, Actual: 0.00\n",
      "Predicted: 17.51, Actual: 9.00\n",
      "Predicted: 8.46, Actual: 0.00\n",
      "Predicted: 3.84, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.8753\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    # Iterate through the testing data loader\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        for idx, test_inputs in enumerate(inputs):\n",
    "            outputs = model(test_inputs)\n",
    "            # Optionally calculate the loss (if you want to evaluate performance)\n",
    "            loss = loss_fn(outputs.squeeze(), targets[idx])\n",
    "            \n",
    "            # Accumulate the loss\n",
    "            total_loss += loss.item()\n",
    "            num_samples += 1\n",
    "            \n",
    "            # Print the predictions and the actual targets\n",
    "            print(f\"Predicted: {outputs.item()*30:.2f}, Actual: {targets[idx].item()*30:.2f}\")\n",
    "    \n",
    "    # Calculate the average loss\n",
    "        avg_loss = total_loss / num_samples\n",
    "        print(f\"Average loss on the testing dataset: {avg_loss*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5819331-a239-44b0-9924-aad6c7eff8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model/model1TopBotomData10000-25.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559abe-fd2b-41f6-b012-2e4203d1e785",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "- Dataset used here is a dummy data with if top level more then 70 then predition should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b504e5b1-6767-450c-986d-4d478e6d1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2NN, self).__init__()\n",
    "        self.layer = nn.Linear(4, 10)\n",
    "        self.layer2 = nn.Linear(10, 10)\n",
    "        self.layer3 = nn.Linear(10,1)\n",
    "        self.activation = nn.Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = torch.relu(self.layer(X))\n",
    "        X=torch.relu(self.layer2(X))\n",
    "        X=self.layer3(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "\n",
    "# Instantiate the model\n",
    "model1 = Model2NN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec95365-f70c-4810-8420-5ef013c2ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e1fcce-f5b8-41d8-abb7-843b5d50bb08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 17.111504\n",
      "Epoch [2/250], Loss: 15.124679\n",
      "Epoch [3/250], Loss: 9.205971\n",
      "Epoch [4/250], Loss: 13.209859\n",
      "Epoch [5/250], Loss: 14.791776\n",
      "Epoch [6/250], Loss: 13.766974\n",
      "Epoch [7/250], Loss: 15.676764\n",
      "Epoch [8/250], Loss: 10.609420\n",
      "Epoch [9/250], Loss: 10.169192\n",
      "Epoch [10/250], Loss: 14.231463\n",
      "Epoch [11/250], Loss: 12.503614\n",
      "Epoch [12/250], Loss: 12.468126\n",
      "Epoch [13/250], Loss: 10.061267\n",
      "Epoch [14/250], Loss: 11.009903\n",
      "Epoch [15/250], Loss: 12.676449\n",
      "Epoch [16/250], Loss: 7.211148\n",
      "Epoch [17/250], Loss: 8.209468\n",
      "Epoch [18/250], Loss: 7.626436\n",
      "Epoch [19/250], Loss: 12.379772\n",
      "Epoch [20/250], Loss: 8.663177\n",
      "Epoch [21/250], Loss: 6.797534\n",
      "Epoch [22/250], Loss: 12.201913\n",
      "Epoch [23/250], Loss: 13.040495\n",
      "Epoch [24/250], Loss: 16.003433\n",
      "Epoch [25/250], Loss: 9.615223\n",
      "Epoch [26/250], Loss: 12.931551\n",
      "Epoch [27/250], Loss: 11.006681\n",
      "Epoch [28/250], Loss: 13.974191\n",
      "Epoch [29/250], Loss: 14.331345\n",
      "Epoch [30/250], Loss: 8.091088\n",
      "Epoch [31/250], Loss: 13.598169\n",
      "Epoch [32/250], Loss: 15.901436\n",
      "Epoch [33/250], Loss: 10.957330\n",
      "Epoch [34/250], Loss: 14.002992\n",
      "Epoch [35/250], Loss: 9.547993\n",
      "Epoch [36/250], Loss: 6.684363\n",
      "Epoch [37/250], Loss: 12.142710\n",
      "Epoch [38/250], Loss: 8.478925\n",
      "Epoch [39/250], Loss: 10.308976\n",
      "Epoch [40/250], Loss: 8.160169\n",
      "Epoch [41/250], Loss: 9.408241\n",
      "Epoch [42/250], Loss: 7.377728\n",
      "Epoch [43/250], Loss: 8.491535\n",
      "Epoch [44/250], Loss: 14.889738\n",
      "Epoch [45/250], Loss: 9.210835\n",
      "Epoch [46/250], Loss: 8.962808\n",
      "Epoch [47/250], Loss: 9.513088\n",
      "Epoch [48/250], Loss: 9.160877\n",
      "Epoch [49/250], Loss: 8.277655\n",
      "Epoch [50/250], Loss: 9.287096\n",
      "Epoch [51/250], Loss: 13.116977\n",
      "Epoch [52/250], Loss: 8.644539\n",
      "Epoch [53/250], Loss: 7.045012\n",
      "Epoch [54/250], Loss: 10.891278\n",
      "Epoch [55/250], Loss: 7.792434\n",
      "Epoch [56/250], Loss: 8.067414\n",
      "Epoch [57/250], Loss: 14.571214\n",
      "Epoch [58/250], Loss: 6.390207\n",
      "Epoch [59/250], Loss: 8.387671\n",
      "Epoch [60/250], Loss: 9.694652\n",
      "Epoch [61/250], Loss: 14.712280\n",
      "Epoch [62/250], Loss: 10.685118\n",
      "Epoch [63/250], Loss: 6.324778\n",
      "Epoch [64/250], Loss: 7.331076\n",
      "Epoch [65/250], Loss: 6.517123\n",
      "Epoch [66/250], Loss: 8.490054\n",
      "Epoch [67/250], Loss: 8.991814\n",
      "Epoch [68/250], Loss: 9.593388\n",
      "Epoch [69/250], Loss: 14.429510\n",
      "Epoch [70/250], Loss: 12.042699\n",
      "Epoch [71/250], Loss: 11.109651\n",
      "Epoch [72/250], Loss: 8.857007\n",
      "Epoch [73/250], Loss: 6.903327\n",
      "Epoch [74/250], Loss: 7.101797\n",
      "Epoch [75/250], Loss: 5.721230\n",
      "Epoch [76/250], Loss: 8.058406\n",
      "Epoch [77/250], Loss: 14.764233\n",
      "Epoch [78/250], Loss: 6.716461\n",
      "Epoch [79/250], Loss: 11.890550\n",
      "Epoch [80/250], Loss: 12.924215\n",
      "Epoch [81/250], Loss: 10.666528\n",
      "Epoch [82/250], Loss: 10.912777\n",
      "Epoch [83/250], Loss: 3.976791\n",
      "Epoch [84/250], Loss: 8.632525\n",
      "Epoch [85/250], Loss: 13.445458\n",
      "Epoch [86/250], Loss: 10.543300\n",
      "Epoch [87/250], Loss: 7.898638\n",
      "Epoch [88/250], Loss: 9.505720\n",
      "Epoch [89/250], Loss: 9.351049\n",
      "Epoch [90/250], Loss: 12.508607\n",
      "Epoch [91/250], Loss: 8.869949\n",
      "Epoch [92/250], Loss: 9.056988\n",
      "Epoch [93/250], Loss: 14.286534\n",
      "Epoch [94/250], Loss: 6.227027\n",
      "Epoch [95/250], Loss: 6.243939\n",
      "Epoch [96/250], Loss: 7.252303\n",
      "Epoch [97/250], Loss: 15.905432\n",
      "Epoch [98/250], Loss: 10.486877\n",
      "Epoch [99/250], Loss: 8.370873\n",
      "Epoch [100/250], Loss: 12.075604\n",
      "Epoch [101/250], Loss: 8.122587\n",
      "Epoch [102/250], Loss: 14.140609\n",
      "Epoch [103/250], Loss: 16.550061\n",
      "Epoch [104/250], Loss: 9.792908\n",
      "Epoch [105/250], Loss: 20.021512\n",
      "Epoch [106/250], Loss: 12.114491\n",
      "Epoch [107/250], Loss: 8.282553\n",
      "Epoch [108/250], Loss: 13.753824\n",
      "Epoch [109/250], Loss: 17.800863\n",
      "Epoch [110/250], Loss: 10.987055\n",
      "Epoch [111/250], Loss: 12.067305\n",
      "Epoch [112/250], Loss: 10.563108\n",
      "Epoch [113/250], Loss: 11.725730\n",
      "Epoch [114/250], Loss: 5.613486\n",
      "Epoch [115/250], Loss: 16.032043\n",
      "Epoch [116/250], Loss: 9.455953\n",
      "Epoch [117/250], Loss: 11.196961\n",
      "Epoch [118/250], Loss: 11.652444\n",
      "Epoch [119/250], Loss: 9.133564\n",
      "Epoch [120/250], Loss: 8.501766\n",
      "Epoch [121/250], Loss: 16.272232\n",
      "Epoch [122/250], Loss: 10.038611\n",
      "Epoch [123/250], Loss: 8.364333\n",
      "Epoch [124/250], Loss: 5.326213\n",
      "Epoch [125/250], Loss: 5.825638\n",
      "Epoch [126/250], Loss: 9.283081\n",
      "Epoch [127/250], Loss: 5.228452\n",
      "Epoch [128/250], Loss: 8.303294\n",
      "Epoch [129/250], Loss: 8.973558\n",
      "Epoch [130/250], Loss: 8.279029\n",
      "Epoch [131/250], Loss: 7.510264\n",
      "Epoch [132/250], Loss: 15.172791\n",
      "Epoch [133/250], Loss: 9.283774\n",
      "Epoch [134/250], Loss: 8.215669\n",
      "Epoch [135/250], Loss: 6.482524\n",
      "Epoch [136/250], Loss: 13.655357\n",
      "Epoch [137/250], Loss: 12.298494\n",
      "Epoch [138/250], Loss: 8.728327\n",
      "Epoch [139/250], Loss: 10.886535\n",
      "Epoch [140/250], Loss: 21.682310\n",
      "Epoch [141/250], Loss: 14.346290\n",
      "Epoch [142/250], Loss: 11.906940\n",
      "Epoch [143/250], Loss: 15.035920\n",
      "Epoch [144/250], Loss: 7.787964\n",
      "Epoch [145/250], Loss: 7.448152\n",
      "Epoch [146/250], Loss: 10.156684\n",
      "Epoch [147/250], Loss: 7.584196\n",
      "Epoch [148/250], Loss: 13.994275\n",
      "Epoch [149/250], Loss: 11.839829\n",
      "Epoch [150/250], Loss: 11.907379\n",
      "Epoch [151/250], Loss: 4.627324\n",
      "Epoch [152/250], Loss: 14.643489\n",
      "Epoch [153/250], Loss: 7.149239\n",
      "Epoch [154/250], Loss: 11.785836\n",
      "Epoch [155/250], Loss: 12.172427\n",
      "Epoch [156/250], Loss: 10.417467\n",
      "Epoch [157/250], Loss: 9.012811\n",
      "Epoch [158/250], Loss: 10.949356\n",
      "Epoch [159/250], Loss: 13.854797\n",
      "Epoch [160/250], Loss: 10.089104\n",
      "Epoch [161/250], Loss: 8.824480\n",
      "Epoch [162/250], Loss: 4.307126\n",
      "Epoch [163/250], Loss: 7.317834\n",
      "Epoch [164/250], Loss: 12.143014\n",
      "Epoch [165/250], Loss: 11.658056\n",
      "Epoch [166/250], Loss: 8.894879\n",
      "Epoch [167/250], Loss: 7.956166\n",
      "Epoch [168/250], Loss: 14.979209\n",
      "Epoch [169/250], Loss: 7.504976\n",
      "Epoch [170/250], Loss: 14.749837\n",
      "Epoch [171/250], Loss: 15.904224\n",
      "Epoch [172/250], Loss: 10.729367\n",
      "Epoch [173/250], Loss: 19.250037\n",
      "Epoch [174/250], Loss: 8.011843\n",
      "Epoch [175/250], Loss: 17.243889\n",
      "Epoch [176/250], Loss: 14.644170\n",
      "Epoch [177/250], Loss: 10.935050\n",
      "Epoch [178/250], Loss: 10.571061\n",
      "Epoch [179/250], Loss: 5.305639\n",
      "Epoch [180/250], Loss: 5.572319\n",
      "Epoch [181/250], Loss: 8.796625\n",
      "Epoch [182/250], Loss: 10.611695\n",
      "Epoch [183/250], Loss: 9.231940\n",
      "Epoch [184/250], Loss: 12.334508\n",
      "Epoch [185/250], Loss: 10.989914\n",
      "Epoch [186/250], Loss: 11.300114\n",
      "Epoch [187/250], Loss: 5.250999\n",
      "Epoch [188/250], Loss: 11.080799\n",
      "Epoch [189/250], Loss: 10.556172\n",
      "Epoch [190/250], Loss: 11.323360\n",
      "Epoch [191/250], Loss: 9.018032\n",
      "Epoch [192/250], Loss: 7.845104\n",
      "Epoch [193/250], Loss: 7.659631\n",
      "Epoch [194/250], Loss: 12.291847\n",
      "Epoch [195/250], Loss: 9.187396\n",
      "Epoch [196/250], Loss: 18.772617\n",
      "Epoch [197/250], Loss: 10.652652\n",
      "Epoch [198/250], Loss: 14.214580\n",
      "Epoch [199/250], Loss: 6.760111\n",
      "Epoch [200/250], Loss: 3.721333\n",
      "Epoch [201/250], Loss: 12.688997\n",
      "Epoch [202/250], Loss: 6.484578\n",
      "Epoch [203/250], Loss: 14.157142\n",
      "Epoch [204/250], Loss: 9.263814\n",
      "Epoch [205/250], Loss: 7.760023\n",
      "Epoch [206/250], Loss: 6.909879\n",
      "Epoch [207/250], Loss: 15.149260\n",
      "Epoch [208/250], Loss: 13.381456\n",
      "Epoch [209/250], Loss: 6.882177\n",
      "Epoch [210/250], Loss: 10.672604\n",
      "Epoch [211/250], Loss: 17.168975\n",
      "Epoch [212/250], Loss: 10.235814\n",
      "Epoch [213/250], Loss: 14.687642\n",
      "Epoch [214/250], Loss: 6.245823\n",
      "Epoch [215/250], Loss: 17.105086\n",
      "Epoch [216/250], Loss: 9.737694\n",
      "Epoch [217/250], Loss: 5.987877\n",
      "Epoch [218/250], Loss: 8.198927\n",
      "Epoch [219/250], Loss: 10.094578\n",
      "Epoch [220/250], Loss: 16.160011\n",
      "Epoch [221/250], Loss: 8.851449\n",
      "Epoch [222/250], Loss: 16.122749\n",
      "Epoch [223/250], Loss: 8.749419\n",
      "Epoch [224/250], Loss: 9.415171\n",
      "Epoch [225/250], Loss: 11.995007\n",
      "Epoch [226/250], Loss: 7.938051\n",
      "Epoch [227/250], Loss: 15.361056\n",
      "Epoch [228/250], Loss: 7.054975\n",
      "Epoch [229/250], Loss: 12.527944\n",
      "Epoch [230/250], Loss: 7.846415\n",
      "Epoch [231/250], Loss: 9.733135\n",
      "Epoch [232/250], Loss: 11.261270\n",
      "Epoch [233/250], Loss: 7.136404\n",
      "Epoch [234/250], Loss: 10.884839\n",
      "Epoch [235/250], Loss: 10.230938\n",
      "Epoch [236/250], Loss: 9.533617\n",
      "Epoch [237/250], Loss: 10.067200\n",
      "Epoch [238/250], Loss: 7.970230\n",
      "Epoch [239/250], Loss: 9.653120\n",
      "Epoch [240/250], Loss: 8.769409\n",
      "Epoch [241/250], Loss: 9.022490\n",
      "Epoch [242/250], Loss: 7.251216\n",
      "Epoch [243/250], Loss: 7.218685\n",
      "Epoch [244/250], Loss: 8.362587\n",
      "Epoch [245/250], Loss: 12.019320\n",
      "Epoch [246/250], Loss: 7.741167\n",
      "Epoch [247/250], Loss: 15.761501\n",
      "Epoch [248/250], Loss: 13.200401\n",
      "Epoch [249/250], Loss: 10.363849\n",
      "Epoch [250/250], Loss: 8.075914\n",
      "Epoch [251/250], Loss: 10.534178\n",
      "Epoch [252/250], Loss: 13.806534\n",
      "Epoch [253/250], Loss: 17.475054\n",
      "Epoch [254/250], Loss: 13.557288\n",
      "Epoch [255/250], Loss: 13.744874\n",
      "Epoch [256/250], Loss: 6.982514\n",
      "Epoch [257/250], Loss: 15.611784\n",
      "Epoch [258/250], Loss: 9.239940\n",
      "Epoch [259/250], Loss: 10.650025\n",
      "Epoch [260/250], Loss: 5.061383\n",
      "Epoch [261/250], Loss: 5.973477\n",
      "Epoch [262/250], Loss: 7.820727\n",
      "Epoch [263/250], Loss: 16.848403\n",
      "Epoch [264/250], Loss: 7.913669\n",
      "Epoch [265/250], Loss: 12.541668\n",
      "Epoch [266/250], Loss: 9.293436\n",
      "Epoch [267/250], Loss: 10.543911\n",
      "Epoch [268/250], Loss: 14.082262\n",
      "Epoch [269/250], Loss: 8.852275\n",
      "Epoch [270/250], Loss: 10.665137\n",
      "Epoch [271/250], Loss: 9.910943\n",
      "Epoch [272/250], Loss: 12.249257\n",
      "Epoch [273/250], Loss: 13.143238\n",
      "Epoch [274/250], Loss: 13.866608\n",
      "Epoch [275/250], Loss: 6.916758\n",
      "Epoch [276/250], Loss: 10.894450\n",
      "Epoch [277/250], Loss: 8.723162\n",
      "Epoch [278/250], Loss: 9.893059\n",
      "Epoch [279/250], Loss: 10.849018\n",
      "Epoch [280/250], Loss: 11.693782\n",
      "Epoch [281/250], Loss: 6.423878\n",
      "Epoch [282/250], Loss: 13.166694\n",
      "Epoch [283/250], Loss: 14.254928\n",
      "Epoch [284/250], Loss: 14.122690\n",
      "Epoch [285/250], Loss: 6.777870\n",
      "Epoch [286/250], Loss: 8.012726\n",
      "Epoch [287/250], Loss: 10.036946\n",
      "Epoch [288/250], Loss: 10.735916\n",
      "Epoch [289/250], Loss: 10.266604\n",
      "Epoch [290/250], Loss: 9.260900\n",
      "Epoch [291/250], Loss: 10.945675\n",
      "Epoch [292/250], Loss: 12.825662\n",
      "Epoch [293/250], Loss: 15.017593\n",
      "Epoch [294/250], Loss: 16.432363\n",
      "Epoch [295/250], Loss: 7.042322\n",
      "Epoch [296/250], Loss: 14.424503\n",
      "Epoch [297/250], Loss: 5.641743\n",
      "Epoch [298/250], Loss: 9.878799\n",
      "Epoch [299/250], Loss: 12.149839\n",
      "Epoch [300/250], Loss: 13.392833\n",
      "Epoch [301/250], Loss: 10.615326\n",
      "Epoch [302/250], Loss: 10.026637\n",
      "Epoch [303/250], Loss: 7.151134\n",
      "Epoch [304/250], Loss: 16.191554\n",
      "Epoch [305/250], Loss: 9.077580\n",
      "Epoch [306/250], Loss: 11.684798\n",
      "Epoch [307/250], Loss: 10.128874\n",
      "Epoch [308/250], Loss: 9.798519\n",
      "Epoch [309/250], Loss: 15.712792\n",
      "Epoch [310/250], Loss: 10.981950\n",
      "Epoch [311/250], Loss: 13.416536\n",
      "Epoch [312/250], Loss: 13.580975\n",
      "Epoch [313/250], Loss: 11.441856\n",
      "Epoch [314/250], Loss: 14.042403\n",
      "Epoch [315/250], Loss: 8.935557\n",
      "Epoch [316/250], Loss: 13.123031\n",
      "Epoch [317/250], Loss: 6.599633\n",
      "Epoch [318/250], Loss: 9.010618\n",
      "Epoch [319/250], Loss: 6.982612\n",
      "Epoch [320/250], Loss: 9.359105\n",
      "Epoch [321/250], Loss: 11.889834\n",
      "Epoch [322/250], Loss: 6.384256\n",
      "Epoch [323/250], Loss: 6.494877\n",
      "Epoch [324/250], Loss: 8.820096\n",
      "Epoch [325/250], Loss: 14.029172\n",
      "Epoch [326/250], Loss: 7.096889\n",
      "Epoch [327/250], Loss: 9.077719\n",
      "Epoch [328/250], Loss: 12.863281\n",
      "Epoch [329/250], Loss: 15.568845\n",
      "Epoch [330/250], Loss: 7.999153\n",
      "Epoch [331/250], Loss: 10.043920\n",
      "Epoch [332/250], Loss: 7.786861\n",
      "Epoch [333/250], Loss: 8.252373\n",
      "Epoch [334/250], Loss: 9.627309\n",
      "Epoch [335/250], Loss: 7.821833\n",
      "Epoch [336/250], Loss: 7.316767\n",
      "Epoch [337/250], Loss: 6.719396\n",
      "Epoch [338/250], Loss: 8.283317\n",
      "Epoch [339/250], Loss: 11.130200\n",
      "Epoch [340/250], Loss: 4.492440\n",
      "Epoch [341/250], Loss: 12.826787\n",
      "Epoch [342/250], Loss: 7.751714\n",
      "Epoch [343/250], Loss: 16.355243\n",
      "Epoch [344/250], Loss: 9.781854\n",
      "Epoch [345/250], Loss: 10.113398\n",
      "Epoch [346/250], Loss: 5.073212\n",
      "Epoch [347/250], Loss: 23.615468\n",
      "Epoch [348/250], Loss: 11.694923\n",
      "Epoch [349/250], Loss: 6.339969\n",
      "Epoch [350/250], Loss: 9.158426\n",
      "Epoch [351/250], Loss: 10.733742\n",
      "Epoch [352/250], Loss: 4.290862\n",
      "Epoch [353/250], Loss: 7.891390\n",
      "Epoch [354/250], Loss: 8.523142\n",
      "Epoch [355/250], Loss: 8.574464\n",
      "Epoch [356/250], Loss: 9.166730\n",
      "Epoch [357/250], Loss: 10.390744\n",
      "Epoch [358/250], Loss: 7.842539\n",
      "Epoch [359/250], Loss: 8.511820\n",
      "Epoch [360/250], Loss: 11.650239\n",
      "Epoch [361/250], Loss: 8.443612\n",
      "Epoch [362/250], Loss: 12.889095\n",
      "Epoch [363/250], Loss: 6.913498\n",
      "Epoch [364/250], Loss: 4.945092\n",
      "Epoch [365/250], Loss: 9.844052\n",
      "Epoch [366/250], Loss: 10.720236\n",
      "Epoch [367/250], Loss: 8.268667\n",
      "Epoch [368/250], Loss: 6.155943\n",
      "Epoch [369/250], Loss: 9.222997\n",
      "Epoch [370/250], Loss: 9.038703\n",
      "Epoch [371/250], Loss: 12.690344\n",
      "Epoch [372/250], Loss: 6.227057\n",
      "Epoch [373/250], Loss: 6.417900\n",
      "Epoch [374/250], Loss: 9.807031\n",
      "Epoch [375/250], Loss: 8.386803\n",
      "Epoch [376/250], Loss: 7.212412\n",
      "Epoch [377/250], Loss: 6.173265\n",
      "Epoch [378/250], Loss: 7.909221\n",
      "Epoch [379/250], Loss: 9.136662\n",
      "Epoch [380/250], Loss: 9.006506\n",
      "Epoch [381/250], Loss: 8.216564\n",
      "Epoch [382/250], Loss: 5.510032\n",
      "Epoch [383/250], Loss: 5.213370\n",
      "Epoch [384/250], Loss: 3.898844\n",
      "Epoch [385/250], Loss: 10.261609\n",
      "Epoch [386/250], Loss: 8.738641\n",
      "Epoch [387/250], Loss: 11.082178\n",
      "Epoch [388/250], Loss: 4.389249\n",
      "Epoch [389/250], Loss: 9.067869\n",
      "Epoch [390/250], Loss: 6.501289\n",
      "Epoch [391/250], Loss: 5.069788\n",
      "Epoch [392/250], Loss: 11.340412\n",
      "Epoch [393/250], Loss: 11.372799\n",
      "Epoch [394/250], Loss: 8.006372\n",
      "Epoch [395/250], Loss: 9.771092\n",
      "Epoch [396/250], Loss: 9.725870\n",
      "Epoch [397/250], Loss: 16.520321\n",
      "Epoch [398/250], Loss: 8.305963\n",
      "Epoch [399/250], Loss: 5.973774\n",
      "Epoch [400/250], Loss: 12.550680\n",
      "Epoch [401/250], Loss: 9.112138\n",
      "Epoch [402/250], Loss: 12.734307\n",
      "Epoch [403/250], Loss: 6.691414\n",
      "Epoch [404/250], Loss: 4.211660\n",
      "Epoch [405/250], Loss: 2.660709\n",
      "Epoch [406/250], Loss: 13.347228\n",
      "Epoch [407/250], Loss: 4.302436\n",
      "Epoch [408/250], Loss: 4.716055\n",
      "Epoch [409/250], Loss: 6.407776\n",
      "Epoch [410/250], Loss: 12.488398\n",
      "Epoch [411/250], Loss: 4.792281\n",
      "Epoch [412/250], Loss: 8.751088\n",
      "Epoch [413/250], Loss: 7.646232\n",
      "Epoch [414/250], Loss: 3.544315\n",
      "Epoch [415/250], Loss: 9.858844\n",
      "Epoch [416/250], Loss: 6.476487\n",
      "Epoch [417/250], Loss: 6.574159\n",
      "Epoch [418/250], Loss: 5.327574\n",
      "Epoch [419/250], Loss: 9.749679\n",
      "Epoch [420/250], Loss: 5.630352\n",
      "Epoch [421/250], Loss: 9.157682\n",
      "Epoch [422/250], Loss: 8.769945\n",
      "Epoch [423/250], Loss: 4.069817\n",
      "Epoch [424/250], Loss: 5.272195\n",
      "Epoch [425/250], Loss: 4.085412\n",
      "Epoch [426/250], Loss: 9.901266\n",
      "Epoch [427/250], Loss: 7.357799\n",
      "Epoch [428/250], Loss: 7.147989\n",
      "Epoch [429/250], Loss: 4.868577\n",
      "Epoch [430/250], Loss: 11.633428\n",
      "Epoch [431/250], Loss: 4.657787\n",
      "Epoch [432/250], Loss: 7.532613\n",
      "Epoch [433/250], Loss: 8.025523\n",
      "Epoch [434/250], Loss: 6.824908\n",
      "Epoch [435/250], Loss: 8.872851\n",
      "Epoch [436/250], Loss: 7.826117\n",
      "Epoch [437/250], Loss: 11.841901\n",
      "Epoch [438/250], Loss: 5.292609\n",
      "Epoch [439/250], Loss: 6.722809\n",
      "Epoch [440/250], Loss: 7.558887\n",
      "Epoch [441/250], Loss: 14.851741\n",
      "Epoch [442/250], Loss: 3.768485\n",
      "Epoch [443/250], Loss: 8.114117\n",
      "Epoch [444/250], Loss: 7.118258\n",
      "Epoch [445/250], Loss: 5.671186\n",
      "Epoch [446/250], Loss: 11.066405\n",
      "Epoch [447/250], Loss: 3.488606\n",
      "Epoch [448/250], Loss: 6.034617\n",
      "Epoch [449/250], Loss: 10.971344\n",
      "Epoch [450/250], Loss: 5.742219\n",
      "Epoch [451/250], Loss: 6.134449\n",
      "Epoch [452/250], Loss: 6.587449\n",
      "Epoch [453/250], Loss: 8.814833\n",
      "Epoch [454/250], Loss: 9.355070\n",
      "Epoch [455/250], Loss: 8.623607\n",
      "Epoch [456/250], Loss: 9.501311\n",
      "Epoch [457/250], Loss: 7.593293\n",
      "Epoch [458/250], Loss: 6.908447\n",
      "Epoch [459/250], Loss: 5.773764\n",
      "Epoch [460/250], Loss: 6.513532\n",
      "Epoch [461/250], Loss: 5.647079\n",
      "Epoch [462/250], Loss: 8.971842\n",
      "Epoch [463/250], Loss: 6.974857\n",
      "Epoch [464/250], Loss: 2.928714\n",
      "Epoch [465/250], Loss: 7.875644\n",
      "Epoch [466/250], Loss: 5.426828\n",
      "Epoch [467/250], Loss: 7.409056\n",
      "Epoch [468/250], Loss: 3.228890\n",
      "Epoch [469/250], Loss: 7.889001\n",
      "Epoch [470/250], Loss: 7.659032\n",
      "Epoch [471/250], Loss: 9.338009\n",
      "Epoch [472/250], Loss: 6.403419\n",
      "Epoch [473/250], Loss: 7.498108\n",
      "Epoch [474/250], Loss: 6.621716\n",
      "Epoch [475/250], Loss: 10.645442\n",
      "Epoch [476/250], Loss: 6.989816\n",
      "Epoch [477/250], Loss: 7.254602\n",
      "Epoch [478/250], Loss: 6.113403\n",
      "Epoch [479/250], Loss: 3.898780\n",
      "Epoch [480/250], Loss: 4.489154\n",
      "Epoch [481/250], Loss: 5.538802\n",
      "Epoch [482/250], Loss: 5.817377\n",
      "Epoch [483/250], Loss: 9.882236\n",
      "Epoch [484/250], Loss: 6.011174\n",
      "Epoch [485/250], Loss: 8.809105\n",
      "Epoch [486/250], Loss: 3.779770\n",
      "Epoch [487/250], Loss: 6.975354\n",
      "Epoch [488/250], Loss: 8.552819\n",
      "Epoch [489/250], Loss: 2.305187\n",
      "Epoch [490/250], Loss: 14.297996\n",
      "Epoch [491/250], Loss: 7.771395\n",
      "Epoch [492/250], Loss: 7.299142\n",
      "Epoch [493/250], Loss: 7.742620\n",
      "Epoch [494/250], Loss: 6.681786\n",
      "Epoch [495/250], Loss: 6.768761\n",
      "Epoch [496/250], Loss: 12.117150\n",
      "Epoch [497/250], Loss: 6.996487\n",
      "Epoch [498/250], Loss: 5.890673\n",
      "Epoch [499/250], Loss: 8.647094\n",
      "Epoch [500/250], Loss: 4.954948\n",
      "Epoch [501/250], Loss: 5.440043\n",
      "Epoch [502/250], Loss: 10.634147\n",
      "Epoch [503/250], Loss: 3.977101\n",
      "Epoch [504/250], Loss: 5.582674\n",
      "Epoch [505/250], Loss: 4.241067\n",
      "Epoch [506/250], Loss: 5.309038\n",
      "Epoch [507/250], Loss: 4.439948\n",
      "Epoch [508/250], Loss: 9.837016\n",
      "Epoch [509/250], Loss: 9.942803\n",
      "Epoch [510/250], Loss: 5.408008\n",
      "Epoch [511/250], Loss: 7.035279\n",
      "Epoch [512/250], Loss: 3.155376\n",
      "Epoch [513/250], Loss: 6.276882\n",
      "Epoch [514/250], Loss: 5.698588\n",
      "Epoch [515/250], Loss: 3.636214\n",
      "Epoch [516/250], Loss: 8.783588\n",
      "Epoch [517/250], Loss: 6.852581\n",
      "Epoch [518/250], Loss: 6.556014\n",
      "Epoch [519/250], Loss: 3.884453\n",
      "Epoch [520/250], Loss: 9.275385\n",
      "Epoch [521/250], Loss: 7.722384\n",
      "Epoch [522/250], Loss: 7.055606\n",
      "Epoch [523/250], Loss: 9.416902\n",
      "Epoch [524/250], Loss: 3.244117\n",
      "Epoch [525/250], Loss: 8.653726\n",
      "Epoch [526/250], Loss: 4.756369\n",
      "Epoch [527/250], Loss: 10.768583\n",
      "Epoch [528/250], Loss: 8.762914\n",
      "Epoch [529/250], Loss: 5.892918\n",
      "Epoch [530/250], Loss: 6.740248\n",
      "Epoch [531/250], Loss: 4.768506\n",
      "Epoch [532/250], Loss: 5.339694\n",
      "Epoch [533/250], Loss: 4.154001\n",
      "Epoch [534/250], Loss: 6.384346\n",
      "Epoch [535/250], Loss: 9.083513\n",
      "Epoch [536/250], Loss: 6.006419\n",
      "Epoch [537/250], Loss: 7.700507\n",
      "Epoch [538/250], Loss: 9.248961\n",
      "Epoch [539/250], Loss: 5.060251\n",
      "Epoch [540/250], Loss: 5.361967\n",
      "Epoch [541/250], Loss: 6.167848\n",
      "Epoch [542/250], Loss: 7.077896\n",
      "Epoch [543/250], Loss: 2.050582\n",
      "Epoch [544/250], Loss: 6.172514\n",
      "Epoch [545/250], Loss: 7.882304\n",
      "Epoch [546/250], Loss: 11.366194\n",
      "Epoch [547/250], Loss: 6.909829\n",
      "Epoch [548/250], Loss: 7.094164\n",
      "Epoch [549/250], Loss: 6.829754\n",
      "Epoch [550/250], Loss: 8.802640\n",
      "Epoch [551/250], Loss: 2.081277\n",
      "Epoch [552/250], Loss: 7.397476\n",
      "Epoch [553/250], Loss: 5.611065\n",
      "Epoch [554/250], Loss: 8.009861\n",
      "Epoch [555/250], Loss: 9.787521\n",
      "Epoch [556/250], Loss: 7.174181\n",
      "Epoch [557/250], Loss: 3.547981\n",
      "Epoch [558/250], Loss: 6.571506\n",
      "Epoch [559/250], Loss: 5.458536\n",
      "Epoch [560/250], Loss: 4.128929\n",
      "Epoch [561/250], Loss: 3.836661\n",
      "Epoch [562/250], Loss: 7.141779\n",
      "Epoch [563/250], Loss: 7.745091\n",
      "Epoch [564/250], Loss: 6.261747\n",
      "Epoch [565/250], Loss: 7.523923\n",
      "Epoch [566/250], Loss: 8.007354\n",
      "Epoch [567/250], Loss: 8.226527\n",
      "Epoch [568/250], Loss: 11.066843\n",
      "Epoch [569/250], Loss: 10.363444\n",
      "Epoch [570/250], Loss: 7.310013\n",
      "Epoch [571/250], Loss: 5.190126\n",
      "Epoch [572/250], Loss: 3.391977\n",
      "Epoch [573/250], Loss: 6.245732\n",
      "Epoch [574/250], Loss: 6.693386\n",
      "Epoch [575/250], Loss: 4.639482\n",
      "Epoch [576/250], Loss: 8.789030\n",
      "Epoch [577/250], Loss: 6.441722\n",
      "Epoch [578/250], Loss: 9.982991\n",
      "Epoch [579/250], Loss: 4.530992\n",
      "Epoch [580/250], Loss: 3.598575\n",
      "Epoch [581/250], Loss: 6.684653\n",
      "Epoch [582/250], Loss: 9.429068\n",
      "Epoch [583/250], Loss: 7.793929\n",
      "Epoch [584/250], Loss: 12.624428\n",
      "Epoch [585/250], Loss: 6.722896\n",
      "Epoch [586/250], Loss: 6.344664\n",
      "Epoch [587/250], Loss: 3.996615\n",
      "Epoch [588/250], Loss: 6.480812\n",
      "Epoch [589/250], Loss: 2.670689\n",
      "Epoch [590/250], Loss: 7.293675\n",
      "Epoch [591/250], Loss: 3.215696\n",
      "Epoch [592/250], Loss: 8.477528\n",
      "Epoch [593/250], Loss: 4.498171\n",
      "Epoch [594/250], Loss: 7.005967\n",
      "Epoch [595/250], Loss: 7.547119\n",
      "Epoch [596/250], Loss: 4.497053\n",
      "Epoch [597/250], Loss: 10.834041\n",
      "Epoch [598/250], Loss: 8.145452\n",
      "Epoch [599/250], Loss: 14.103374\n",
      "Epoch [600/250], Loss: 3.597783\n",
      "Epoch [601/250], Loss: 7.621698\n",
      "Epoch [602/250], Loss: 6.036167\n",
      "Epoch [603/250], Loss: 7.131383\n",
      "Epoch [604/250], Loss: 6.036779\n",
      "Epoch [605/250], Loss: 7.146733\n",
      "Epoch [606/250], Loss: 6.025651\n",
      "Epoch [607/250], Loss: 13.217273\n",
      "Epoch [608/250], Loss: 7.960732\n",
      "Epoch [609/250], Loss: 6.838667\n",
      "Epoch [610/250], Loss: 4.856775\n",
      "Epoch [611/250], Loss: 8.956753\n",
      "Epoch [612/250], Loss: 7.549984\n",
      "Epoch [613/250], Loss: 4.917589\n",
      "Epoch [614/250], Loss: 7.995013\n",
      "Epoch [615/250], Loss: 5.343208\n",
      "Epoch [616/250], Loss: 6.366304\n",
      "Epoch [617/250], Loss: 4.033277\n",
      "Epoch [618/250], Loss: 5.953598\n",
      "Epoch [619/250], Loss: 4.255367\n",
      "Epoch [620/250], Loss: 2.302014\n",
      "Epoch [621/250], Loss: 5.844247\n",
      "Epoch [622/250], Loss: 1.552442\n",
      "Epoch [623/250], Loss: 13.551980\n",
      "Epoch [624/250], Loss: 11.978544\n",
      "Epoch [625/250], Loss: 3.233375\n",
      "Epoch [626/250], Loss: 7.546401\n",
      "Epoch [627/250], Loss: 16.747124\n",
      "Epoch [628/250], Loss: 3.304968\n",
      "Epoch [629/250], Loss: 8.612893\n",
      "Epoch [630/250], Loss: 10.622647\n",
      "Epoch [631/250], Loss: 6.405994\n",
      "Epoch [632/250], Loss: 6.852672\n",
      "Epoch [633/250], Loss: 5.426826\n",
      "Epoch [634/250], Loss: 7.245945\n",
      "Epoch [635/250], Loss: 3.236794\n",
      "Epoch [636/250], Loss: 3.607613\n",
      "Epoch [637/250], Loss: 6.687483\n",
      "Epoch [638/250], Loss: 4.953448\n",
      "Epoch [639/250], Loss: 9.796011\n",
      "Epoch [640/250], Loss: 4.462221\n",
      "Epoch [641/250], Loss: 3.479341\n",
      "Epoch [642/250], Loss: 6.477210\n",
      "Epoch [643/250], Loss: 8.362978\n",
      "Epoch [644/250], Loss: 6.340552\n",
      "Epoch [645/250], Loss: 5.894051\n",
      "Epoch [646/250], Loss: 3.629662\n",
      "Epoch [647/250], Loss: 7.536205\n",
      "Epoch [648/250], Loss: 7.619511\n",
      "Epoch [649/250], Loss: 7.496318\n",
      "Epoch [650/250], Loss: 6.065694\n",
      "Epoch [651/250], Loss: 8.521997\n",
      "Epoch [652/250], Loss: 5.938988\n",
      "Epoch [653/250], Loss: 6.223965\n",
      "Epoch [654/250], Loss: 7.122747\n",
      "Epoch [655/250], Loss: 3.631474\n",
      "Epoch [656/250], Loss: 6.116962\n",
      "Epoch [657/250], Loss: 7.404691\n",
      "Epoch [658/250], Loss: 6.645183\n",
      "Epoch [659/250], Loss: 5.008306\n",
      "Epoch [660/250], Loss: 3.118280\n",
      "Epoch [661/250], Loss: 7.063803\n",
      "Epoch [662/250], Loss: 9.406248\n",
      "Epoch [663/250], Loss: 5.238969\n",
      "Epoch [664/250], Loss: 3.755423\n",
      "Epoch [665/250], Loss: 5.569772\n",
      "Epoch [666/250], Loss: 8.524876\n",
      "Epoch [667/250], Loss: 3.871834\n",
      "Epoch [668/250], Loss: 12.145312\n",
      "Epoch [669/250], Loss: 3.569824\n",
      "Epoch [670/250], Loss: 8.716331\n",
      "Epoch [671/250], Loss: 8.529244\n",
      "Epoch [672/250], Loss: 6.570709\n",
      "Epoch [673/250], Loss: 6.616972\n",
      "Epoch [674/250], Loss: 13.564125\n",
      "Epoch [675/250], Loss: 6.020761\n",
      "Epoch [676/250], Loss: 5.873660\n",
      "Epoch [677/250], Loss: 8.899858\n",
      "Epoch [678/250], Loss: 6.589484\n",
      "Epoch [679/250], Loss: 7.934806\n",
      "Epoch [680/250], Loss: 9.186264\n",
      "Epoch [681/250], Loss: 7.461381\n",
      "Epoch [682/250], Loss: 7.550927\n",
      "Epoch [683/250], Loss: 11.334936\n",
      "Epoch [684/250], Loss: 6.889624\n",
      "Epoch [685/250], Loss: 7.500761\n",
      "Epoch [686/250], Loss: 6.256820\n",
      "Epoch [687/250], Loss: 5.253241\n",
      "Epoch [688/250], Loss: 2.019707\n",
      "Epoch [689/250], Loss: 3.380227\n",
      "Epoch [690/250], Loss: 4.805296\n",
      "Epoch [691/250], Loss: 8.983137\n",
      "Epoch [692/250], Loss: 9.078566\n",
      "Epoch [693/250], Loss: 3.586664\n",
      "Epoch [694/250], Loss: 6.185533\n",
      "Epoch [695/250], Loss: 10.860466\n",
      "Epoch [696/250], Loss: 5.165247\n",
      "Epoch [697/250], Loss: 5.283095\n",
      "Epoch [698/250], Loss: 10.504670\n",
      "Epoch [699/250], Loss: 8.343302\n",
      "Epoch [700/250], Loss: 3.849432\n",
      "Epoch [701/250], Loss: 4.572926\n",
      "Epoch [702/250], Loss: 4.924998\n",
      "Epoch [703/250], Loss: 5.356175\n",
      "Epoch [704/250], Loss: 5.079256\n",
      "Epoch [705/250], Loss: 6.610946\n",
      "Epoch [706/250], Loss: 8.010752\n",
      "Epoch [707/250], Loss: 8.424589\n",
      "Epoch [708/250], Loss: 9.124939\n",
      "Epoch [709/250], Loss: 9.736801\n",
      "Epoch [710/250], Loss: 5.925925\n",
      "Epoch [711/250], Loss: 8.088253\n",
      "Epoch [712/250], Loss: 9.623320\n",
      "Epoch [713/250], Loss: 7.625181\n",
      "Epoch [714/250], Loss: 4.768249\n",
      "Epoch [715/250], Loss: 8.498244\n",
      "Epoch [716/250], Loss: 1.760685\n",
      "Epoch [717/250], Loss: 4.765183\n",
      "Epoch [718/250], Loss: 4.545538\n",
      "Epoch [719/250], Loss: 3.958485\n",
      "Epoch [720/250], Loss: 6.962623\n",
      "Epoch [721/250], Loss: 15.693730\n",
      "Epoch [722/250], Loss: 4.299529\n",
      "Epoch [723/250], Loss: 7.886948\n",
      "Epoch [724/250], Loss: 3.171652\n",
      "Epoch [725/250], Loss: 7.658577\n",
      "Epoch [726/250], Loss: 5.363133\n",
      "Epoch [727/250], Loss: 13.608851\n",
      "Epoch [728/250], Loss: 4.367266\n",
      "Epoch [729/250], Loss: 8.054936\n",
      "Epoch [730/250], Loss: 9.213557\n",
      "Epoch [731/250], Loss: 8.418457\n",
      "Epoch [732/250], Loss: 4.376850\n",
      "Epoch [733/250], Loss: 5.419138\n",
      "Epoch [734/250], Loss: 3.046537\n",
      "Epoch [735/250], Loss: 7.570241\n",
      "Epoch [736/250], Loss: 3.636437\n",
      "Epoch [737/250], Loss: 4.125306\n",
      "Epoch [738/250], Loss: 5.781005\n",
      "Epoch [739/250], Loss: 7.339804\n",
      "Epoch [740/250], Loss: 5.413202\n",
      "Epoch [741/250], Loss: 6.792858\n",
      "Epoch [742/250], Loss: 7.057916\n",
      "Epoch [743/250], Loss: 8.946207\n",
      "Epoch [744/250], Loss: 6.696143\n",
      "Epoch [745/250], Loss: 5.765042\n",
      "Epoch [746/250], Loss: 5.237912\n",
      "Epoch [747/250], Loss: 3.942960\n",
      "Epoch [748/250], Loss: 8.894150\n",
      "Epoch [749/250], Loss: 6.564720\n",
      "Epoch [750/250], Loss: 3.863811\n",
      "Epoch [751/250], Loss: 3.589858\n",
      "Epoch [752/250], Loss: 5.436156\n",
      "Epoch [753/250], Loss: 4.589996\n",
      "Epoch [754/250], Loss: 8.229982\n",
      "Epoch [755/250], Loss: 8.725621\n",
      "Epoch [756/250], Loss: 4.482758\n",
      "Epoch [757/250], Loss: 14.973462\n",
      "Epoch [758/250], Loss: 2.344060\n",
      "Epoch [759/250], Loss: 5.719449\n",
      "Epoch [760/250], Loss: 5.699693\n",
      "Epoch [761/250], Loss: 7.011139\n",
      "Epoch [762/250], Loss: 5.206751\n",
      "Epoch [763/250], Loss: 10.004287\n",
      "Epoch [764/250], Loss: 3.873519\n",
      "Epoch [765/250], Loss: 6.020518\n",
      "Epoch [766/250], Loss: 4.682684\n",
      "Epoch [767/250], Loss: 4.703486\n",
      "Epoch [768/250], Loss: 7.105924\n",
      "Epoch [769/250], Loss: 6.986921\n",
      "Epoch [770/250], Loss: 7.481170\n",
      "Epoch [771/250], Loss: 11.789341\n",
      "Epoch [772/250], Loss: 10.722250\n",
      "Epoch [773/250], Loss: 7.159666\n",
      "Epoch [774/250], Loss: 5.487908\n",
      "Epoch [775/250], Loss: 7.839899\n",
      "Epoch [776/250], Loss: 3.763627\n",
      "Epoch [777/250], Loss: 8.014978\n",
      "Epoch [778/250], Loss: 5.296816\n",
      "Epoch [779/250], Loss: 15.321025\n",
      "Epoch [780/250], Loss: 6.220440\n",
      "Epoch [781/250], Loss: 8.797686\n",
      "Epoch [782/250], Loss: 9.916653\n",
      "Epoch [783/250], Loss: 8.081976\n",
      "Epoch [784/250], Loss: 7.120996\n",
      "Epoch [785/250], Loss: 8.320266\n",
      "Epoch [786/250], Loss: 4.656243\n",
      "Epoch [787/250], Loss: 7.894303\n",
      "Epoch [788/250], Loss: 10.096490\n",
      "Epoch [789/250], Loss: 8.601729\n",
      "Epoch [790/250], Loss: 3.997920\n",
      "Epoch [791/250], Loss: 5.121299\n",
      "Epoch [792/250], Loss: 2.584730\n",
      "Epoch [793/250], Loss: 4.135462\n",
      "Epoch [794/250], Loss: 6.008615\n",
      "Epoch [795/250], Loss: 7.557792\n",
      "Epoch [796/250], Loss: 10.232445\n",
      "Epoch [797/250], Loss: 11.235135\n",
      "Epoch [798/250], Loss: 6.844583\n",
      "Epoch [799/250], Loss: 2.722702\n",
      "Epoch [800/250], Loss: 7.933348\n",
      "Epoch [801/250], Loss: 5.268936\n",
      "Epoch [802/250], Loss: 6.319787\n",
      "Epoch [803/250], Loss: 10.367105\n",
      "Epoch [804/250], Loss: 4.356562\n",
      "Epoch [805/250], Loss: 7.127529\n",
      "Epoch [806/250], Loss: 4.969209\n",
      "Epoch [807/250], Loss: 6.415957\n",
      "Epoch [808/250], Loss: 5.371227\n",
      "Epoch [809/250], Loss: 8.931106\n",
      "Epoch [810/250], Loss: 3.257757\n",
      "Epoch [811/250], Loss: 3.978403\n",
      "Epoch [812/250], Loss: 2.936055\n",
      "Epoch [813/250], Loss: 4.803877\n",
      "Epoch [814/250], Loss: 5.722196\n",
      "Epoch [815/250], Loss: 15.681823\n",
      "Epoch [816/250], Loss: 8.146738\n",
      "Epoch [817/250], Loss: 4.084069\n",
      "Epoch [818/250], Loss: 4.329935\n",
      "Epoch [819/250], Loss: 9.041484\n",
      "Epoch [820/250], Loss: 5.345166\n",
      "Epoch [821/250], Loss: 7.327820\n",
      "Epoch [822/250], Loss: 6.775289\n",
      "Epoch [823/250], Loss: 4.490610\n",
      "Epoch [824/250], Loss: 4.211132\n",
      "Epoch [825/250], Loss: 4.781857\n",
      "Epoch [826/250], Loss: 6.402524\n",
      "Epoch [827/250], Loss: 7.492726\n",
      "Epoch [828/250], Loss: 5.321869\n",
      "Epoch [829/250], Loss: 12.619738\n",
      "Epoch [830/250], Loss: 7.272468\n",
      "Epoch [831/250], Loss: 5.245938\n",
      "Epoch [832/250], Loss: 3.249196\n",
      "Epoch [833/250], Loss: 9.699932\n",
      "Epoch [834/250], Loss: 5.360088\n",
      "Epoch [835/250], Loss: 7.097751\n",
      "Epoch [836/250], Loss: 7.064992\n",
      "Epoch [837/250], Loss: 3.553626\n",
      "Epoch [838/250], Loss: 6.886206\n",
      "Epoch [839/250], Loss: 3.429852\n",
      "Epoch [840/250], Loss: 2.000948\n",
      "Epoch [841/250], Loss: 7.482179\n",
      "Epoch [842/250], Loss: 6.271526\n",
      "Epoch [843/250], Loss: 9.089419\n",
      "Epoch [844/250], Loss: 2.283539\n",
      "Epoch [845/250], Loss: 10.607755\n",
      "Epoch [846/250], Loss: 4.442075\n",
      "Epoch [847/250], Loss: 3.515709\n",
      "Epoch [848/250], Loss: 8.541896\n",
      "Epoch [849/250], Loss: 7.007396\n",
      "Epoch [850/250], Loss: 3.938060\n",
      "Epoch [851/250], Loss: 2.555575\n",
      "Epoch [852/250], Loss: 10.616340\n",
      "Epoch [853/250], Loss: 5.413166\n",
      "Epoch [854/250], Loss: 2.531251\n",
      "Epoch [855/250], Loss: 1.473281\n",
      "Epoch [856/250], Loss: 6.007010\n",
      "Epoch [857/250], Loss: 9.230697\n",
      "Epoch [858/250], Loss: 9.395699\n",
      "Epoch [859/250], Loss: 3.845059\n",
      "Epoch [860/250], Loss: 5.645207\n",
      "Epoch [861/250], Loss: 6.314923\n",
      "Epoch [862/250], Loss: 4.468088\n",
      "Epoch [863/250], Loss: 4.776466\n",
      "Epoch [864/250], Loss: 9.446585\n",
      "Epoch [865/250], Loss: 4.141209\n",
      "Epoch [866/250], Loss: 4.967764\n",
      "Epoch [867/250], Loss: 6.324660\n",
      "Epoch [868/250], Loss: 7.870629\n",
      "Epoch [869/250], Loss: 8.386481\n",
      "Epoch [870/250], Loss: 10.950210\n",
      "Epoch [871/250], Loss: 6.389748\n",
      "Epoch [872/250], Loss: 7.871843\n",
      "Epoch [873/250], Loss: 5.211130\n",
      "Epoch [874/250], Loss: 5.312663\n",
      "Epoch [875/250], Loss: 7.016541\n",
      "Epoch [876/250], Loss: 4.518103\n",
      "Epoch [877/250], Loss: 2.679165\n",
      "Epoch [878/250], Loss: 6.287969\n",
      "Epoch [879/250], Loss: 2.913864\n",
      "Epoch [880/250], Loss: 3.450007\n",
      "Epoch [881/250], Loss: 7.057315\n",
      "Epoch [882/250], Loss: 6.042506\n",
      "Epoch [883/250], Loss: 4.757116\n",
      "Epoch [884/250], Loss: 5.137938\n",
      "Epoch [885/250], Loss: 3.995876\n",
      "Epoch [886/250], Loss: 3.798021\n",
      "Epoch [887/250], Loss: 7.007457\n",
      "Epoch [888/250], Loss: 3.477648\n",
      "Epoch [889/250], Loss: 4.358419\n",
      "Epoch [890/250], Loss: 6.306178\n",
      "Epoch [891/250], Loss: 2.942449\n",
      "Epoch [892/250], Loss: 5.054094\n",
      "Epoch [893/250], Loss: 5.320097\n",
      "Epoch [894/250], Loss: 10.817449\n",
      "Epoch [895/250], Loss: 6.305895\n",
      "Epoch [896/250], Loss: 3.104138\n",
      "Epoch [897/250], Loss: 5.406348\n",
      "Epoch [898/250], Loss: 8.734214\n",
      "Epoch [899/250], Loss: 5.315277\n",
      "Epoch [900/250], Loss: 4.619561\n",
      "Epoch [901/250], Loss: 7.739317\n",
      "Epoch [902/250], Loss: 9.378683\n",
      "Epoch [903/250], Loss: 8.013910\n",
      "Epoch [904/250], Loss: 5.074754\n",
      "Epoch [905/250], Loss: 5.233207\n",
      "Epoch [906/250], Loss: 6.359965\n",
      "Epoch [907/250], Loss: 7.977282\n",
      "Epoch [908/250], Loss: 4.356632\n",
      "Epoch [909/250], Loss: 6.227030\n",
      "Epoch [910/250], Loss: 5.064050\n",
      "Epoch [911/250], Loss: 3.332136\n",
      "Epoch [912/250], Loss: 7.895854\n",
      "Epoch [913/250], Loss: 6.669826\n",
      "Epoch [914/250], Loss: 8.079495\n",
      "Epoch [915/250], Loss: 9.493746\n",
      "Epoch [916/250], Loss: 9.350300\n",
      "Epoch [917/250], Loss: 9.278434\n",
      "Epoch [918/250], Loss: 7.172877\n",
      "Epoch [919/250], Loss: 7.132632\n",
      "Epoch [920/250], Loss: 5.896065\n",
      "Epoch [921/250], Loss: 6.257126\n",
      "Epoch [922/250], Loss: 4.830099\n",
      "Epoch [923/250], Loss: 11.257836\n",
      "Epoch [924/250], Loss: 2.397468\n",
      "Epoch [925/250], Loss: 3.573183\n",
      "Epoch [926/250], Loss: 11.976713\n",
      "Epoch [927/250], Loss: 6.559019\n",
      "Epoch [928/250], Loss: 5.634221\n",
      "Epoch [929/250], Loss: 6.623696\n",
      "Epoch [930/250], Loss: 5.011978\n",
      "Epoch [931/250], Loss: 7.185362\n",
      "Epoch [932/250], Loss: 7.731730\n",
      "Epoch [933/250], Loss: 5.782482\n",
      "Epoch [934/250], Loss: 5.427684\n",
      "Epoch [935/250], Loss: 6.449256\n",
      "Epoch [936/250], Loss: 1.243262\n",
      "Epoch [937/250], Loss: 7.600692\n",
      "Epoch [938/250], Loss: 3.227425\n",
      "Epoch [939/250], Loss: 8.963999\n",
      "Epoch [940/250], Loss: 4.403963\n",
      "Epoch [941/250], Loss: 6.233326\n",
      "Epoch [942/250], Loss: 9.803222\n",
      "Epoch [943/250], Loss: 9.100057\n",
      "Epoch [944/250], Loss: 6.253868\n",
      "Epoch [945/250], Loss: 7.233033\n",
      "Epoch [946/250], Loss: 4.893586\n",
      "Epoch [947/250], Loss: 3.582586\n",
      "Epoch [948/250], Loss: 6.825148\n",
      "Epoch [949/250], Loss: 2.910428\n",
      "Epoch [950/250], Loss: 6.950708\n",
      "Epoch [951/250], Loss: 4.359002\n",
      "Epoch [952/250], Loss: 4.849366\n",
      "Epoch [953/250], Loss: 3.015094\n",
      "Epoch [954/250], Loss: 7.942517\n",
      "Epoch [955/250], Loss: 2.642751\n",
      "Epoch [956/250], Loss: 4.034117\n",
      "Epoch [957/250], Loss: 8.441114\n",
      "Epoch [958/250], Loss: 5.383064\n",
      "Epoch [959/250], Loss: 5.051937\n",
      "Epoch [960/250], Loss: 4.801721\n",
      "Epoch [961/250], Loss: 4.567146\n",
      "Epoch [962/250], Loss: 6.640448\n",
      "Epoch [963/250], Loss: 6.311405\n",
      "Epoch [964/250], Loss: 9.459148\n",
      "Epoch [965/250], Loss: 5.502216\n",
      "Epoch [966/250], Loss: 4.121645\n",
      "Epoch [967/250], Loss: 6.122687\n",
      "Epoch [968/250], Loss: 7.699867\n",
      "Epoch [969/250], Loss: 4.773479\n",
      "Epoch [970/250], Loss: 5.310654\n",
      "Epoch [971/250], Loss: 3.250185\n",
      "Epoch [972/250], Loss: 3.729883\n",
      "Epoch [973/250], Loss: 9.453961\n",
      "Epoch [974/250], Loss: 6.136952\n",
      "Epoch [975/250], Loss: 7.355552\n",
      "Epoch [976/250], Loss: 4.508936\n",
      "Epoch [977/250], Loss: 6.083366\n",
      "Epoch [978/250], Loss: 2.401787\n",
      "Epoch [979/250], Loss: 4.141475\n",
      "Epoch [980/250], Loss: 8.261696\n",
      "Epoch [981/250], Loss: 11.612538\n",
      "Epoch [982/250], Loss: 4.134161\n",
      "Epoch [983/250], Loss: 7.233389\n",
      "Epoch [984/250], Loss: 8.260015\n",
      "Epoch [985/250], Loss: 7.674444\n",
      "Epoch [986/250], Loss: 6.845038\n",
      "Epoch [987/250], Loss: 7.572555\n",
      "Epoch [988/250], Loss: 3.176178\n",
      "Epoch [989/250], Loss: 6.478909\n",
      "Epoch [990/250], Loss: 4.020321\n",
      "Epoch [991/250], Loss: 6.014191\n",
      "Epoch [992/250], Loss: 4.607282\n",
      "Epoch [993/250], Loss: 2.023486\n",
      "Epoch [994/250], Loss: 5.017199\n",
      "Epoch [995/250], Loss: 6.543961\n",
      "Epoch [996/250], Loss: 5.790525\n",
      "Epoch [997/250], Loss: 3.942815\n",
      "Epoch [998/250], Loss: 7.506157\n",
      "Epoch [999/250], Loss: 2.521360\n",
      "Epoch [1000/250], Loss: 3.947671\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):  # Number of epochs\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), targets.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/10000], Loss: {loss.item()*100:0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3e9c319-5e47-48fe-9860-364300f9faa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.0000, 0.6500, 0.4200])\n",
      "Predicted: 15.19, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.0700, 0.2800])\n",
      "Predicted: 1.83, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.4000])\n",
      "Predicted: 15.04, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.5000, 0.8700])\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7100, 0.9700])\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0900, 0.0000])\n",
      "Predicted: 3.08, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.0200])\n",
      "Predicted: 16.01, Actual: 13.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.4700])\n",
      "Predicted: 4.11, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4700, 0.1700])\n",
      "Predicted: 14.45, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.4400, 0.1100])\n",
      "Predicted: 14.52, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.7100, 0.9600])\n",
      "Predicted: 1.69, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7400, 0.1100])\n",
      "Predicted: 15.33, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.7600])\n",
      "Predicted: 3.92, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3000, 0.7700])\n",
      "Predicted: 1.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2300, 0.1400])\n",
      "Predicted: 5.43, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.8200])\n",
      "Predicted: 3.81, Actual: 0.00\n",
      "Average loss on the testing dataset: 3.0416\n",
      "tensor([0.0000, 0.0000, 0.3500, 0.1500])\n",
      "Predicted: 11.71, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.0700, 0.2400])\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.6800])\n",
      "Predicted: 6.05, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.5800])\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6400, 0.5900])\n",
      "Predicted: 9.83, Actual: 14.00\n",
      "tensor([0.0000, 1.0000, 0.2500, 0.8100])\n",
      "Predicted: 1.22, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.8700])\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.9700])\n",
      "Predicted: 0.30, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6100, 0.9600])\n",
      "Predicted: 1.22, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0900, 0.4500])\n",
      "Predicted: 1.79, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.7200])\n",
      "Predicted: 0.73, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.7700])\n",
      "Predicted: 3.87, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8600, 0.5900])\n",
      "Predicted: 12.88, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.4900, 0.4900])\n",
      "Predicted: 10.63, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.5900])\n",
      "Predicted: 8.15, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.0100, 0.2900])\n",
      "Predicted: 1.72, Actual: 0.00\n",
      "Average loss on the testing dataset: 3.8365\n",
      "tensor([1.0000, 1.0000, 0.4700, 0.4300])\n",
      "Predicted: 11.60, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.8900])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.8700])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 0.9200])\n",
      "Predicted: 0.83, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.0200])\n",
      "Predicted: 15.08, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.4500])\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.5600])\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6200, 0.8800])\n",
      "Predicted: 2.26, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4900, 0.4500])\n",
      "Predicted: 10.89, Actual: 30.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.0500])\n",
      "Predicted: 5.93, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9800, 0.4600])\n",
      "Predicted: 15.08, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.3700, 0.9200])\n",
      "Predicted: 1.01, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6900, 0.8000])\n",
      "Predicted: 3.96, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4100, 0.5800])\n",
      "Predicted: 6.69, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.6900, 0.7900])\n",
      "Predicted: 4.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.7400])\n",
      "Predicted: 8.60, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.1260\n",
      "tensor([1.0000, 1.0000, 0.2300, 0.1100])\n",
      "Predicted: 5.65, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0100, 0.5200])\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.2700])\n",
      "Predicted: 15.00, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 1.0000])\n",
      "Predicted: 3.05, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.2100])\n",
      "Predicted: 15.95, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.0200, 0.2300])\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.4000])\n",
      "Predicted: 14.95, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.9900])\n",
      "Predicted: 0.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.8300])\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.7200])\n",
      "Predicted: 8.74, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.2500])\n",
      "Predicted: 3.04, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3500, 0.2600])\n",
      "Predicted: 9.45, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.0800, 0.2200])\n",
      "Predicted: 2.58, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.5300])\n",
      "Predicted: 14.85, Actual: 24.00\n",
      "tensor([1.0000, 0.0000, 0.4600, 0.9700])\n",
      "Predicted: 0.70, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 1.0000])\n",
      "Predicted: 0.49, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.1102\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.0300])\n",
      "Predicted: 5.18, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9100, 0.9400])\n",
      "Predicted: 3.11, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.9800])\n",
      "Predicted: 0.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.4400])\n",
      "Predicted: 1.28, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.6100])\n",
      "Predicted: 5.34, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.5000, 0.3200])\n",
      "Predicted: 14.52, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.6900, 0.3900])\n",
      "Predicted: 15.31, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.9600])\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7400, 0.3800])\n",
      "Predicted: 15.58, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.6800, 0.3600])\n",
      "Predicted: 15.32, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.6600])\n",
      "Predicted: 5.72, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.6100])\n",
      "Predicted: 14.82, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.2200])\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.0000])\n",
      "Predicted: 16.11, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.3500])\n",
      "Predicted: 5.46, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6500, 0.2500])\n",
      "Predicted: 14.98, Actual: 4.00\n",
      "Average loss on the testing dataset: 5.5114\n",
      "tensor([0.0000, 1.0000, 0.2000, 0.7500])\n",
      "Predicted: 1.33, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.5800])\n",
      "Predicted: 9.43, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.1400])\n",
      "Predicted: 3.00, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.1200])\n",
      "Predicted: 15.68, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.9200, 0.7900])\n",
      "Predicted: 8.20, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.5200])\n",
      "Predicted: 15.11, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.7800])\n",
      "Predicted: 0.98, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9800, 0.5000])\n",
      "Predicted: 14.96, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.8000, 0.2900])\n",
      "Predicted: 15.37, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.0700, 0.7200])\n",
      "Predicted: 0.81, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0000, 0.4700])\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.4100])\n",
      "Predicted: 15.62, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.4200])\n",
      "Predicted: 15.49, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.7900])\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.5900])\n",
      "Predicted: 15.21, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.7400, 0.2700])\n",
      "Predicted: 15.15, Actual: 3.00\n",
      "Average loss on the testing dataset: 5.8028\n",
      "tensor([1.0000, 0.0000, 0.0400, 0.4800])\n",
      "Predicted: 1.04, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.7400])\n",
      "Predicted: 1.78, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.6600])\n",
      "Predicted: 0.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.4300])\n",
      "Predicted: 15.62, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.9700])\n",
      "Predicted: 1.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2400, 0.6800])\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.4500])\n",
      "Predicted: 15.26, Actual: 22.00\n",
      "tensor([0.0000, 1.0000, 0.3900, 0.1200])\n",
      "Predicted: 13.32, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.1100, 0.3300])\n",
      "Predicted: 2.68, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8800, 0.1400])\n",
      "Predicted: 16.00, Actual: 11.00\n",
      "tensor([0.0000, 0.0000, 0.9200, 0.3200])\n",
      "Predicted: 15.42, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.6800])\n",
      "Predicted: 1.21, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.1200])\n",
      "Predicted: 14.90, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.9200, 0.1700])\n",
      "Predicted: 16.18, Actual: 28.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.2900])\n",
      "Predicted: 7.38, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.6800])\n",
      "Predicted: 5.38, Actual: 10.00\n",
      "Average loss on the testing dataset: 5.7566\n",
      "tensor([0.0000, 1.0000, 0.2100, 0.6300])\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.0100])\n",
      "Predicted: 12.20, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.1500, 0.0800])\n",
      "Predicted: 5.80, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2900, 0.5800])\n",
      "Predicted: 3.22, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3800, 0.4200])\n",
      "Predicted: 8.10, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.7000])\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0400, 0.8800])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4800, 0.6400])\n",
      "Predicted: 4.82, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.9200, 0.1500])\n",
      "Predicted: 16.07, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.0800, 0.0900])\n",
      "Predicted: 2.76, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5300, 0.4500])\n",
      "Predicted: 12.90, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.5100])\n",
      "Predicted: 13.96, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.0200])\n",
      "Predicted: 15.18, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.4700])\n",
      "Predicted: 13.23, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.4200, 0.1000])\n",
      "Predicted: 14.29, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.7400])\n",
      "Predicted: 8.60, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.5414\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.6300])\n",
      "Predicted: 13.38, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.9700])\n",
      "Predicted: 0.47, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.8500])\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9200, 0.5200])\n",
      "Predicted: 14.86, Actual: 8.00\n",
      "tensor([0.0000, 0.0000, 0.2700, 0.5600])\n",
      "Predicted: 3.03, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.6300])\n",
      "Predicted: 9.94, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.4300, 0.2700])\n",
      "Predicted: 11.62, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.8500])\n",
      "Predicted: 3.96, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.0100])\n",
      "Predicted: 3.62, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4400, 0.4800])\n",
      "Predicted: 8.54, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.2900])\n",
      "Predicted: 15.59, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.5300])\n",
      "Predicted: 2.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6100, 0.0200])\n",
      "Predicted: 15.12, Actual: 8.00\n",
      "tensor([0.0000, 0.0000, 0.3800, 0.8700])\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5300, 0.2000])\n",
      "Predicted: 14.77, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.6500])\n",
      "Predicted: 4.17, Actual: 4.00\n",
      "Average loss on the testing dataset: 5.6643\n",
      "tensor([0.0000, 0.0000, 0.8300, 0.7500])\n",
      "Predicted: 6.63, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.4700])\n",
      "Predicted: 12.96, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.2000, 0.8900])\n",
      "Predicted: 0.74, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6900, 0.0100])\n",
      "Predicted: 15.25, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.1500])\n",
      "Predicted: 14.90, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.1400, 0.5500])\n",
      "Predicted: 1.59, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7900, 0.0600])\n",
      "Predicted: 15.55, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.9200])\n",
      "Predicted: 0.41, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.6700])\n",
      "Predicted: 9.85, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.9400, 0.0700])\n",
      "Predicted: 15.80, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.3600])\n",
      "Predicted: 1.81, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.0300])\n",
      "Predicted: 15.44, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.3400])\n",
      "Predicted: 2.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.1000])\n",
      "Predicted: 7.15, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.2800])\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.6300])\n",
      "Predicted: 15.01, Actual: 2.00\n",
      "Average loss on the testing dataset: 5.7894\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.1000])\n",
      "Predicted: 9.25, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.4800])\n",
      "Predicted: 3.33, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.2700])\n",
      "Predicted: 15.53, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.4600])\n",
      "Predicted: 11.84, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.6300])\n",
      "Predicted: 10.77, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.9600, 0.2600])\n",
      "Predicted: 15.62, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.5400, 0.5800])\n",
      "Predicted: 9.05, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.8300])\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.4900])\n",
      "Predicted: 13.39, Actual: 24.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 0.5600])\n",
      "Predicted: 1.44, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4200, 0.7700])\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0200, 0.5000])\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.9400])\n",
      "Predicted: 2.74, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.6700])\n",
      "Predicted: 13.80, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.0200])\n",
      "Predicted: 15.99, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.6300])\n",
      "Predicted: 7.06, Actual: 4.00\n",
      "Average loss on the testing dataset: 5.7441\n",
      "tensor([0.0000, 1.0000, 0.4800, 0.4800])\n",
      "Predicted: 10.55, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.5700])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.0300])\n",
      "Predicted: 15.62, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.1200, 0.9700])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4400, 0.9100])\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2800, 0.9000])\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5400, 0.9800])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0700, 0.8500])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.3900])\n",
      "Predicted: 6.44, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.2600])\n",
      "Predicted: 15.43, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.9100])\n",
      "Predicted: 2.49, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.7200])\n",
      "Predicted: 9.34, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.3900])\n",
      "Predicted: 15.58, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.7600])\n",
      "Predicted: 4.39, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.6700])\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2900, 0.8100])\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.7773\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.9600])\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.1700])\n",
      "Predicted: 14.67, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.4500, 0.0400])\n",
      "Predicted: 14.54, Actual: 14.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.7400])\n",
      "Predicted: 6.08, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.5700])\n",
      "Predicted: 15.21, Actual: 16.00\n",
      "tensor([1.0000, 1.0000, 0.2000, 0.8400])\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.9500])\n",
      "Predicted: 2.88, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.3600])\n",
      "Predicted: 10.71, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.2700, 0.7200])\n",
      "Predicted: 1.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.7200])\n",
      "Predicted: 10.45, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.0200])\n",
      "Predicted: 15.50, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.7700])\n",
      "Predicted: 0.47, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.4700])\n",
      "Predicted: 14.74, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.3600])\n",
      "Predicted: 15.73, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.6400, 0.7200])\n",
      "Predicted: 6.03, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.8900])\n",
      "Predicted: 0.40, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.4939\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.0600])\n",
      "Predicted: 14.99, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.5900, 0.6500])\n",
      "Predicted: 6.58, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.1500])\n",
      "Predicted: 10.55, Actual: 6.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.6800])\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.4700])\n",
      "Predicted: 15.39, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.0500, 0.8400])\n",
      "Predicted: 0.45, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.5700])\n",
      "Predicted: 15.21, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.1000])\n",
      "Predicted: 10.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.2200])\n",
      "Predicted: 15.66, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.7600])\n",
      "Predicted: 2.20, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6400, 0.5300])\n",
      "Predicted: 13.14, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.1300])\n",
      "Predicted: 4.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6200, 0.1000])\n",
      "Predicted: 15.32, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.3000, 0.7000])\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.1200])\n",
      "Predicted: 15.31, Actual: 28.00\n",
      "tensor([1.0000, 0.0000, 0.9200, 0.1900])\n",
      "Predicted: 16.03, Actual: 24.00\n",
      "Average loss on the testing dataset: 5.6687\n",
      "tensor([0.0000, 0.0000, 0.7600, 0.2200])\n",
      "Predicted: 15.25, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.9700])\n",
      "Predicted: 3.01, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4100, 0.5100])\n",
      "Predicted: 8.10, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.2800])\n",
      "Predicted: 6.73, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.6000])\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2200, 0.7000])\n",
      "Predicted: 1.53, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.0400])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.2100])\n",
      "Predicted: 8.41, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.3500])\n",
      "Predicted: 4.08, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7300, 0.2500])\n",
      "Predicted: 15.15, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.2400, 0.6500])\n",
      "Predicted: 2.47, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.4500])\n",
      "Predicted: 3.58, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.5200])\n",
      "Predicted: 11.16, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.9700])\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.0700])\n",
      "Predicted: 14.75, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.7400, 0.8400])\n",
      "Predicted: 3.72, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.7855\n",
      "tensor([0.0000, 1.0000, 0.7900, 0.0500])\n",
      "Predicted: 15.55, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.9800])\n",
      "Predicted: 1.27, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6100, 0.2300])\n",
      "Predicted: 15.30, Actual: 10.00\n",
      "tensor([1.0000, 0.0000, 0.3800, 0.4300])\n",
      "Predicted: 7.95, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.6700])\n",
      "Predicted: 4.89, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.9600])\n",
      "Predicted: 0.43, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.7900])\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.6100])\n",
      "Predicted: 6.82, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.4400, 0.4300])\n",
      "Predicted: 10.35, Actual: 17.00\n",
      "tensor([1.0000, 0.0000, 0.3300, 0.6100])\n",
      "Predicted: 3.85, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.6800])\n",
      "Predicted: 1.60, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0100, 0.1900])\n",
      "Predicted: 2.20, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3900, 0.9000])\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3900, 0.6400])\n",
      "Predicted: 4.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.2300])\n",
      "Predicted: 3.31, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7100, 0.9800])\n",
      "Predicted: 1.85, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9457\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.5700])\n",
      "Predicted: 0.83, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0300, 0.2800])\n",
      "Predicted: 1.62, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7300, 0.6800])\n",
      "Predicted: 7.37, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.3600])\n",
      "Predicted: 4.01, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.0300])\n",
      "Predicted: 14.68, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.4400, 0.3600])\n",
      "Predicted: 11.58, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.4500, 1.0000])\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6400, 0.2100])\n",
      "Predicted: 15.38, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.1400])\n",
      "Predicted: 12.82, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.3400])\n",
      "Predicted: 13.72, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.9100])\n",
      "Predicted: 4.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2700, 0.5900])\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4500, 0.5900])\n",
      "Predicted: 6.07, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.3500])\n",
      "Predicted: 14.99, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.8200, 0.6600])\n",
      "Predicted: 9.68, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.3700])\n",
      "Predicted: 15.79, Actual: 12.00\n",
      "Average loss on the testing dataset: 5.9386\n",
      "tensor([0.0000, 1.0000, 0.9700, 0.8600])\n",
      "Predicted: 5.21, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.4800])\n",
      "Predicted: 3.00, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.7700])\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.2200])\n",
      "Predicted: 11.69, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.3300])\n",
      "Predicted: 15.07, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.4400])\n",
      "Predicted: 7.69, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.9300, 0.6000])\n",
      "Predicted: 15.16, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.4100, 0.7900])\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.9000])\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.8700])\n",
      "Predicted: 0.95, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2800, 0.8700])\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.0300])\n",
      "Predicted: 14.97, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.9600, 0.4200])\n",
      "Predicted: 15.17, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.7900])\n",
      "Predicted: 3.83, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9600, 0.2800])\n",
      "Predicted: 16.03, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.0000])\n",
      "Predicted: 14.83, Actual: 2.00\n",
      "Average loss on the testing dataset: 5.8910\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.6500])\n",
      "Predicted: 11.71, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.3300])\n",
      "Predicted: 15.65, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.4900, 0.2600])\n",
      "Predicted: 14.50, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.3100, 0.7300])\n",
      "Predicted: 2.48, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.3100])\n",
      "Predicted: 15.26, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.0000])\n",
      "Predicted: 16.39, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.6100])\n",
      "Predicted: 15.11, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.8400])\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2600, 0.2800])\n",
      "Predicted: 5.73, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7800, 0.6800])\n",
      "Predicted: 9.25, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.9000])\n",
      "Predicted: 0.44, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8500, 0.3800])\n",
      "Predicted: 15.65, Actual: 16.00\n",
      "tensor([1.0000, 1.0000, 0.4900, 0.6700])\n",
      "Predicted: 5.38, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.1500])\n",
      "Predicted: 15.00, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.3100])\n",
      "Predicted: 2.40, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5700, 0.8700])\n",
      "Predicted: 2.12, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.7542\n",
      "tensor([1.0000, 0.0000, 0.2500, 1.0000])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2400, 0.3200])\n",
      "Predicted: 5.30, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.8000])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4100, 0.3200])\n",
      "Predicted: 10.78, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.1100, 0.3100])\n",
      "Predicted: 2.22, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1500, 0.7100])\n",
      "Predicted: 1.07, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2800, 0.9600])\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1500, 0.4600])\n",
      "Predicted: 2.42, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.5500])\n",
      "Predicted: 14.22, Actual: 19.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.7600])\n",
      "Predicted: 1.40, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.9400])\n",
      "Predicted: 0.22, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9800, 0.8600])\n",
      "Predicted: 6.63, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.9300])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6200, 0.8600])\n",
      "Predicted: 2.29, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0300, 0.8200])\n",
      "Predicted: 0.34, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6300, 0.2700])\n",
      "Predicted: 15.04, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.6087\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.3200])\n",
      "Predicted: 15.93, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.6500, 0.8100])\n",
      "Predicted: 3.95, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.7300])\n",
      "Predicted: 1.83, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.3600])\n",
      "Predicted: 4.59, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.1000])\n",
      "Predicted: 2.25, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2500, 0.1400])\n",
      "Predicted: 6.02, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3500, 0.2900])\n",
      "Predicted: 8.95, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.3200, 0.6500])\n",
      "Predicted: 3.63, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.1700, 0.4200])\n",
      "Predicted: 2.96, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3000, 0.3200])\n",
      "Predicted: 6.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5000, 0.9300])\n",
      "Predicted: 0.95, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.4200])\n",
      "Predicted: 15.35, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.6800])\n",
      "Predicted: 4.05, Actual: 4.00\n",
      "tensor([0.0000, 0.0000, 0.1000, 0.8300])\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.4300])\n",
      "Predicted: 15.49, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.1500, 0.8200])\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.5570\n",
      "tensor([0.0000, 1.0000, 0.3200, 0.3900])\n",
      "Predicted: 6.63, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.9800])\n",
      "Predicted: 1.49, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2900, 0.6800])\n",
      "Predicted: 2.65, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.2900])\n",
      "Predicted: 15.02, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.6600])\n",
      "Predicted: 3.31, Actual: 19.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.2100])\n",
      "Predicted: 15.32, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.9300])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.9500])\n",
      "Predicted: 0.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.9400])\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.0900])\n",
      "Predicted: 2.46, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.7500])\n",
      "Predicted: 7.23, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4700, 0.0100])\n",
      "Predicted: 14.60, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.2700, 0.2300])\n",
      "Predicted: 5.94, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.5800])\n",
      "Predicted: 2.56, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.7800])\n",
      "Predicted: 2.57, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.7200])\n",
      "Predicted: 2.59, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.5744\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.8900])\n",
      "Predicted: 1.34, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.9600])\n",
      "Predicted: 0.55, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.7500])\n",
      "Predicted: 4.65, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7100, 0.6800])\n",
      "Predicted: 7.79, Actual: 19.00\n",
      "tensor([1.0000, 0.0000, 0.1000, 0.5800])\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.4300])\n",
      "Predicted: 12.62, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.3600])\n",
      "Predicted: 14.91, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.4100])\n",
      "Predicted: 7.28, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.4900, 0.4800])\n",
      "Predicted: 11.62, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.3600])\n",
      "Predicted: 14.97, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.9700])\n",
      "Predicted: 2.38, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3600, 0.2800])\n",
      "Predicted: 8.59, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.9700])\n",
      "Predicted: 2.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.4700])\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.8100])\n",
      "Predicted: 2.23, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3700, 0.1300])\n",
      "Predicted: 12.38, Actual: 16.00\n",
      "Average loss on the testing dataset: 5.5589\n",
      "tensor([0.0000, 1.0000, 0.5100, 0.4000])\n",
      "Predicted: 13.04, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.8000])\n",
      "Predicted: 4.72, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.0600])\n",
      "Predicted: 5.25, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.6700])\n",
      "Predicted: 0.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4400, 0.5600])\n",
      "Predicted: 7.89, Actual: 11.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.0600])\n",
      "Predicted: 15.96, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.1100])\n",
      "Predicted: 15.17, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.2100])\n",
      "Predicted: 4.88, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.3800])\n",
      "Predicted: 9.34, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.8600])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1700, 0.1100])\n",
      "Predicted: 4.12, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.6600])\n",
      "Predicted: 4.49, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.2300])\n",
      "Predicted: 15.84, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.6000])\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1000, 0.1600])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.5000])\n",
      "Predicted: 1.13, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.7201\n",
      "tensor([1.0000, 0.0000, 0.4800, 0.9100])\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3200, 0.6400])\n",
      "Predicted: 3.74, Actual: 30.00\n",
      "tensor([1.0000, 0.0000, 0.9400, 0.2000])\n",
      "Predicted: 16.06, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.7200])\n",
      "Predicted: 2.59, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0200, 0.8200])\n",
      "Predicted: 0.44, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.7400])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.5200])\n",
      "Predicted: 6.04, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.0300])\n",
      "Predicted: 15.18, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.3300, 0.8800])\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.1700])\n",
      "Predicted: 15.87, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.5300, 0.8100])\n",
      "Predicted: 2.90, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8100, 0.8000])\n",
      "Predicted: 6.14, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.1800])\n",
      "Predicted: 8.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.0600])\n",
      "Predicted: 6.16, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.4200])\n",
      "Predicted: 14.99, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.0000])\n",
      "Predicted: 15.80, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9428\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.9500])\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8000, 0.1700])\n",
      "Predicted: 15.80, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.8900])\n",
      "Predicted: 6.15, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.6500])\n",
      "Predicted: 9.70, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.7100, 0.9100])\n",
      "Predicted: 2.27, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8400, 0.6000])\n",
      "Predicted: 12.12, Actual: 28.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.4000])\n",
      "Predicted: 14.88, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.7200, 0.4400])\n",
      "Predicted: 15.24, Actual: 21.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.9400])\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.4900])\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.0800])\n",
      "Predicted: 15.81, Actual: 22.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.4000])\n",
      "Predicted: 9.04, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.2100])\n",
      "Predicted: 16.11, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.7000, 0.7800])\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.4300])\n",
      "Predicted: 6.99, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.9900, 0.2900])\n",
      "Predicted: 16.03, Actual: 26.00\n",
      "Average loss on the testing dataset: 5.9786\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.1900])\n",
      "Predicted: 14.82, Actual: 4.00\n",
      "tensor([0.0000, 0.0000, 0.2800, 0.1600])\n",
      "Predicted: 8.56, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4800, 0.6300])\n",
      "Predicted: 6.36, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.0000, 0.3200])\n",
      "Predicted: 1.14, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1200, 0.6700])\n",
      "Predicted: 1.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7600, 0.1600])\n",
      "Predicted: 15.43, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.0600])\n",
      "Predicted: 2.67, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8800, 0.1800])\n",
      "Predicted: 15.67, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.1500])\n",
      "Predicted: 15.17, Actual: 17.00\n",
      "tensor([1.0000, 0.0000, 0.3300, 0.0300])\n",
      "Predicted: 11.44, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.0500])\n",
      "Predicted: 15.49, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.6500, 0.2200])\n",
      "Predicted: 15.02, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.8500, 0.8200])\n",
      "Predicted: 4.93, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5700, 0.5700])\n",
      "Predicted: 8.59, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.3100])\n",
      "Predicted: 1.32, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.4700])\n",
      "Predicted: 7.73, Actual: 30.00\n",
      "Average loss on the testing dataset: 6.0559\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.8700])\n",
      "Predicted: 0.32, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.4500])\n",
      "Predicted: 15.09, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.2700, 0.2100])\n",
      "Predicted: 6.09, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.8500])\n",
      "Predicted: 1.71, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9200, 0.2800])\n",
      "Predicted: 15.55, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 0.6700])\n",
      "Predicted: 1.11, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8300, 0.7300])\n",
      "Predicted: 7.28, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1400, 0.8000])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 1.0000, 0.5300])\n",
      "Predicted: 14.92, Actual: 6.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.4700])\n",
      "Predicted: 14.92, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.1900, 0.7200])\n",
      "Predicted: 1.43, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.0400])\n",
      "Predicted: 14.81, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.4800, 0.0700])\n",
      "Predicted: 14.75, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.0400])\n",
      "Predicted: 4.06, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.2400])\n",
      "Predicted: 9.14, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 1.0000])\n",
      "Predicted: 0.24, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1295\n",
      "tensor([1.0000, 0.0000, 0.9400, 0.1200])\n",
      "Predicted: 16.14, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.2600])\n",
      "Predicted: 15.83, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.0900])\n",
      "Predicted: 1.92, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4000, 0.6600])\n",
      "Predicted: 3.62, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.7200])\n",
      "Predicted: 8.61, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2000, 0.8600])\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9800, 0.3400])\n",
      "Predicted: 15.45, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.8600])\n",
      "Predicted: 2.51, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9900, 0.0500])\n",
      "Predicted: 16.40, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.8700])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.6100])\n",
      "Predicted: 8.80, Actual: 11.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.3700])\n",
      "Predicted: 6.60, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.4100, 0.8800])\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.6700])\n",
      "Predicted: 10.14, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.7800])\n",
      "Predicted: 0.33, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5800, 0.6000])\n",
      "Predicted: 7.68, Actual: 13.00\n",
      "Average loss on the testing dataset: 6.1585\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.9400])\n",
      "Predicted: 3.54, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.3500])\n",
      "Predicted: 14.97, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.8300, 0.0900])\n",
      "Predicted: 15.67, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.5000])\n",
      "Predicted: 11.82, Actual: 2.00\n",
      "tensor([0.0000, 1.0000, 0.8200, 0.3500])\n",
      "Predicted: 15.24, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.5200, 0.9100])\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6500, 0.0600])\n",
      "Predicted: 15.43, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.2500, 0.8000])\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.0500])\n",
      "Predicted: 12.88, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.9000])\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 0.5000])\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 0.1400])\n",
      "Predicted: 13.75, Actual: 13.00\n",
      "tensor([0.0000, 0.0000, 0.1800, 0.2500])\n",
      "Predicted: 4.18, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1200, 0.2800])\n",
      "Predicted: 2.52, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.8400])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.8900])\n",
      "Predicted: 0.40, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1163\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.0000])\n",
      "Predicted: 14.11, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 0.8100])\n",
      "Predicted: 1.91, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0200, 0.8300])\n",
      "Predicted: 0.43, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.2400])\n",
      "Predicted: 15.70, Actual: 14.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.4500])\n",
      "Predicted: 2.62, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.1900])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.1900])\n",
      "Predicted: 16.01, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.2000])\n",
      "Predicted: 15.85, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.6400, 0.5800])\n",
      "Predicted: 11.00, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.3000])\n",
      "Predicted: 5.34, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9900, 0.6300])\n",
      "Predicted: 14.47, Actual: 27.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.7500])\n",
      "Predicted: 11.12, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1100, 0.9800])\n",
      "Predicted: 0.20, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7400, 0.2600])\n",
      "Predicted: 15.57, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.0700, 0.4300])\n",
      "Predicted: 1.40, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.0600])\n",
      "Predicted: 15.15, Actual: 27.00\n",
      "Average loss on the testing dataset: 6.1484\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.1400])\n",
      "Predicted: 3.41, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9200, 0.2700])\n",
      "Predicted: 15.58, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.0700])\n",
      "Predicted: 15.36, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.2000])\n",
      "Predicted: 15.82, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.4600, 0.0800])\n",
      "Predicted: 14.67, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.0200])\n",
      "Predicted: 16.14, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.3600])\n",
      "Predicted: 3.49, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3200, 0.3400])\n",
      "Predicted: 6.91, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.9000])\n",
      "Predicted: 0.34, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2800, 0.3200])\n",
      "Predicted: 5.93, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.3500])\n",
      "Predicted: 15.10, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.4000])\n",
      "Predicted: 15.02, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.0400, 0.1800])\n",
      "Predicted: 2.65, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7000, 0.5900])\n",
      "Predicted: 10.19, Actual: 24.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.3700])\n",
      "Predicted: 14.61, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3000, 0.4700])\n",
      "Predicted: 5.08, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1885\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.7100])\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6700, 1.0000])\n",
      "Predicted: 1.17, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8400, 0.4400])\n",
      "Predicted: 15.01, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.0100])\n",
      "Predicted: 14.44, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.6600])\n",
      "Predicted: 14.12, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.4200, 0.4900])\n",
      "Predicted: 7.75, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.5200, 0.6900])\n",
      "Predicted: 5.24, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.9900, 0.6000])\n",
      "Predicted: 14.70, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.2100])\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7800, 0.0400])\n",
      "Predicted: 15.86, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.5100, 0.9800])\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4100, 0.5600])\n",
      "Predicted: 7.07, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.2200, 0.0400])\n",
      "Predicted: 8.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9200, 0.3600])\n",
      "Predicted: 15.30, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.2500])\n",
      "Predicted: 2.83, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.3400])\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2557\n",
      "tensor([0.0000, 1.0000, 0.2300, 0.8300])\n",
      "Predicted: 1.03, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 1.0000, 0.7500])\n",
      "Predicted: 8.91, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.8200])\n",
      "Predicted: 1.19, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1500, 0.3300])\n",
      "Predicted: 2.77, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.5300])\n",
      "Predicted: 12.77, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.9900, 0.4000])\n",
      "Predicted: 15.28, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.2800])\n",
      "Predicted: 15.94, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.2800, 0.9700])\n",
      "Predicted: 0.53, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2300, 0.2600])\n",
      "Predicted: 4.65, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.0000])\n",
      "Predicted: 16.32, Actual: 13.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.6400])\n",
      "Predicted: 1.47, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.4500])\n",
      "Predicted: 15.35, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.6000])\n",
      "Predicted: 15.14, Actual: 14.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.4700])\n",
      "Predicted: 15.39, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.1500])\n",
      "Predicted: 15.77, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.5000, 0.6100])\n",
      "Predicted: 5.96, Actual: 12.00\n",
      "Average loss on the testing dataset: 6.1610\n",
      "tensor([0.0000, 1.0000, 0.3800, 0.2800])\n",
      "Predicted: 10.23, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.7600])\n",
      "Predicted: 4.39, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9500, 0.0500])\n",
      "Predicted: 15.85, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.0200, 0.2300])\n",
      "Predicted: 1.76, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.1200])\n",
      "Predicted: 11.79, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.6000])\n",
      "Predicted: 6.98, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.4200])\n",
      "Predicted: 15.59, Actual: 14.00\n",
      "tensor([1.0000, 1.0000, 0.2500, 0.0200])\n",
      "Predicted: 6.97, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.3300])\n",
      "Predicted: 15.79, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.4900, 0.4000])\n",
      "Predicted: 12.51, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.6600, 0.9700])\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2200, 0.4600])\n",
      "Predicted: 2.99, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1900, 0.7300])\n",
      "Predicted: 1.46, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.1900])\n",
      "Predicted: 6.95, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.4300])\n",
      "Predicted: 15.14, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.7900])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1675\n",
      "tensor([1.0000, 0.0000, 0.7300, 0.6500])\n",
      "Predicted: 9.37, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.1500])\n",
      "Predicted: 15.18, Actual: 15.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.0300])\n",
      "Predicted: 14.99, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 0.0200])\n",
      "Predicted: 3.17, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.0500])\n",
      "Predicted: 3.59, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9300, 0.6100])\n",
      "Predicted: 14.09, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.2100, 0.7100])\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.5200])\n",
      "Predicted: 2.01, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.0500])\n",
      "Predicted: 16.27, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.5900])\n",
      "Predicted: 10.84, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.7100, 0.7800])\n",
      "Predicted: 4.71, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.0800])\n",
      "Predicted: 14.20, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.8300])\n",
      "Predicted: 7.57, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.3200])\n",
      "Predicted: 14.98, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.8400])\n",
      "Predicted: 1.99, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2000, 0.9000])\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0437\n",
      "tensor([0.0000, 1.0000, 0.5700, 0.5600])\n",
      "Predicted: 9.27, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.1900])\n",
      "Predicted: 9.08, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.9500])\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3800, 0.6800])\n",
      "Predicted: 3.89, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.2600])\n",
      "Predicted: 2.05, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1400, 0.6100])\n",
      "Predicted: 1.22, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5200, 0.9500])\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.9300])\n",
      "Predicted: 3.76, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.1000])\n",
      "Predicted: 16.10, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.0800])\n",
      "Predicted: 10.30, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.3900])\n",
      "Predicted: 2.03, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.8900])\n",
      "Predicted: 2.29, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.3800])\n",
      "Predicted: 15.20, Actual: 13.00\n",
      "tensor([0.0000, 0.0000, 0.8500, 0.5600])\n",
      "Predicted: 14.64, Actual: 24.00\n",
      "tensor([1.0000, 0.0000, 0.3800, 0.4400])\n",
      "Predicted: 7.80, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.3600])\n",
      "Predicted: 15.36, Actual: 22.00\n",
      "Average loss on the testing dataset: 6.0819\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.0800])\n",
      "Predicted: 3.56, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.4700])\n",
      "Predicted: 13.09, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.1900, 0.9000])\n",
      "Predicted: 0.44, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.3300])\n",
      "Predicted: 15.12, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.4800, 0.6100])\n",
      "Predicted: 6.98, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.0500, 0.5300])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4300, 0.2000])\n",
      "Predicted: 12.41, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.5500, 0.1400])\n",
      "Predicted: 15.07, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.1700, 0.6600])\n",
      "Predicted: 1.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7100, 0.0900])\n",
      "Predicted: 15.24, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.4100, 0.2900])\n",
      "Predicted: 11.41, Actual: 24.00\n",
      "tensor([0.0000, 1.0000, 0.6000, 0.4300])\n",
      "Predicted: 14.88, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.5100])\n",
      "Predicted: 1.07, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.0300])\n",
      "Predicted: 2.49, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.1600])\n",
      "Predicted: 15.14, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.6100])\n",
      "Predicted: 11.60, Actual: 8.00\n",
      "Average loss on the testing dataset: 6.0620\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.4000])\n",
      "Predicted: 4.52, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.6300])\n",
      "Predicted: 12.01, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.0800, 0.3400])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9600, 0.0700])\n",
      "Predicted: 16.23, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.1100, 0.2600])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.2800])\n",
      "Predicted: 5.25, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.6500])\n",
      "Predicted: 8.31, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.6500, 0.6900])\n",
      "Predicted: 6.34, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.8300])\n",
      "Predicted: 4.37, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.5500])\n",
      "Predicted: 7.11, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 0.4300])\n",
      "Predicted: 1.99, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.5400])\n",
      "Predicted: 14.77, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.9500])\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.5300])\n",
      "Predicted: 1.14, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.3100])\n",
      "Predicted: 14.97, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.1100, 0.8300])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0670\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.7200])\n",
      "Predicted: 2.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7500, 0.9800])\n",
      "Predicted: 1.59, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8600, 0.9200])\n",
      "Predicted: 2.98, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3000, 0.8900])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.2200])\n",
      "Predicted: 16.06, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7200, 0.1600])\n",
      "Predicted: 15.23, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.4600])\n",
      "Predicted: 14.88, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.7200])\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.4000])\n",
      "Predicted: 4.16, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.1100])\n",
      "Predicted: 7.50, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.8500])\n",
      "Predicted: 1.31, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.0000])\n",
      "Predicted: 14.49, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.0300])\n",
      "Predicted: 14.76, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.6700])\n",
      "Predicted: 3.96, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.3800, 0.7000])\n",
      "Predicted: 2.72, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8600, 0.1700])\n",
      "Predicted: 15.52, Actual: 22.00\n",
      "Average loss on the testing dataset: 6.1068\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.2500])\n",
      "Predicted: 2.51, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9000, 0.4700])\n",
      "Predicted: 14.96, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.4200])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3000, 0.6400])\n",
      "Predicted: 3.41, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.7800])\n",
      "Predicted: 4.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.9700])\n",
      "Predicted: 0.20, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3700, 0.1000])\n",
      "Predicted: 13.57, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 1.0000])\n",
      "Predicted: 0.27, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.0900])\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.1500])\n",
      "Predicted: 10.55, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.0300, 0.6700])\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2100, 0.0900])\n",
      "Predicted: 5.23, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.8600])\n",
      "Predicted: 4.91, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.3300])\n",
      "Predicted: 15.12, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.8100, 0.0900])\n",
      "Predicted: 15.89, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.4000, 0.1600])\n",
      "Predicted: 13.63, Actual: 20.00\n",
      "Average loss on the testing dataset: 6.0177\n",
      "tensor([0.0000, 0.0000, 0.9300, 0.4800])\n",
      "Predicted: 14.97, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.0500, 0.8400])\n",
      "Predicted: 0.35, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.3800])\n",
      "Predicted: 15.13, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.5600])\n",
      "Predicted: 5.53, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.6200, 0.8500])\n",
      "Predicted: 2.27, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.5300])\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4200, 0.6900])\n",
      "Predicted: 3.75, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.7500, 0.6700])\n",
      "Predicted: 8.06, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.7100])\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0200, 0.1900])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.0600])\n",
      "Predicted: 14.89, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.2300, 0.5300])\n",
      "Predicted: 2.86, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.7600])\n",
      "Predicted: 0.70, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.2500])\n",
      "Predicted: 2.77, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.2100])\n",
      "Predicted: 15.74, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.2400, 0.6400])\n",
      "Predicted: 2.46, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0358\n",
      "tensor([0.0000, 1.0000, 0.6700, 0.1700])\n",
      "Predicted: 15.14, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.7600, 0.2200])\n",
      "Predicted: 15.75, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.2000])\n",
      "Predicted: 15.35, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.9100])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.1500])\n",
      "Predicted: 15.14, Actual: 27.00\n",
      "tensor([1.0000, 0.0000, 0.0200, 0.4100])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.4600])\n",
      "Predicted: 15.29, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.0300, 0.6800])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5600, 0.6400])\n",
      "Predicted: 6.51, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.0200])\n",
      "Predicted: 12.06, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.1100, 0.2000])\n",
      "Predicted: 3.65, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7600, 0.0600])\n",
      "Predicted: 15.41, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.0100, 0.7900])\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.9600])\n",
      "Predicted: 3.26, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.3400])\n",
      "Predicted: 14.96, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.7000, 0.2600])\n",
      "Predicted: 15.48, Actual: 14.00\n",
      "Average loss on the testing dataset: 6.0340\n",
      "tensor([1.0000, 0.0000, 0.2300, 0.3500])\n",
      "Predicted: 4.32, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8500, 0.2700])\n",
      "Predicted: 15.38, Actual: 28.00\n",
      "tensor([0.0000, 0.0000, 0.7200, 0.5200])\n",
      "Predicted: 13.66, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.6400])\n",
      "Predicted: 12.43, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.4800, 0.9400])\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.1600])\n",
      "Predicted: 15.63, Actual: 27.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.5000])\n",
      "Predicted: 10.85, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.4000])\n",
      "Predicted: 7.43, Actual: 10.00\n",
      "tensor([1.0000, 0.0000, 0.0300, 0.3100])\n",
      "Predicted: 1.35, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.6100])\n",
      "Predicted: 7.77, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.8600, 0.9800])\n",
      "Predicted: 2.13, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.5700])\n",
      "Predicted: 7.84, Actual: 28.00\n",
      "tensor([1.0000, 0.0000, 0.4600, 0.2300])\n",
      "Predicted: 14.75, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.4000])\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9900, 0.1600])\n",
      "Predicted: 15.93, Actual: 14.00\n",
      "tensor([1.0000, 0.0000, 0.5000, 0.6400])\n",
      "Predicted: 5.40, Actual: 14.00\n",
      "Average loss on the testing dataset: 6.1734\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.5600])\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.9300])\n",
      "Predicted: 0.36, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5200, 0.9600])\n",
      "Predicted: 1.11, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6500, 0.7000])\n",
      "Predicted: 6.03, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6000, 0.9300])\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4400, 0.0900])\n",
      "Predicted: 14.60, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.6100, 0.0800])\n",
      "Predicted: 15.28, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.4700])\n",
      "Predicted: 4.19, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.4200])\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.0300])\n",
      "Predicted: 14.99, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.3800])\n",
      "Predicted: 2.51, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3100, 0.2400])\n",
      "Predicted: 7.14, Actual: 6.00\n",
      "tensor([1.0000, 1.0000, 0.2700, 0.7500])\n",
      "Predicted: 2.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.6100])\n",
      "Predicted: 4.45, Actual: 14.00\n",
      "tensor([1.0000, 1.0000, 0.4300, 0.7500])\n",
      "Predicted: 3.07, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1900, 0.8200])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0847\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.7100])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.4600])\n",
      "Predicted: 1.24, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.4800])\n",
      "Predicted: 11.51, Actual: 21.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.0100])\n",
      "Predicted: 3.59, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.1500])\n",
      "Predicted: 15.60, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 0.2700])\n",
      "Predicted: 12.31, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.7600, 0.1400])\n",
      "Predicted: 15.73, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.0200, 0.1200])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6000, 0.1300])\n",
      "Predicted: 14.95, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.9500, 1.0000])\n",
      "Predicted: 2.42, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2900, 0.3800])\n",
      "Predicted: 5.43, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8200, 0.8300])\n",
      "Predicted: 4.35, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.3800])\n",
      "Predicted: 15.44, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.5900, 0.0400])\n",
      "Predicted: 15.18, Actual: 21.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.6600])\n",
      "Predicted: 1.51, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.8500])\n",
      "Predicted: 0.77, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0496\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.5900])\n",
      "Predicted: 4.29, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.4900, 0.3700])\n",
      "Predicted: 13.19, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.8900, 0.3100])\n",
      "Predicted: 15.43, Actual: 4.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.5500])\n",
      "Predicted: 3.89, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.4100, 0.3000])\n",
      "Predicted: 11.32, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.2600])\n",
      "Predicted: 15.16, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.4500, 0.1800])\n",
      "Predicted: 14.38, Actual: 11.00\n",
      "tensor([0.0000, 0.0000, 0.8400, 0.0400])\n",
      "Predicted: 15.63, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.8800])\n",
      "Predicted: 3.17, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7900, 0.6300])\n",
      "Predicted: 10.10, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.5000])\n",
      "Predicted: 10.43, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.6700])\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.3500])\n",
      "Predicted: 15.76, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.6700])\n",
      "Predicted: 0.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.9800])\n",
      "Predicted: 0.36, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6600, 0.1400])\n",
      "Predicted: 15.12, Actual: 30.00\n",
      "Average loss on the testing dataset: 6.0521\n",
      "tensor([0.0000, 1.0000, 0.8600, 0.4300])\n",
      "Predicted: 15.05, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.9600, 0.1400])\n",
      "Predicted: 16.16, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.5100])\n",
      "Predicted: 1.00, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.0400])\n",
      "Predicted: 15.97, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.6900])\n",
      "Predicted: 4.26, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.2800, 0.5100])\n",
      "Predicted: 4.27, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7600, 0.3200])\n",
      "Predicted: 15.71, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.4700, 0.4000])\n",
      "Predicted: 11.75, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.9000])\n",
      "Predicted: 3.50, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7400, 0.4900])\n",
      "Predicted: 14.73, Actual: 28.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.4400])\n",
      "Predicted: 15.06, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.2500])\n",
      "Predicted: 16.10, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.6300])\n",
      "Predicted: 6.99, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.9800, 0.7100])\n",
      "Predicted: 12.69, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.9200])\n",
      "Predicted: 0.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4900, 0.6300])\n",
      "Predicted: 5.23, Actual: 27.00\n",
      "Average loss on the testing dataset: 6.2365\n",
      "tensor([0.0000, 1.0000, 0.8000, 0.1300])\n",
      "Predicted: 15.56, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.7100, 0.4100])\n",
      "Predicted: 14.91, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.2900])\n",
      "Predicted: 5.05, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.7100])\n",
      "Predicted: 12.92, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7500, 0.4800])\n",
      "Predicted: 15.34, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.3300, 0.8200])\n",
      "Predicted: 1.59, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.6700])\n",
      "Predicted: 9.00, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.7300])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9900, 0.0300])\n",
      "Predicted: 15.95, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.2600])\n",
      "Predicted: 4.30, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1000, 0.5700])\n",
      "Predicted: 1.18, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8100, 0.9200])\n",
      "Predicted: 2.93, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.4700])\n",
      "Predicted: 4.19, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.0500])\n",
      "Predicted: 5.04, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.7500])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.3300])\n",
      "Predicted: 7.41, Actual: 25.00\n",
      "Average loss on the testing dataset: 6.2201\n",
      "tensor([0.0000, 0.0000, 0.4400, 0.5300])\n",
      "Predicted: 7.16, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.7300])\n",
      "Predicted: 1.83, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.5800])\n",
      "Predicted: 14.38, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.1200])\n",
      "Predicted: 15.38, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.4200, 0.7300])\n",
      "Predicted: 3.04, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2400, 0.0600])\n",
      "Predicted: 6.32, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.9000])\n",
      "Predicted: 5.57, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6700, 0.9700])\n",
      "Predicted: 1.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.1000])\n",
      "Predicted: 2.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.3000])\n",
      "Predicted: 1.49, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.7700])\n",
      "Predicted: 10.14, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.1800])\n",
      "Predicted: 2.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1900, 0.1400])\n",
      "Predicted: 6.16, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 1.0000])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.6800])\n",
      "Predicted: 13.45, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.1600])\n",
      "Predicted: 16.00, Actual: 30.00\n",
      "Average loss on the testing dataset: 6.2195\n",
      "tensor([1.0000, 1.0000, 0.1900, 0.5300])\n",
      "Predicted: 2.49, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.4200])\n",
      "Predicted: 14.86, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4900, 0.3800])\n",
      "Predicted: 12.62, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.8900])\n",
      "Predicted: 0.55, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.3100])\n",
      "Predicted: 3.31, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.2300])\n",
      "Predicted: 3.34, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7700, 0.1900])\n",
      "Predicted: 15.79, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.8200])\n",
      "Predicted: 1.19, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.2300])\n",
      "Predicted: 15.17, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.6000])\n",
      "Predicted: 9.25, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.2500, 0.7200])\n",
      "Predicted: 1.89, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7000, 0.5000])\n",
      "Predicted: 15.05, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.5400, 0.0300])\n",
      "Predicted: 14.97, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.6100])\n",
      "Predicted: 0.99, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.2700])\n",
      "Predicted: 14.92, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.9500, 0.4900])\n",
      "Predicted: 15.45, Actual: 25.00\n",
      "Average loss on the testing dataset: 6.3042\n",
      "tensor([1.0000, 1.0000, 0.4500, 0.3200])\n",
      "Predicted: 11.95, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.2200, 0.7300])\n",
      "Predicted: 1.28, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.1100])\n",
      "Predicted: 15.77, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.1400, 0.1700])\n",
      "Predicted: 3.45, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.9900])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.1800])\n",
      "Predicted: 2.28, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.7900])\n",
      "Predicted: 7.49, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.0100])\n",
      "Predicted: 15.95, Actual: 21.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.2800])\n",
      "Predicted: 3.08, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7700, 0.4800])\n",
      "Predicted: 15.20, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.9300])\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.2500])\n",
      "Predicted: 15.61, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.0100, 0.1500])\n",
      "Predicted: 2.43, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0100, 1.0000])\n",
      "Predicted: 0.19, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5100, 0.3300])\n",
      "Predicted: 14.91, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 1.0000])\n",
      "Predicted: 0.87, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2906\n",
      "tensor([1.0000, 0.0000, 0.7800, 0.7400])\n",
      "Predicted: 7.02, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1300, 0.1000])\n",
      "Predicted: 5.05, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.9500])\n",
      "Predicted: 0.42, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3900, 0.2800])\n",
      "Predicted: 10.58, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.1700, 0.6800])\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9700, 0.2700])\n",
      "Predicted: 15.64, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.2300, 0.2800])\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8500, 0.2800])\n",
      "Predicted: 15.48, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.1900, 0.9700])\n",
      "Predicted: 0.41, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0200, 0.0600])\n",
      "Predicted: 3.07, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.8100])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.8400])\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0400, 0.2100])\n",
      "Predicted: 2.47, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9400, 0.4800])\n",
      "Predicted: 14.98, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.9600, 0.9900])\n",
      "Predicted: 2.63, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2300, 0.5200])\n",
      "Predicted: 3.20, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2262\n",
      "tensor([0.0000, 0.0000, 0.9900, 0.1300])\n",
      "Predicted: 15.84, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.2800, 0.6700])\n",
      "Predicted: 2.81, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4100, 0.0400])\n",
      "Predicted: 14.45, Actual: 13.00\n",
      "tensor([0.0000, 1.0000, 0.6400, 0.5300])\n",
      "Predicted: 11.56, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.5600])\n",
      "Predicted: 8.42, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.2100, 0.9400])\n",
      "Predicted: 0.57, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1700, 0.5100])\n",
      "Predicted: 2.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.2700])\n",
      "Predicted: 15.17, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.0500, 0.1300])\n",
      "Predicted: 2.13, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3300, 0.4700])\n",
      "Predicted: 5.76, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.6900, 0.9300])\n",
      "Predicted: 1.90, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.4500])\n",
      "Predicted: 15.54, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.3600, 0.4900])\n",
      "Predicted: 6.66, Actual: 24.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.5000])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3200, 0.6800])\n",
      "Predicted: 2.38, Actual: 6.00\n",
      "tensor([0.0000, 1.0000, 0.5100, 0.5300])\n",
      "Predicted: 9.45, Actual: 14.00\n",
      "Average loss on the testing dataset: 6.2654\n",
      "tensor([0.0000, 0.0000, 0.8500, 0.0500])\n",
      "Predicted: 15.63, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.7800, 0.7900])\n",
      "Predicted: 5.46, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1200, 0.9100])\n",
      "Predicted: 0.38, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.6900])\n",
      "Predicted: 11.14, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.9800])\n",
      "Predicted: 2.57, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6200, 0.2800])\n",
      "Predicted: 15.38, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.9000])\n",
      "Predicted: 3.08, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.6900])\n",
      "Predicted: 7.92, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.7100])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.9200])\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.2700])\n",
      "Predicted: 15.44, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.6400, 0.0200])\n",
      "Predicted: 15.36, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.1600])\n",
      "Predicted: 14.84, Actual: 28.00\n",
      "tensor([1.0000, 0.0000, 0.4400, 0.4200])\n",
      "Predicted: 10.52, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.8500])\n",
      "Predicted: 4.87, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.6400])\n",
      "Predicted: 3.09, Actual: 23.00\n",
      "Average loss on the testing dataset: 6.3636\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.0900])\n",
      "Predicted: 4.92, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.1700])\n",
      "Predicted: 14.92, Actual: 30.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.4600])\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1000, 0.4400])\n",
      "Predicted: 1.56, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.4700])\n",
      "Predicted: 4.54, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1400, 0.1300])\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.4000])\n",
      "Predicted: 7.14, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.7600])\n",
      "Predicted: 6.07, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.8400])\n",
      "Predicted: 0.88, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.1000])\n",
      "Predicted: 14.72, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.9900, 0.2700])\n",
      "Predicted: 16.09, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.1800])\n",
      "Predicted: 4.05, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9100, 0.4500])\n",
      "Predicted: 15.52, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.6600, 0.2400])\n",
      "Predicted: 15.41, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.1900, 0.1400])\n",
      "Predicted: 4.86, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.4700])\n",
      "Predicted: 3.18, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.3920\n",
      "tensor([0.0000, 0.0000, 0.6900, 0.4000])\n",
      "Predicted: 14.88, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.0500])\n",
      "Predicted: 15.08, Actual: 6.00\n",
      "tensor([1.0000, 1.0000, 0.7500, 0.4800])\n",
      "Predicted: 15.34, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.6000, 0.9800])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8400, 0.1300])\n",
      "Predicted: 15.65, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.1700, 0.4900])\n",
      "Predicted: 2.06, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.6600])\n",
      "Predicted: 14.27, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.1600])\n",
      "Predicted: 15.43, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.4700])\n",
      "Predicted: 1.15, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7500, 0.3100])\n",
      "Predicted: 15.54, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.0700, 0.0200])\n",
      "Predicted: 2.93, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.1700])\n",
      "Predicted: 16.03, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.2900, 0.6600])\n",
      "Predicted: 2.43, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.4000])\n",
      "Predicted: 6.80, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.8200])\n",
      "Predicted: 6.42, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7400, 0.9500])\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4000\n",
      "tensor([1.0000, 1.0000, 0.1900, 0.3300])\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9100, 0.6400])\n",
      "Predicted: 13.90, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.8100, 0.6900])\n",
      "Predicted: 9.51, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.7500])\n",
      "Predicted: 3.25, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.7700])\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.3400])\n",
      "Predicted: 15.21, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.0000])\n",
      "Predicted: 14.94, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.4800])\n",
      "Predicted: 1.13, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.3500])\n",
      "Predicted: 1.47, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7900, 0.1100])\n",
      "Predicted: 15.44, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.4800])\n",
      "Predicted: 14.91, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.7300])\n",
      "Predicted: 6.94, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.3300])\n",
      "Predicted: 15.83, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.0600])\n",
      "Predicted: 15.35, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.0500, 0.4900])\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.1700])\n",
      "Predicted: 15.27, Actual: 12.00\n",
      "Average loss on the testing dataset: 6.3738\n",
      "tensor([1.0000, 0.0000, 0.2600, 0.7600])\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3700, 0.5300])\n",
      "Predicted: 6.52, Actual: 22.00\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.1600])\n",
      "Predicted: 2.87, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6900, 0.3200])\n",
      "Predicted: 15.59, Actual: 10.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.1200])\n",
      "Predicted: 7.35, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.2600])\n",
      "Predicted: 15.64, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.1000])\n",
      "Predicted: 16.00, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.0600])\n",
      "Predicted: 4.05, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5100, 0.0500])\n",
      "Predicted: 14.70, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.4100])\n",
      "Predicted: 15.12, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.7500, 1.0000])\n",
      "Predicted: 1.41, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.1300])\n",
      "Predicted: 15.90, Actual: 30.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.9300])\n",
      "Predicted: 0.38, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.3100])\n",
      "Predicted: 8.10, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.0100])\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.3200])\n",
      "Predicted: 15.08, Actual: 2.00\n",
      "Average loss on the testing dataset: 6.3972\n",
      "tensor([0.0000, 1.0000, 0.4700, 0.3400])\n",
      "Predicted: 12.55, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.1400])\n",
      "Predicted: 5.88, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.9500])\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.9200])\n",
      "Predicted: 0.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9500, 0.8700])\n",
      "Predicted: 6.11, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.7200])\n",
      "Predicted: 4.39, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2600, 0.5400])\n",
      "Predicted: 3.30, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.5800])\n",
      "Predicted: 7.58, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.5100])\n",
      "Predicted: 3.83, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2900, 0.3200])\n",
      "Predicted: 5.87, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.1300])\n",
      "Predicted: 6.57, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6800, 0.6600])\n",
      "Predicted: 7.93, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.4000, 0.5200])\n",
      "Predicted: 7.58, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.6500, 0.5200])\n",
      "Predicted: 12.19, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.5000, 0.8300])\n",
      "Predicted: 2.40, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.0100])\n",
      "Predicted: 5.57, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4267\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.0900])\n",
      "Predicted: 12.69, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.9200])\n",
      "Predicted: 1.12, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.9100])\n",
      "Predicted: 4.02, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.2900])\n",
      "Predicted: 15.66, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.4100])\n",
      "Predicted: 7.28, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.4400])\n",
      "Predicted: 13.12, Actual: 2.00\n",
      "tensor([0.0000, 1.0000, 0.0400, 0.2700])\n",
      "Predicted: 2.13, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.9800])\n",
      "Predicted: 0.21, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5700, 0.5200])\n",
      "Predicted: 12.08, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.0900, 0.4800])\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.3400])\n",
      "Predicted: 7.81, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.0300, 0.9800])\n",
      "Predicted: 0.16, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9300, 0.5000])\n",
      "Predicted: 14.93, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.3900])\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.8200])\n",
      "Predicted: 3.95, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.2800])\n",
      "Predicted: 14.82, Actual: 2.00\n",
      "Average loss on the testing dataset: 6.5054\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.7100])\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.9600])\n",
      "Predicted: 3.10, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9600, 0.0200])\n",
      "Predicted: 16.33, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.4700, 0.6200])\n",
      "Predicted: 5.51, Actual: 22.00\n",
      "tensor([0.0000, 0.0000, 0.9300, 0.7100])\n",
      "Predicted: 9.76, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7200, 0.9900])\n",
      "Predicted: 1.36, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.4800])\n",
      "Predicted: 4.42, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5100, 1.0000])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8200, 0.2500])\n",
      "Predicted: 15.46, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.1600])\n",
      "Predicted: 4.97, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.9800])\n",
      "Predicted: 0.94, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.1500])\n",
      "Predicted: 12.68, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.4600])\n",
      "Predicted: 1.17, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 0.0600])\n",
      "Predicted: 14.51, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.1800, 0.5800])\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.6200])\n",
      "Predicted: 3.38, Actual: 26.00\n",
      "Average loss on the testing dataset: 6.5446\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.0300])\n",
      "Predicted: 9.43, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.3800])\n",
      "Predicted: 15.65, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.7900])\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 0.3900])\n",
      "Predicted: 10.18, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.7900])\n",
      "Predicted: 3.52, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.0400])\n",
      "Predicted: 15.71, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.5100, 0.5900])\n",
      "Predicted: 6.77, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.2600])\n",
      "Predicted: 15.84, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.0800, 0.0600])\n",
      "Predicted: 2.91, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.9000])\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0300, 0.4800])\n",
      "Predicted: 1.20, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.5800])\n",
      "Predicted: 0.90, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 1.0000, 0.4900])\n",
      "Predicted: 15.03, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.5700, 0.2800])\n",
      "Predicted: 14.88, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.7100])\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0400, 0.9200])\n",
      "Predicted: 0.31, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.5044\n",
      "tensor([1.0000, 0.0000, 0.9200, 0.3000])\n",
      "Predicted: 15.88, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.3500])\n",
      "Predicted: 14.61, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8300, 0.6700])\n",
      "Predicted: 9.23, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.2000])\n",
      "Predicted: 15.00, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.5800, 0.3700])\n",
      "Predicted: 15.31, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.7600, 0.0800])\n",
      "Predicted: 15.70, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.7900, 0.9700])\n",
      "Predicted: 1.87, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6700, 0.7100])\n",
      "Predicted: 6.06, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.3000])\n",
      "Predicted: 12.22, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.0000])\n",
      "Predicted: 6.45, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.4400])\n",
      "Predicted: 15.45, Actual: 30.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.9700])\n",
      "Predicted: 0.34, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2700, 0.1600])\n",
      "Predicted: 8.18, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7300, 0.3300])\n",
      "Predicted: 15.05, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 1.0000, 0.4400])\n",
      "Predicted: 15.18, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.1300])\n",
      "Predicted: 14.65, Actual: 17.00\n",
      "Average loss on the testing dataset: 6.5537\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.0900])\n",
      "Predicted: 4.70, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.3700])\n",
      "Predicted: 15.13, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.2800, 0.4400])\n",
      "Predicted: 4.77, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4500, 0.3200])\n",
      "Predicted: 11.95, Actual: 14.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.2800])\n",
      "Predicted: 9.93, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.4300])\n",
      "Predicted: 2.49, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.2100])\n",
      "Predicted: 15.74, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.9900])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4000, 0.2000])\n",
      "Predicted: 12.81, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.4900, 0.4300])\n",
      "Predicted: 11.53, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.2300])\n",
      "Predicted: 8.31, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.6600, 0.2000])\n",
      "Predicted: 15.45, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.9600])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1100, 0.9900])\n",
      "Predicted: 0.32, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.0800])\n",
      "Predicted: 14.72, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.5800])\n",
      "Predicted: 10.74, Actual: 30.00\n",
      "Average loss on the testing dataset: 6.5412\n",
      "tensor([1.0000, 1.0000, 0.4300, 0.8300])\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.7600])\n",
      "Predicted: 3.58, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.1400])\n",
      "Predicted: 7.47, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 1.0000])\n",
      "Predicted: 0.36, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.6200])\n",
      "Predicted: 12.37, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.9800, 0.9300])\n",
      "Predicted: 3.83, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.6100])\n",
      "Predicted: 14.82, Actual: 14.00\n",
      "tensor([1.0000, 0.0000, 0.4000, 0.3100])\n",
      "Predicted: 10.70, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.0500])\n",
      "Predicted: 7.32, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.4100])\n",
      "Predicted: 15.59, Actual: 13.00\n",
      "tensor([1.0000, 1.0000, 0.4900, 0.0500])\n",
      "Predicted: 14.75, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.9500])\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.1300])\n",
      "Predicted: 14.97, Actual: 11.00\n",
      "tensor([0.0000, 0.0000, 0.6200, 0.5500])\n",
      "Predicted: 10.30, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.5200])\n",
      "Predicted: 12.66, Actual: 13.00\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.2300])\n",
      "Predicted: 15.10, Actual: 26.00\n",
      "Average loss on the testing dataset: 6.4951\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.1400])\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.0800])\n",
      "Predicted: 9.56, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3000, 0.6800])\n",
      "Predicted: 2.37, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.7000])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.6700])\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3900, 0.7000])\n",
      "Predicted: 3.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.0700])\n",
      "Predicted: 15.59, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.5800, 0.2800])\n",
      "Predicted: 14.90, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.1000])\n",
      "Predicted: 14.85, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.5500, 0.7400])\n",
      "Predicted: 4.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6200, 0.1800])\n",
      "Predicted: 15.31, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.8200, 0.6000])\n",
      "Predicted: 12.21, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.7100])\n",
      "Predicted: 6.18, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.0300])\n",
      "Predicted: 16.04, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.3100])\n",
      "Predicted: 7.94, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.2800])\n",
      "Predicted: 2.60, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4642\n",
      "tensor([1.0000, 1.0000, 0.0100, 0.9200])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.8300])\n",
      "Predicted: 1.16, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.8900])\n",
      "Predicted: 4.24, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.5000])\n",
      "Predicted: 10.43, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.1100])\n",
      "Predicted: 12.26, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.0800])\n",
      "Predicted: 16.16, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.7100, 0.5900])\n",
      "Predicted: 11.48, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.4600])\n",
      "Predicted: 1.77, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5800, 0.7400])\n",
      "Predicted: 3.76, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1600, 0.5900])\n",
      "Predicted: 1.46, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8200, 0.9100])\n",
      "Predicted: 3.63, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7700, 0.8100])\n",
      "Predicted: 4.78, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.3600])\n",
      "Predicted: 6.83, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.0600])\n",
      "Predicted: 15.12, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.9200, 0.4400])\n",
      "Predicted: 15.07, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.7100])\n",
      "Predicted: 5.00, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4427\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.1400])\n",
      "Predicted: 14.42, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.6000, 0.5800])\n",
      "Predicted: 9.00, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.8300])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8100, 0.3800])\n",
      "Predicted: 15.53, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.5900])\n",
      "Predicted: 13.47, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.9800])\n",
      "Predicted: 3.02, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9100, 0.1600])\n",
      "Predicted: 16.15, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.3600])\n",
      "Predicted: 11.14, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.5900])\n",
      "Predicted: 14.50, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.2000, 0.6300])\n",
      "Predicted: 2.16, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7700, 0.3800])\n",
      "Predicted: 15.59, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.6600, 0.9300])\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.3200])\n",
      "Predicted: 15.32, Actual: 16.00\n",
      "tensor([1.0000, 1.0000, 0.9100, 0.0000])\n",
      "Predicted: 16.20, Actual: 15.00\n",
      "tensor([1.0000, 0.0000, 0.4500, 0.2300])\n",
      "Predicted: 14.47, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.3200, 0.5000])\n",
      "Predicted: 4.68, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4313\n",
      "tensor([0.0000, 1.0000, 1.0000, 0.5100])\n",
      "Predicted: 14.97, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.9300, 0.3300])\n",
      "Predicted: 15.86, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.0300])\n",
      "Predicted: 15.34, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.8500])\n",
      "Predicted: 3.73, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.7200])\n",
      "Predicted: 3.84, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.2700])\n",
      "Predicted: 4.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6700, 0.3900])\n",
      "Predicted: 15.03, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.4200, 0.6800])\n",
      "Predicted: 4.31, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.1000, 0.6100])\n",
      "Predicted: 1.05, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6600, 0.7100])\n",
      "Predicted: 5.89, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.0000])\n",
      "Predicted: 10.02, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5900, 0.5300])\n",
      "Predicted: 11.25, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.3900, 0.0600])\n",
      "Predicted: 14.39, Actual: 7.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.8000])\n",
      "Predicted: 0.58, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5100, 0.7800])\n",
      "Predicted: 2.41, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1600, 0.4000])\n",
      "Predicted: 2.61, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.4180\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.1900])\n",
      "Predicted: 16.02, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.7900, 0.3200])\n",
      "Predicted: 15.19, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.0700])\n",
      "Predicted: 14.20, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.8200])\n",
      "Predicted: 3.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5100, 0.0200])\n",
      "Predicted: 14.79, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.8700])\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.2100])\n",
      "Predicted: 15.86, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.9200])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 0.5200])\n",
      "Predicted: 7.60, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.5700, 0.0600])\n",
      "Predicted: 14.87, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.4900])\n",
      "Predicted: 15.35, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.3500, 0.5900])\n",
      "Predicted: 4.50, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.0000])\n",
      "Predicted: 13.11, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.5000, 0.4600])\n",
      "Predicted: 12.49, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.0300])\n",
      "Predicted: 7.23, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.6300])\n",
      "Predicted: 12.79, Actual: 13.00\n",
      "Average loss on the testing dataset: 6.3679\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.6600])\n",
      "Predicted: 11.50, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.3700, 0.5100])\n",
      "Predicted: 5.92, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.1500, 0.7000])\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8000, 0.1900])\n",
      "Predicted: 15.50, Actual: 16.00\n",
      "tensor([1.0000, 1.0000, 0.3900, 0.2900])\n",
      "Predicted: 9.69, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.3200])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.8200])\n",
      "Predicted: 3.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5300, 0.5600])\n",
      "Predicted: 8.67, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.7100, 0.4500])\n",
      "Predicted: 14.81, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.9100, 0.4200])\n",
      "Predicted: 15.59, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.0600, 0.1500])\n",
      "Predicted: 2.78, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.5300])\n",
      "Predicted: 15.11, Actual: 22.00\n",
      "tensor([0.0000, 0.0000, 0.3500, 0.2700])\n",
      "Predicted: 9.26, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.5000, 0.1200])\n",
      "Predicted: 14.84, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.9100])\n",
      "Predicted: 0.22, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.6800])\n",
      "Predicted: 11.34, Actual: 23.00\n",
      "Average loss on the testing dataset: 6.3751\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.9400])\n",
      "Predicted: 4.55, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2500, 0.0600])\n",
      "Predicted: 6.64, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.8500])\n",
      "Predicted: 1.10, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.2800])\n",
      "Predicted: 3.45, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.9700])\n",
      "Predicted: 1.50, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.6600])\n",
      "Predicted: 12.36, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.6500, 0.8200])\n",
      "Predicted: 3.16, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3700, 0.7400])\n",
      "Predicted: 2.76, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9400, 0.7000])\n",
      "Predicted: 11.92, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.9800])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6500, 0.9000])\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3300, 0.6800])\n",
      "Predicted: 3.42, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.2800])\n",
      "Predicted: 15.60, Actual: 13.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.7800])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.0800])\n",
      "Predicted: 14.41, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.5000, 0.2800])\n",
      "Predicted: 14.53, Actual: 4.00\n",
      "Average loss on the testing dataset: 6.3663\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.8000])\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6100, 0.7000])\n",
      "Predicted: 5.09, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2400, 0.5900])\n",
      "Predicted: 2.85, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2300, 0.0600])\n",
      "Predicted: 6.02, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.2200])\n",
      "Predicted: 15.17, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.2100, 0.7700])\n",
      "Predicted: 1.41, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.6700])\n",
      "Predicted: 1.32, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4500, 0.8300])\n",
      "Predicted: 1.91, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.6500])\n",
      "Predicted: 7.92, Actual: 22.00\n",
      "tensor([0.0000, 1.0000, 0.9700, 0.5100])\n",
      "Predicted: 14.94, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.8000])\n",
      "Predicted: 3.51, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2700, 0.6100])\n",
      "Predicted: 3.25, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.4600])\n",
      "Predicted: 15.58, Actual: 27.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.7100])\n",
      "Predicted: 5.98, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5300, 0.5400])\n",
      "Predicted: 9.43, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.9900])\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.3537\n",
      "tensor([1.0000, 0.0000, 0.0300, 0.1400])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4700, 0.6400])\n",
      "Predicted: 5.47, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.2300, 0.1900])\n",
      "Predicted: 5.60, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.7800])\n",
      "Predicted: 2.00, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.5400])\n",
      "Predicted: 15.05, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.1000])\n",
      "Predicted: 2.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7700, 0.3500])\n",
      "Predicted: 15.11, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.6800, 0.4100])\n",
      "Predicted: 15.27, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.2400, 0.4300])\n",
      "Predicted: 4.15, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4500, 0.9800])\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.2800])\n",
      "Predicted: 15.28, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.0000])\n",
      "Predicted: 3.85, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.2700])\n",
      "Predicted: 14.66, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.3000])\n",
      "Predicted: 15.77, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.0500, 0.2200])\n",
      "Predicted: 2.16, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.3700])\n",
      "Predicted: 15.66, Actual: 28.00\n",
      "Average loss on the testing dataset: 6.3286\n",
      "tensor([0.0000, 0.0000, 0.5700, 0.8100])\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.3400])\n",
      "Predicted: 15.09, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.5000])\n",
      "Predicted: 11.25, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.0500])\n",
      "Predicted: 4.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.5100])\n",
      "Predicted: 2.17, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2600, 0.2600])\n",
      "Predicted: 6.20, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7400, 0.8900])\n",
      "Predicted: 2.80, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.7700])\n",
      "Predicted: 0.91, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.1800])\n",
      "Predicted: 15.65, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.3100])\n",
      "Predicted: 14.95, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.6000])\n",
      "Predicted: 2.28, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0600, 0.8700])\n",
      "Predicted: 0.42, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.0100])\n",
      "Predicted: 15.22, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4800, 0.0700])\n",
      "Predicted: 14.49, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.8000])\n",
      "Predicted: 4.12, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8900, 0.4700])\n",
      "Predicted: 14.97, Actual: 7.00\n",
      "Average loss on the testing dataset: 6.3268\n",
      "tensor([1.0000, 0.0000, 0.0800, 0.8900])\n",
      "Predicted: 0.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7300, 0.1000])\n",
      "Predicted: 15.70, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.5200])\n",
      "Predicted: 15.32, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.5700])\n",
      "Predicted: 4.65, Actual: 7.00\n",
      "tensor([0.0000, 0.0000, 0.8600, 0.6100])\n",
      "Predicted: 12.60, Actual: 2.00\n",
      "tensor([1.0000, 0.0000, 0.7800, 0.0500])\n",
      "Predicted: 15.86, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.9700])\n",
      "Predicted: 0.30, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.4600])\n",
      "Predicted: 6.28, Actual: 13.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.9800])\n",
      "Predicted: 0.26, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.3500])\n",
      "Predicted: 15.63, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.8800, 0.2900])\n",
      "Predicted: 15.48, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.7400, 0.5400])\n",
      "Predicted: 14.55, Actual: 14.00\n",
      "tensor([0.0000, 0.0000, 0.1700, 0.9800])\n",
      "Predicted: 0.24, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.0100])\n",
      "Predicted: 7.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1500, 0.8700])\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.4700])\n",
      "Predicted: 2.75, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2815\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.5700])\n",
      "Predicted: 15.21, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.1000, 0.9600])\n",
      "Predicted: 0.22, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9600, 0.3800])\n",
      "Predicted: 15.29, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.3700, 0.9100])\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9200, 0.4300])\n",
      "Predicted: 15.53, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.2600])\n",
      "Predicted: 16.06, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.4500])\n",
      "Predicted: 14.38, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.9900, 0.8500])\n",
      "Predicted: 5.90, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.1200])\n",
      "Predicted: 15.87, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.5700, 0.8000])\n",
      "Predicted: 2.60, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.7900])\n",
      "Predicted: 1.19, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.6000])\n",
      "Predicted: 5.62, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.6100])\n",
      "Predicted: 11.21, Actual: 5.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.9200])\n",
      "Predicted: 3.11, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.9600])\n",
      "Predicted: 0.30, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.9300])\n",
      "Predicted: 2.38, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2670\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.8400])\n",
      "Predicted: 0.54, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4600, 0.4900])\n",
      "Predicted: 9.43, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.1700, 1.0000])\n",
      "Predicted: 0.33, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.9300])\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6800, 0.8100])\n",
      "Predicted: 4.27, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5400, 0.0800])\n",
      "Predicted: 14.94, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.1000, 0.3100])\n",
      "Predicted: 2.11, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.3100])\n",
      "Predicted: 8.42, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.5900])\n",
      "Predicted: 5.85, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.8900, 0.5200])\n",
      "Predicted: 14.84, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.0500, 0.7700])\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.3800])\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9900, 0.3100])\n",
      "Predicted: 15.54, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.1600])\n",
      "Predicted: 8.98, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.2700])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.3500])\n",
      "Predicted: 9.81, Actual: 28.00\n",
      "Average loss on the testing dataset: 6.2685\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.7800])\n",
      "Predicted: 3.20, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.6600])\n",
      "Predicted: 0.78, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.9300])\n",
      "Predicted: 3.04, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0600, 0.1200])\n",
      "Predicted: 3.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.0000])\n",
      "Predicted: 15.79, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.6700, 0.5100])\n",
      "Predicted: 12.90, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.4800, 0.4400])\n",
      "Predicted: 11.21, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.9600])\n",
      "Predicted: 1.43, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.8700])\n",
      "Predicted: 0.73, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5400, 0.3400])\n",
      "Predicted: 15.02, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.0400, 0.1700])\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6900, 0.6400])\n",
      "Predicted: 9.58, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.6800, 0.8500])\n",
      "Predicted: 2.92, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.6300])\n",
      "Predicted: 1.94, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.9600])\n",
      "Predicted: 0.73, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.1100])\n",
      "Predicted: 5.39, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2211\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.2800])\n",
      "Predicted: 14.80, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.9900, 0.9400])\n",
      "Predicted: 3.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2200, 0.9300])\n",
      "Predicted: 0.37, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 1.0000])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.6800])\n",
      "Predicted: 3.22, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.6000, 0.6900])\n",
      "Predicted: 5.52, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.0100])\n",
      "Predicted: 14.95, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.3700])\n",
      "Predicted: 15.61, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.5100, 0.4400])\n",
      "Predicted: 11.75, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.3100, 0.5100])\n",
      "Predicted: 5.00, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.6400])\n",
      "Predicted: 12.20, Actual: 28.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 1.0000])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9400, 0.5300])\n",
      "Predicted: 14.83, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.7500])\n",
      "Predicted: 0.95, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.5200])\n",
      "Predicted: 11.45, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.7500, 0.2200])\n",
      "Predicted: 15.72, Actual: 8.00\n",
      "Average loss on the testing dataset: 6.2207\n",
      "tensor([0.0000, 1.0000, 0.9700, 0.6900])\n",
      "Predicted: 10.69, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.4300])\n",
      "Predicted: 14.69, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.5800, 0.3400])\n",
      "Predicted: 14.73, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.4300, 0.8500])\n",
      "Predicted: 1.77, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9200, 0.8100])\n",
      "Predicted: 5.97, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7800, 0.0100])\n",
      "Predicted: 15.48, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.6800])\n",
      "Predicted: 11.82, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.4600])\n",
      "Predicted: 4.65, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6200, 0.1400])\n",
      "Predicted: 14.94, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.8800, 0.2100])\n",
      "Predicted: 15.64, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.4500, 0.2800])\n",
      "Predicted: 12.83, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.9300, 0.1100])\n",
      "Predicted: 15.86, Actual: 13.00\n",
      "tensor([0.0000, 0.0000, 0.2600, 0.7200])\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.8600])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.4200])\n",
      "Predicted: 15.58, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5300, 0.2500])\n",
      "Predicted: 15.05, Actual: 10.00\n",
      "Average loss on the testing dataset: 6.2179\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.4400])\n",
      "Predicted: 14.93, Actual: 28.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.8000])\n",
      "Predicted: 4.30, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2900, 0.7800])\n",
      "Predicted: 1.62, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3000, 0.1900])\n",
      "Predicted: 8.08, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6600, 0.7500])\n",
      "Predicted: 4.45, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1100, 0.7100])\n",
      "Predicted: 1.03, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9000, 1.0000])\n",
      "Predicted: 2.45, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.3800])\n",
      "Predicted: 3.31, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.7200])\n",
      "Predicted: 0.40, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8800, 0.8100])\n",
      "Predicted: 6.88, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.9300])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5400, 0.7000])\n",
      "Predicted: 4.41, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5300, 0.5200])\n",
      "Predicted: 11.24, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.9300, 0.5500])\n",
      "Predicted: 15.28, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.6600, 0.4400])\n",
      "Predicted: 15.36, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.0900, 0.5800])\n",
      "Predicted: 1.30, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1959\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.5100])\n",
      "Predicted: 13.79, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.5900])\n",
      "Predicted: 2.57, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.6500])\n",
      "Predicted: 2.74, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.2000])\n",
      "Predicted: 16.17, Actual: 24.00\n",
      "tensor([0.0000, 0.0000, 0.9200, 0.1900])\n",
      "Predicted: 15.62, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.7400])\n",
      "Predicted: 4.50, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.6300])\n",
      "Predicted: 10.17, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.8400])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.0100])\n",
      "Predicted: 3.62, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.4300])\n",
      "Predicted: 5.82, Actual: 14.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.5000])\n",
      "Predicted: 14.77, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.5600])\n",
      "Predicted: 0.83, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1300, 0.6900])\n",
      "Predicted: 1.22, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.3200])\n",
      "Predicted: 6.89, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.0300, 0.4900])\n",
      "Predicted: 1.17, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0500, 0.3800])\n",
      "Predicted: 1.37, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1774\n",
      "tensor([1.0000, 0.0000, 0.5500, 0.7000])\n",
      "Predicted: 4.54, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.4700])\n",
      "Predicted: 1.85, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.0500])\n",
      "Predicted: 15.80, Actual: 21.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.6100])\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2900, 0.6100])\n",
      "Predicted: 2.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.7900])\n",
      "Predicted: 1.32, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0700, 0.7100])\n",
      "Predicted: 0.66, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5300, 0.4800])\n",
      "Predicted: 11.72, Actual: 13.00\n",
      "tensor([0.0000, 1.0000, 0.3800, 0.2000])\n",
      "Predicted: 11.55, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.0400])\n",
      "Predicted: 14.68, Actual: 14.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.8100])\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.4000])\n",
      "Predicted: 10.07, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.4500])\n",
      "Predicted: 7.30, Actual: 13.00\n",
      "tensor([1.0000, 1.0000, 0.6100, 0.4600])\n",
      "Predicted: 15.27, Actual: 15.00\n",
      "tensor([1.0000, 0.0000, 0.0400, 0.1100])\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4900, 0.2600])\n",
      "Predicted: 14.66, Actual: 24.00\n",
      "Average loss on the testing dataset: 6.1425\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.8600])\n",
      "Predicted: 6.46, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3600, 0.0400])\n",
      "Predicted: 12.76, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.3000])\n",
      "Predicted: 15.26, Actual: 13.00\n",
      "tensor([0.0000, 1.0000, 0.4700, 0.2800])\n",
      "Predicted: 13.61, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.9500])\n",
      "Predicted: 0.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4600, 0.5500])\n",
      "Predicted: 7.58, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.1600])\n",
      "Predicted: 2.25, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4400, 0.6700])\n",
      "Predicted: 4.38, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.9200, 0.9600])\n",
      "Predicted: 2.80, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6600, 0.3700])\n",
      "Predicted: 15.06, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.6100])\n",
      "Predicted: 1.86, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3900, 0.1400])\n",
      "Predicted: 11.29, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.9500])\n",
      "Predicted: 0.32, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4700, 0.2600])\n",
      "Predicted: 13.97, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2000, 0.7100])\n",
      "Predicted: 1.65, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6400, 0.7700])\n",
      "Predicted: 4.14, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1880\n",
      "tensor([0.0000, 1.0000, 0.6900, 0.0900])\n",
      "Predicted: 15.23, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.0100])\n",
      "Predicted: 14.11, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.3100])\n",
      "Predicted: 15.41, Actual: 11.00\n",
      "tensor([0.0000, 1.0000, 0.8600, 0.3400])\n",
      "Predicted: 15.31, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.7100, 0.2900])\n",
      "Predicted: 15.06, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.8800, 0.4900])\n",
      "Predicted: 14.88, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.7600])\n",
      "Predicted: 1.25, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.1500])\n",
      "Predicted: 16.09, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.2900])\n",
      "Predicted: 4.01, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.5000])\n",
      "Predicted: 7.57, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.5300])\n",
      "Predicted: 3.69, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.8100])\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.1900])\n",
      "Predicted: 15.10, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.7500, 0.4100])\n",
      "Predicted: 15.37, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.4900])\n",
      "Predicted: 3.37, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.2700])\n",
      "Predicted: 12.77, Actual: 23.00\n",
      "Average loss on the testing dataset: 6.1893\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.3600])\n",
      "Predicted: 2.19, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.5000])\n",
      "Predicted: 14.82, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.4200, 0.4800])\n",
      "Predicted: 8.93, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.2400])\n",
      "Predicted: 15.10, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.1600])\n",
      "Predicted: 16.10, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.6200, 0.6400])\n",
      "Predicted: 8.30, Actual: 4.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 0.2700])\n",
      "Predicted: 2.22, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0400, 0.2100])\n",
      "Predicted: 2.47, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.4800])\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3900, 1.0000])\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.4000])\n",
      "Predicted: 15.37, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.1100])\n",
      "Predicted: 15.18, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.5200, 0.0600])\n",
      "Predicted: 14.63, Actual: 26.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.5600])\n",
      "Predicted: 8.61, Actual: 10.00\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.3200])\n",
      "Predicted: 15.73, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.0200, 0.5700])\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1820\n",
      "tensor([0.0000, 0.0000, 0.7400, 0.0100])\n",
      "Predicted: 15.35, Actual: 3.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.0400])\n",
      "Predicted: 15.73, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.8500, 0.4500])\n",
      "Predicted: 14.99, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.5300, 0.3700])\n",
      "Predicted: 14.36, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.4600, 0.5900])\n",
      "Predicted: 5.91, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.1300, 0.4500])\n",
      "Predicted: 2.03, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.4500])\n",
      "Predicted: 3.64, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0300, 0.5700])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.2700])\n",
      "Predicted: 4.00, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1400, 0.7700])\n",
      "Predicted: 0.93, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.2000])\n",
      "Predicted: 7.79, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5300, 0.8100])\n",
      "Predicted: 2.16, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4500, 0.9600])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.8800])\n",
      "Predicted: 1.47, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.5500])\n",
      "Predicted: 14.70, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.6200])\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1754\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.3200])\n",
      "Predicted: 14.93, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.5200, 0.9300])\n",
      "Predicted: 1.45, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.6200])\n",
      "Predicted: 0.58, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3200, 0.0100])\n",
      "Predicted: 11.23, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.2800, 0.0300])\n",
      "Predicted: 10.71, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9100, 0.0600])\n",
      "Predicted: 15.88, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.7400])\n",
      "Predicted: 1.13, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.0500])\n",
      "Predicted: 16.15, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.8200, 0.9300])\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9500, 0.9500])\n",
      "Predicted: 4.12, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7700, 0.1500])\n",
      "Predicted: 15.78, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.6900, 0.9100])\n",
      "Predicted: 2.13, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.0100])\n",
      "Predicted: 16.05, Actual: 5.00\n",
      "tensor([1.0000, 0.0000, 0.9400, 0.5000])\n",
      "Predicted: 15.37, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.5800])\n",
      "Predicted: 11.91, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.8800, 0.0400])\n",
      "Predicted: 15.84, Actual: 23.00\n",
      "Average loss on the testing dataset: 6.1781\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.9600])\n",
      "Predicted: 0.69, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.6600])\n",
      "Predicted: 9.49, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.3700])\n",
      "Predicted: 7.05, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.6100, 0.4700])\n",
      "Predicted: 13.51, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.7500, 0.5800])\n",
      "Predicted: 11.63, Actual: 22.00\n",
      "tensor([0.0000, 0.0000, 0.4500, 0.9600])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5700, 0.8900])\n",
      "Predicted: 1.63, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9500, 0.3400])\n",
      "Predicted: 15.40, Actual: 29.00\n",
      "tensor([0.0000, 0.0000, 0.5100, 0.5400])\n",
      "Predicted: 8.57, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.3000, 0.1200])\n",
      "Predicted: 7.85, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3700, 0.2500])\n",
      "Predicted: 10.35, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.1700, 0.2100])\n",
      "Predicted: 3.59, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.0400])\n",
      "Predicted: 9.23, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7500, 0.8900])\n",
      "Predicted: 2.64, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.1000])\n",
      "Predicted: 11.38, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.6600])\n",
      "Predicted: 11.57, Actual: 25.00\n",
      "Average loss on the testing dataset: 6.2083\n",
      "tensor([0.0000, 1.0000, 0.6800, 0.1000])\n",
      "Predicted: 15.19, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.1700, 0.1500])\n",
      "Predicted: 5.49, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.9000])\n",
      "Predicted: 0.79, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1900, 0.6500])\n",
      "Predicted: 1.88, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.0700])\n",
      "Predicted: 7.10, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0400, 0.6800])\n",
      "Predicted: 0.76, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2800, 0.3800])\n",
      "Predicted: 5.36, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6500, 0.7500])\n",
      "Predicted: 5.35, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.7700])\n",
      "Predicted: 3.87, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8100, 0.0700])\n",
      "Predicted: 15.92, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.6500])\n",
      "Predicted: 11.07, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.3700])\n",
      "Predicted: 10.55, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.1100, 0.9800])\n",
      "Predicted: 0.34, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.9700])\n",
      "Predicted: 0.32, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.2500])\n",
      "Predicted: 14.80, Actual: 13.00\n",
      "tensor([1.0000, 1.0000, 0.4600, 0.9400])\n",
      "Predicted: 1.16, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1978\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.3700])\n",
      "Predicted: 2.07, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2500, 0.1500])\n",
      "Predicted: 5.94, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.7600])\n",
      "Predicted: 2.20, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1600, 0.0400])\n",
      "Predicted: 6.34, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1500, 0.7700])\n",
      "Predicted: 0.83, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.3000])\n",
      "Predicted: 15.68, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.8500, 0.5900])\n",
      "Predicted: 14.96, Actual: 20.00\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.4300])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7400, 0.3500])\n",
      "Predicted: 15.64, Actual: 11.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.6700])\n",
      "Predicted: 0.76, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.9300])\n",
      "Predicted: 0.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.6900])\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.6800])\n",
      "Predicted: 1.77, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5600, 0.7400])\n",
      "Predicted: 4.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7300, 0.3800])\n",
      "Predicted: 15.09, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.0500, 0.7500])\n",
      "Predicted: 0.66, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1456\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.0600])\n",
      "Predicted: 16.10, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.2100])\n",
      "Predicted: 8.80, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.4800, 0.1900])\n",
      "Predicted: 14.82, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.1200, 0.2100])\n",
      "Predicted: 3.33, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.8100])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3800, 0.5300])\n",
      "Predicted: 6.34, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.9400, 0.0400])\n",
      "Predicted: 16.22, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.6800, 0.0200])\n",
      "Predicted: 15.38, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.2300, 0.2800])\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4000, 0.1000])\n",
      "Predicted: 14.23, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.3400])\n",
      "Predicted: 9.97, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.4600])\n",
      "Predicted: 15.05, Actual: 4.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.9700])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.3700])\n",
      "Predicted: 5.23, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7200, 0.0000])\n",
      "Predicted: 15.35, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.1700])\n",
      "Predicted: 2.03, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1513\n",
      "tensor([1.0000, 0.0000, 0.2700, 0.3400])\n",
      "Predicted: 5.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.2000])\n",
      "Predicted: 9.75, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.4500, 0.4000])\n",
      "Predicted: 11.31, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.7000, 0.3500])\n",
      "Predicted: 15.14, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.6400, 0.4500])\n",
      "Predicted: 14.72, Actual: 28.00\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.6100])\n",
      "Predicted: 14.58, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.1700])\n",
      "Predicted: 15.54, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.9800])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8400, 0.0900])\n",
      "Predicted: 15.99, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 1.0000])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8400, 0.5900])\n",
      "Predicted: 12.53, Actual: 17.00\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.3200])\n",
      "Predicted: 2.50, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.6600])\n",
      "Predicted: 5.45, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 0.9300])\n",
      "Predicted: 0.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2800, 0.1600])\n",
      "Predicted: 8.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4700, 0.1500])\n",
      "Predicted: 14.45, Actual: 25.00\n",
      "Average loss on the testing dataset: 6.1466\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.0100])\n",
      "Predicted: 16.10, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.5600])\n",
      "Predicted: 1.09, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.7900])\n",
      "Predicted: 0.64, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6600, 0.7400])\n",
      "Predicted: 5.75, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.6600])\n",
      "Predicted: 5.15, Actual: 6.00\n",
      "tensor([1.0000, 1.0000, 0.4000, 0.9100])\n",
      "Predicted: 1.16, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.7700])\n",
      "Predicted: 9.66, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.9700])\n",
      "Predicted: 2.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3100, 0.4500])\n",
      "Predicted: 5.42, Actual: 10.00\n",
      "tensor([0.0000, 1.0000, 0.8000, 0.9300])\n",
      "Predicted: 2.58, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0600, 0.5200])\n",
      "Predicted: 1.07, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2900, 0.1700])\n",
      "Predicted: 8.86, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3300, 0.1200])\n",
      "Predicted: 11.04, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.6600])\n",
      "Predicted: 7.27, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.4400, 0.1500])\n",
      "Predicted: 14.64, Actual: 30.00\n",
      "tensor([1.0000, 1.0000, 0.4900, 0.1400])\n",
      "Predicted: 14.82, Actual: 4.00\n",
      "Average loss on the testing dataset: 6.1452\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.0100])\n",
      "Predicted: 1.93, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1500, 0.6300])\n",
      "Predicted: 1.23, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.0000])\n",
      "Predicted: 16.05, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.3000])\n",
      "Predicted: 15.97, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.6700])\n",
      "Predicted: 1.35, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7600, 0.0000])\n",
      "Predicted: 15.47, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.8000])\n",
      "Predicted: 7.77, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3700, 0.4200])\n",
      "Predicted: 7.66, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 0.4900])\n",
      "Predicted: 1.72, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1500, 0.1300])\n",
      "Predicted: 3.92, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7500, 0.4000])\n",
      "Predicted: 15.40, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.1000])\n",
      "Predicted: 14.79, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.7900, 0.6900])\n",
      "Predicted: 7.95, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.6000, 0.3300])\n",
      "Predicted: 15.17, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.5600])\n",
      "Predicted: 5.46, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.7100, 0.3500])\n",
      "Predicted: 15.60, Actual: 19.00\n",
      "Average loss on the testing dataset: 6.1375\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.1900])\n",
      "Predicted: 15.90, Actual: 30.00\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.4900])\n",
      "Predicted: 3.27, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.3300])\n",
      "Predicted: 4.70, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.0500])\n",
      "Predicted: 10.03, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.2900])\n",
      "Predicted: 8.12, Actual: 29.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.5800])\n",
      "Predicted: 3.51, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4000, 0.8500])\n",
      "Predicted: 1.19, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6400, 0.1800])\n",
      "Predicted: 15.00, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.9200])\n",
      "Predicted: 0.93, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.7700])\n",
      "Predicted: 2.81, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.9900])\n",
      "Predicted: 3.52, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7200, 0.9800])\n",
      "Predicted: 1.55, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.5400])\n",
      "Predicted: 10.57, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6300, 0.7800])\n",
      "Predicted: 3.72, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.6400])\n",
      "Predicted: 12.91, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.4300])\n",
      "Predicted: 15.44, Actual: 3.00\n",
      "Average loss on the testing dataset: 6.1539\n",
      "tensor([1.0000, 0.0000, 0.2800, 0.1100])\n",
      "Predicted: 8.20, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.9700])\n",
      "Predicted: 0.85, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8300, 0.3600])\n",
      "Predicted: 15.22, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.5300, 0.8800])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.5600])\n",
      "Predicted: 9.58, Actual: 22.00\n",
      "tensor([0.0000, 1.0000, 0.2600, 0.9500])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3200, 0.1400])\n",
      "Predicted: 8.40, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.6400, 0.2200])\n",
      "Predicted: 15.39, Actual: 18.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.0700])\n",
      "Predicted: 14.72, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.7100])\n",
      "Predicted: 4.43, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2600, 0.3900])\n",
      "Predicted: 4.58, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.7700])\n",
      "Predicted: 8.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6100, 0.9900])\n",
      "Predicted: 1.02, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.0700])\n",
      "Predicted: 2.64, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0300, 0.1000])\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9500, 0.9200])\n",
      "Predicted: 4.47, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1577\n",
      "tensor([0.0000, 1.0000, 0.9400, 0.2200])\n",
      "Predicted: 15.75, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.9700])\n",
      "Predicted: 0.28, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5700, 0.5700])\n",
      "Predicted: 10.01, Actual: 19.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.3900])\n",
      "Predicted: 3.22, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4800, 0.0300])\n",
      "Predicted: 14.50, Actual: 27.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.0100])\n",
      "Predicted: 16.39, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.1600])\n",
      "Predicted: 15.95, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.9200])\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.6400])\n",
      "Predicted: 1.88, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9100, 0.8000])\n",
      "Predicted: 7.38, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4500, 0.4400])\n",
      "Predicted: 10.13, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.2800])\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9800, 0.7900])\n",
      "Predicted: 7.66, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0600, 0.0300])\n",
      "Predicted: 4.04, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.2300])\n",
      "Predicted: 15.07, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.9700, 0.2600])\n",
      "Predicted: 15.67, Actual: 24.00\n",
      "Average loss on the testing dataset: 6.1688\n",
      "tensor([1.0000, 0.0000, 0.5600, 0.6800])\n",
      "Predicted: 5.20, Actual: 28.00\n",
      "tensor([0.0000, 0.0000, 0.8400, 0.5300])\n",
      "Predicted: 14.72, Actual: 17.00\n",
      "tensor([1.0000, 0.0000, 0.8700, 0.5000])\n",
      "Predicted: 15.28, Actual: 15.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.5200])\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6200, 0.4400])\n",
      "Predicted: 14.69, Actual: 26.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.8100])\n",
      "Predicted: 3.76, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8500, 0.1200])\n",
      "Predicted: 16.02, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.6700])\n",
      "Predicted: 4.27, Actual: 28.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.3000])\n",
      "Predicted: 4.17, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.6600])\n",
      "Predicted: 3.86, Actual: 6.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.8700])\n",
      "Predicted: 1.75, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.8800])\n",
      "Predicted: 4.03, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.2900])\n",
      "Predicted: 15.62, Actual: 24.00\n",
      "tensor([1.0000, 1.0000, 0.2900, 0.8200])\n",
      "Predicted: 1.42, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.8300])\n",
      "Predicted: 1.49, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 1.0000])\n",
      "Predicted: 1.08, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.2005\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.4000])\n",
      "Predicted: 15.59, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.1600])\n",
      "Predicted: 4.06, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.5300])\n",
      "Predicted: 13.82, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.7800])\n",
      "Predicted: 5.60, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8000, 0.4600])\n",
      "Predicted: 14.94, Actual: 15.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.3000])\n",
      "Predicted: 4.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8500, 0.9500])\n",
      "Predicted: 2.80, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6300, 0.4700])\n",
      "Predicted: 13.88, Actual: 10.00\n",
      "tensor([1.0000, 0.0000, 0.1200, 0.8700])\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.6700])\n",
      "Predicted: 2.44, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.5600])\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1600, 0.0300])\n",
      "Predicted: 4.35, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0600, 0.0000])\n",
      "Predicted: 4.26, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1900, 0.9200])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 0.4100])\n",
      "Predicted: 1.81, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7600, 0.7100])\n",
      "Predicted: 8.26, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1632\n",
      "tensor([1.0000, 0.0000, 0.1900, 0.9400])\n",
      "Predicted: 0.35, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4000, 0.7400])\n",
      "Predicted: 2.73, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5700, 0.8000])\n",
      "Predicted: 3.39, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.4300])\n",
      "Predicted: 5.82, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.2000])\n",
      "Predicted: 7.58, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9100, 0.1100])\n",
      "Predicted: 15.82, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.7900, 0.0700])\n",
      "Predicted: 15.55, Actual: 24.00\n",
      "tensor([1.0000, 0.0000, 0.1500, 0.8000])\n",
      "Predicted: 0.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9200, 0.0200])\n",
      "Predicted: 16.23, Actual: 24.00\n",
      "tensor([0.0000, 1.0000, 0.1500, 0.2300])\n",
      "Predicted: 4.17, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4500, 0.7500])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.3100])\n",
      "Predicted: 1.56, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.5100])\n",
      "Predicted: 15.42, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.0600, 0.2400])\n",
      "Predicted: 2.55, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.3000])\n",
      "Predicted: 15.66, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.4900, 0.4400])\n",
      "Predicted: 11.59, Actual: 8.00\n",
      "Average loss on the testing dataset: 6.1434\n",
      "tensor([1.0000, 1.0000, 0.4000, 0.4800])\n",
      "Predicted: 8.17, Actual: 16.00\n",
      "tensor([0.0000, 1.0000, 0.8200, 0.9900])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.0600])\n",
      "Predicted: 2.74, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9400, 0.0200])\n",
      "Predicted: 15.86, Actual: 14.00\n",
      "tensor([1.0000, 1.0000, 0.9700, 0.3100])\n",
      "Predicted: 15.96, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.3400])\n",
      "Predicted: 4.93, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3600, 0.2800])\n",
      "Predicted: 9.47, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.3300])\n",
      "Predicted: 15.36, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.3400])\n",
      "Predicted: 3.95, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.8700])\n",
      "Predicted: 1.90, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4400, 0.8600])\n",
      "Predicted: 1.57, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9000, 0.8900])\n",
      "Predicted: 4.92, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2200, 0.4300])\n",
      "Predicted: 3.75, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1100, 0.1500])\n",
      "Predicted: 2.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9200, 0.6300])\n",
      "Predicted: 14.50, Actual: 18.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.7400])\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.1039\n",
      "tensor([1.0000, 1.0000, 0.9900, 0.9500])\n",
      "Predicted: 4.55, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5100, 0.9800])\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.4400, 0.8100])\n",
      "Predicted: 1.62, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3000, 0.4000])\n",
      "Predicted: 5.57, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.6000])\n",
      "Predicted: 2.10, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7600, 0.0800])\n",
      "Predicted: 15.79, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.4400, 0.1300])\n",
      "Predicted: 13.69, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.5200])\n",
      "Predicted: 9.98, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.4200, 0.9600])\n",
      "Predicted: 0.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2100, 0.9900])\n",
      "Predicted: 0.25, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.8200])\n",
      "Predicted: 0.39, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.6400])\n",
      "Predicted: 1.16, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1800, 0.6200])\n",
      "Predicted: 1.66, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.8600])\n",
      "Predicted: 2.59, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6600, 0.9600])\n",
      "Predicted: 1.44, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.7100])\n",
      "Predicted: 7.74, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0588\n",
      "tensor([1.0000, 1.0000, 0.4500, 1.0000])\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.9400])\n",
      "Predicted: 0.33, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.1400])\n",
      "Predicted: 11.03, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5500, 0.2200])\n",
      "Predicted: 15.06, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.7800])\n",
      "Predicted: 6.29, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.9600])\n",
      "Predicted: 1.81, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0700, 0.7700])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5900, 0.1300])\n",
      "Predicted: 14.84, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.3800, 0.4600])\n",
      "Predicted: 7.00, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.9800])\n",
      "Predicted: 2.82, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4900, 0.3700])\n",
      "Predicted: 13.70, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.7600])\n",
      "Predicted: 1.25, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4100, 0.9800])\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9600, 0.8100])\n",
      "Predicted: 6.43, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0500, 0.4500])\n",
      "Predicted: 1.44, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.4700])\n",
      "Predicted: 4.40, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0317\n",
      "tensor([1.0000, 1.0000, 0.5900, 0.7000])\n",
      "Predicted: 5.90, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.0300])\n",
      "Predicted: 16.02, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.8800, 0.1400])\n",
      "Predicted: 16.00, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.3200])\n",
      "Predicted: 2.34, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.1800])\n",
      "Predicted: 5.26, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5300, 0.5300])\n",
      "Predicted: 10.83, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.5500, 0.2800])\n",
      "Predicted: 15.06, Actual: 16.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.4000])\n",
      "Predicted: 15.15, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.5500, 0.2100])\n",
      "Predicted: 15.08, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.5600, 0.8700])\n",
      "Predicted: 1.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7000, 0.7100])\n",
      "Predicted: 5.98, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4500, 0.9500])\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.9000])\n",
      "Predicted: 2.48, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.5500])\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.8600])\n",
      "Predicted: 0.52, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1000, 0.1500])\n",
      "Predicted: 3.89, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0223\n",
      "tensor([1.0000, 0.0000, 0.4000, 0.1600])\n",
      "Predicted: 13.03, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.7200, 0.8800])\n",
      "Predicted: 2.79, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6300, 0.7200])\n",
      "Predicted: 5.89, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9500, 0.2900])\n",
      "Predicted: 15.54, Actual: 17.00\n",
      "tensor([0.0000, 1.0000, 0.0800, 0.7200])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2700, 0.6600])\n",
      "Predicted: 2.24, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6300, 0.7900])\n",
      "Predicted: 3.67, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3500, 0.9800])\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.9500])\n",
      "Predicted: 2.21, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.2100])\n",
      "Predicted: 2.50, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4300, 0.4400])\n",
      "Predicted: 9.44, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.6700, 0.3100])\n",
      "Predicted: 15.55, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.9800, 0.4000])\n",
      "Predicted: 15.27, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.7700, 0.2400])\n",
      "Predicted: 15.77, Actual: 10.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.1500])\n",
      "Predicted: 15.37, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.5100])\n",
      "Predicted: 3.06, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9905\n",
      "tensor([1.0000, 0.0000, 0.8400, 0.2500])\n",
      "Predicted: 15.80, Actual: 24.00\n",
      "tensor([1.0000, 0.0000, 0.9200, 0.3000])\n",
      "Predicted: 15.88, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7000, 0.1300])\n",
      "Predicted: 15.51, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.7800, 0.2600])\n",
      "Predicted: 15.79, Actual: 12.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.0800])\n",
      "Predicted: 15.51, Actual: 26.00\n",
      "tensor([1.0000, 0.0000, 0.2400, 0.9000])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5000, 0.8800])\n",
      "Predicted: 1.38, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.4300])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8700, 0.5300])\n",
      "Predicted: 14.80, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.9100, 0.0700])\n",
      "Predicted: 15.74, Actual: 22.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.9100])\n",
      "Predicted: 0.43, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5400, 0.5500])\n",
      "Predicted: 8.81, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.5000])\n",
      "Predicted: 1.87, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7200, 0.9400])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2100, 0.6200])\n",
      "Predicted: 1.98, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0900, 0.0100])\n",
      "Predicted: 4.91, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0002\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.0500])\n",
      "Predicted: 7.70, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6800, 0.0800])\n",
      "Predicted: 15.41, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.7800])\n",
      "Predicted: 7.71, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.5500, 0.5800])\n",
      "Predicted: 9.24, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.3600])\n",
      "Predicted: 8.33, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.3800, 0.2300])\n",
      "Predicted: 11.05, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.1300, 0.3000])\n",
      "Predicted: 2.76, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.9800])\n",
      "Predicted: 0.65, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.4700])\n",
      "Predicted: 2.77, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3600, 0.3900])\n",
      "Predicted: 7.91, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.8300, 0.6500])\n",
      "Predicted: 11.71, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.7500])\n",
      "Predicted: 7.39, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.3100])\n",
      "Predicted: 14.95, Actual: 15.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.3200])\n",
      "Predicted: 4.82, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6600, 0.2900])\n",
      "Predicted: 14.96, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.5400])\n",
      "Predicted: 15.23, Actual: 4.00\n",
      "Average loss on the testing dataset: 6.0007\n",
      "tensor([0.0000, 0.0000, 0.9300, 0.8100])\n",
      "Predicted: 6.25, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.2600])\n",
      "Predicted: 5.31, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9600, 0.5300])\n",
      "Predicted: 15.30, Actual: 8.00\n",
      "tensor([0.0000, 0.0000, 0.0700, 0.3900])\n",
      "Predicted: 1.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.4700])\n",
      "Predicted: 14.87, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.3900, 0.0600])\n",
      "Predicted: 14.20, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.2400, 0.1800])\n",
      "Predicted: 6.78, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3100, 0.9900])\n",
      "Predicted: 0.51, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9300, 0.2100])\n",
      "Predicted: 15.74, Actual: 6.00\n",
      "tensor([0.0000, 1.0000, 0.8900, 0.4900])\n",
      "Predicted: 14.92, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.5800, 0.2200])\n",
      "Predicted: 15.17, Actual: 6.00\n",
      "tensor([1.0000, 0.0000, 0.2200, 0.5900])\n",
      "Predicted: 2.29, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.4600])\n",
      "Predicted: 2.91, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9000, 0.6600])\n",
      "Predicted: 12.99, Actual: 30.00\n",
      "tensor([0.0000, 1.0000, 0.5900, 0.8000])\n",
      "Predicted: 3.21, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6200, 0.9500])\n",
      "Predicted: 1.71, Actual: 0.00\n",
      "Average loss on the testing dataset: 6.0061\n",
      "tensor([1.0000, 1.0000, 0.6600, 0.2800])\n",
      "Predicted: 15.51, Actual: 26.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.1200])\n",
      "Predicted: 14.79, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.2900])\n",
      "Predicted: 14.83, Actual: 1.00\n",
      "tensor([0.0000, 1.0000, 0.3800, 0.1500])\n",
      "Predicted: 12.41, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.1800, 0.6300])\n",
      "Predicted: 1.61, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0900, 0.7100])\n",
      "Predicted: 0.74, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.7400])\n",
      "Predicted: 0.58, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4800, 0.0800])\n",
      "Predicted: 14.63, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.3100, 0.7000])\n",
      "Predicted: 2.92, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7800, 0.3100])\n",
      "Predicted: 15.18, Actual: 14.00\n",
      "tensor([1.0000, 1.0000, 0.0200, 0.2500])\n",
      "Predicted: 1.43, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2900, 0.5600])\n",
      "Predicted: 3.70, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.4700])\n",
      "Predicted: 14.89, Actual: 9.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.9600])\n",
      "Predicted: 2.41, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.3800])\n",
      "Predicted: 15.72, Actual: 4.00\n",
      "tensor([0.0000, 1.0000, 0.6500, 0.0800])\n",
      "Predicted: 15.11, Actual: 2.00\n",
      "Average loss on the testing dataset: 6.0026\n",
      "tensor([1.0000, 1.0000, 0.8700, 0.5900])\n",
      "Predicted: 15.14, Actual: 2.00\n",
      "tensor([0.0000, 1.0000, 0.5200, 0.0400])\n",
      "Predicted: 14.73, Actual: 10.00\n",
      "tensor([1.0000, 1.0000, 0.6600, 0.9400])\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9900, 0.6300])\n",
      "Predicted: 15.06, Actual: 2.00\n",
      "tensor([0.0000, 1.0000, 0.0300, 0.4500])\n",
      "Predicted: 1.29, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7400, 0.4300])\n",
      "Predicted: 15.46, Actual: 20.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.0200])\n",
      "Predicted: 15.75, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.5500, 0.4900])\n",
      "Predicted: 11.66, Actual: 19.00\n",
      "tensor([1.0000, 1.0000, 0.6200, 0.4600])\n",
      "Predicted: 15.28, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.9100])\n",
      "Predicted: 3.36, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6100, 0.7400])\n",
      "Predicted: 4.50, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.7600])\n",
      "Predicted: 0.58, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.5500])\n",
      "Predicted: 6.96, Actual: 16.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.3500])\n",
      "Predicted: 15.37, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.1900, 0.0700])\n",
      "Predicted: 6.85, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9000, 0.9100])\n",
      "Predicted: 3.54, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9964\n",
      "tensor([0.0000, 1.0000, 0.0100, 0.3000])\n",
      "Predicted: 1.68, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9800, 0.1800])\n",
      "Predicted: 16.17, Actual: 3.00\n",
      "tensor([1.0000, 1.0000, 0.0500, 0.5900])\n",
      "Predicted: 0.96, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6000, 0.9100])\n",
      "Predicted: 2.02, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6400, 0.3200])\n",
      "Predicted: 14.88, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.2700, 0.1400])\n",
      "Predicted: 6.64, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.6600])\n",
      "Predicted: 1.82, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3000, 0.5700])\n",
      "Predicted: 3.49, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5000, 0.8500])\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9700, 0.5800])\n",
      "Predicted: 14.72, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.2000])\n",
      "Predicted: 14.96, Actual: 14.00\n",
      "tensor([0.0000, 1.0000, 0.7400, 0.1800])\n",
      "Predicted: 15.36, Actual: 15.00\n",
      "tensor([0.0000, 1.0000, 0.9800, 0.7600])\n",
      "Predicted: 8.27, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.0300])\n",
      "Predicted: 14.99, Actual: 2.00\n",
      "tensor([0.0000, 0.0000, 0.6100, 0.7800])\n",
      "Predicted: 3.29, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4600, 0.6200])\n",
      "Predicted: 5.35, Actual: 20.00\n",
      "Average loss on the testing dataset: 5.9956\n",
      "tensor([1.0000, 1.0000, 0.4100, 0.8500])\n",
      "Predicted: 1.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2600, 0.1100])\n",
      "Predicted: 8.71, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.2000, 0.3000])\n",
      "Predicted: 3.95, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6400, 0.4600])\n",
      "Predicted: 15.08, Actual: 14.00\n",
      "tensor([0.0000, 1.0000, 0.8100, 0.4300])\n",
      "Predicted: 15.02, Actual: 7.00\n",
      "tensor([1.0000, 1.0000, 0.9900, 0.0700])\n",
      "Predicted: 16.39, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.1400, 0.0000])\n",
      "Predicted: 4.59, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.9800, 0.5200])\n",
      "Predicted: 15.39, Actual: 21.00\n",
      "tensor([0.0000, 0.0000, 1.0000, 0.1200])\n",
      "Predicted: 15.87, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.4000])\n",
      "Predicted: 5.14, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0500, 0.2100])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7200, 0.7500])\n",
      "Predicted: 5.67, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8900, 0.3900])\n",
      "Predicted: 15.20, Actual: 14.00\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.3700])\n",
      "Predicted: 15.68, Actual: 18.00\n",
      "tensor([1.0000, 1.0000, 0.9600, 0.4600])\n",
      "Predicted: 15.54, Actual: 12.00\n",
      "tensor([1.0000, 0.0000, 0.6400, 0.7900])\n",
      "Predicted: 3.63, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9662\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.1300])\n",
      "Predicted: 11.25, Actual: 9.00\n",
      "tensor([0.0000, 1.0000, 0.8600, 0.9900])\n",
      "Predicted: 2.15, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3000, 0.4500])\n",
      "Predicted: 5.23, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2900, 0.6400])\n",
      "Predicted: 3.25, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9700, 0.7600])\n",
      "Predicted: 10.22, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.5700])\n",
      "Predicted: 15.24, Actual: 9.00\n",
      "tensor([1.0000, 1.0000, 0.4800, 0.1000])\n",
      "Predicted: 14.76, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.0400, 0.0100])\n",
      "Predicted: 3.62, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.4400])\n",
      "Predicted: 15.04, Actual: 25.00\n",
      "tensor([0.0000, 0.0000, 0.2000, 0.8200])\n",
      "Predicted: 0.69, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3400, 0.0900])\n",
      "Predicted: 9.69, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.4900, 0.2600])\n",
      "Predicted: 14.85, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.0500, 0.0300])\n",
      "Predicted: 3.63, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6200, 0.5800])\n",
      "Predicted: 9.79, Actual: 13.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.9900])\n",
      "Predicted: 3.53, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7300, 0.8500])\n",
      "Predicted: 3.41, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9422\n",
      "tensor([1.0000, 1.0000, 0.4400, 0.0600])\n",
      "Predicted: 14.51, Actual: 8.00\n",
      "tensor([0.0000, 1.0000, 0.5800, 0.2400])\n",
      "Predicted: 14.90, Actual: 27.00\n",
      "tensor([0.0000, 1.0000, 0.4600, 0.1900])\n",
      "Predicted: 14.58, Actual: 11.00\n",
      "tensor([0.0000, 0.0000, 0.8000, 0.8000])\n",
      "Predicted: 4.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7300, 0.8600])\n",
      "Predicted: 2.95, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.0000])\n",
      "Predicted: 9.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4500, 0.7900])\n",
      "Predicted: 2.61, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.8500, 0.0200])\n",
      "Predicted: 15.75, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.9800, 0.3400])\n",
      "Predicted: 15.84, Actual: 23.00\n",
      "tensor([1.0000, 0.0000, 0.6000, 1.0000])\n",
      "Predicted: 0.92, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0300, 0.4600])\n",
      "Predicted: 1.26, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7700, 0.8800])\n",
      "Predicted: 3.74, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2900, 0.6900])\n",
      "Predicted: 2.04, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3300, 0.3000])\n",
      "Predicted: 7.31, Actual: 12.00\n",
      "tensor([0.0000, 0.0000, 0.9900, 0.8400])\n",
      "Predicted: 6.20, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0000, 0.9000])\n",
      "Predicted: 0.28, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9286\n",
      "tensor([1.0000, 0.0000, 0.6800, 0.2000])\n",
      "Predicted: 15.50, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.1800, 0.4900])\n",
      "Predicted: 2.53, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3500, 0.3600])\n",
      "Predicted: 7.88, Actual: 14.00\n",
      "tensor([0.0000, 0.0000, 0.8900, 0.9600])\n",
      "Predicted: 2.58, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7800, 0.6300])\n",
      "Predicted: 10.13, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.3300, 0.8100])\n",
      "Predicted: 1.68, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.9600, 0.5500])\n",
      "Predicted: 14.80, Actual: 13.00\n",
      "tensor([1.0000, 0.0000, 0.3700, 0.7500])\n",
      "Predicted: 1.97, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1700, 0.9800])\n",
      "Predicted: 0.29, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1800, 0.2000])\n",
      "Predicted: 4.15, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7600, 0.4500])\n",
      "Predicted: 14.87, Actual: 10.00\n",
      "tensor([0.0000, 1.0000, 0.5800, 0.9000])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7900, 0.6900])\n",
      "Predicted: 9.55, Actual: 8.00\n",
      "tensor([1.0000, 1.0000, 0.7200, 0.3200])\n",
      "Predicted: 15.66, Actual: 8.00\n",
      "tensor([0.0000, 0.0000, 0.2600, 0.3800])\n",
      "Predicted: 4.61, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.0600, 0.7600])\n",
      "Predicted: 0.67, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9105\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.1000])\n",
      "Predicted: 14.88, Actual: 10.00\n",
      "tensor([1.0000, 0.0000, 0.4300, 0.0600])\n",
      "Predicted: 14.55, Actual: 11.00\n",
      "tensor([1.0000, 1.0000, 0.1100, 0.1800])\n",
      "Predicted: 2.67, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0900, 0.8100])\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.7100, 0.2400])\n",
      "Predicted: 15.25, Actual: 23.00\n",
      "tensor([1.0000, 1.0000, 0.0700, 0.6700])\n",
      "Predicted: 0.93, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6700, 0.1200])\n",
      "Predicted: 15.49, Actual: 7.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.6400])\n",
      "Predicted: 9.56, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.8500, 0.9900])\n",
      "Predicted: 1.96, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.6700, 0.0200])\n",
      "Predicted: 15.19, Actual: 25.00\n",
      "tensor([1.0000, 0.0000, 0.3900, 0.5500])\n",
      "Predicted: 6.08, Actual: 23.00\n",
      "tensor([0.0000, 1.0000, 0.7600, 0.5400])\n",
      "Predicted: 13.22, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.4500, 0.4300])\n",
      "Predicted: 10.72, Actual: 21.00\n",
      "tensor([0.0000, 1.0000, 0.8200, 0.8200])\n",
      "Predicted: 4.68, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.6500, 0.1400])\n",
      "Predicted: 15.35, Actual: 1.00\n",
      "tensor([1.0000, 0.0000, 0.1300, 0.5700])\n",
      "Predicted: 1.42, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9221\n",
      "tensor([0.0000, 0.0000, 0.1800, 0.3000])\n",
      "Predicted: 3.66, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6000, 0.1800])\n",
      "Predicted: 14.87, Actual: 23.00\n",
      "tensor([0.0000, 0.0000, 0.9300, 0.8500])\n",
      "Predicted: 5.13, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5500, 0.2700])\n",
      "Predicted: 14.69, Actual: 29.00\n",
      "tensor([0.0000, 1.0000, 0.6700, 0.5900])\n",
      "Predicted: 9.71, Actual: 12.00\n",
      "tensor([1.0000, 1.0000, 0.7100, 0.0300])\n",
      "Predicted: 15.49, Actual: 13.00\n",
      "tensor([0.0000, 0.0000, 0.2900, 0.2500])\n",
      "Predicted: 7.35, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8900, 0.9100])\n",
      "Predicted: 4.34, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3500, 0.9500])\n",
      "Predicted: 0.54, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0500, 0.2100])\n",
      "Predicted: 1.84, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4200, 0.2300])\n",
      "Predicted: 11.62, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.2500])\n",
      "Predicted: 15.38, Actual: 13.00\n",
      "tensor([0.0000, 0.0000, 0.5200, 0.0400])\n",
      "Predicted: 14.63, Actual: 17.00\n",
      "tensor([0.0000, 0.0000, 0.9000, 0.0400])\n",
      "Predicted: 15.75, Actual: 6.00\n",
      "tensor([0.0000, 0.0000, 0.3300, 0.0500])\n",
      "Predicted: 12.88, Actual: 18.00\n",
      "tensor([0.0000, 1.0000, 0.1600, 0.0200])\n",
      "Predicted: 6.89, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9086\n",
      "tensor([1.0000, 0.0000, 0.8600, 0.9200])\n",
      "Predicted: 3.42, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.9300, 0.8500])\n",
      "Predicted: 6.09, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.2800, 0.5100])\n",
      "Predicted: 4.27, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.0500, 0.2500])\n",
      "Predicted: 2.36, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2800, 0.9500])\n",
      "Predicted: 0.40, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1800, 0.4200])\n",
      "Predicted: 2.84, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3500, 0.8300])\n",
      "Predicted: 1.14, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5700, 0.2800])\n",
      "Predicted: 14.75, Actual: 4.00\n",
      "tensor([1.0000, 0.0000, 0.5200, 0.3800])\n",
      "Predicted: 14.69, Actual: 8.00\n",
      "tensor([0.0000, 0.0000, 0.6300, 0.7600])\n",
      "Predicted: 3.91, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.1800])\n",
      "Predicted: 15.94, Actual: 11.00\n",
      "tensor([1.0000, 0.0000, 0.3800, 0.5100])\n",
      "Predicted: 6.73, Actual: 4.00\n",
      "tensor([0.0000, 0.0000, 0.9500, 0.1300])\n",
      "Predicted: 15.75, Actual: 25.00\n",
      "tensor([1.0000, 1.0000, 0.3800, 0.0300])\n",
      "Predicted: 12.07, Actual: 25.00\n",
      "tensor([0.0000, 1.0000, 0.7800, 0.3300])\n",
      "Predicted: 15.25, Actual: 3.00\n",
      "tensor([0.0000, 1.0000, 0.0900, 0.1700])\n",
      "Predicted: 3.53, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9003\n",
      "tensor([0.0000, 1.0000, 0.2700, 0.1400])\n",
      "Predicted: 8.65, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7300, 0.3900])\n",
      "Predicted: 15.55, Actual: 10.00\n",
      "tensor([0.0000, 0.0000, 0.8400, 0.2200])\n",
      "Predicted: 15.42, Actual: 15.00\n",
      "tensor([1.0000, 1.0000, 0.8600, 0.3100])\n",
      "Predicted: 15.84, Actual: 3.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.3900])\n",
      "Predicted: 15.52, Actual: 2.00\n",
      "tensor([1.0000, 1.0000, 0.0800, 0.1500])\n",
      "Predicted: 2.35, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6800, 0.7800])\n",
      "Predicted: 4.00, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.0400, 0.5400])\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1200, 0.9100])\n",
      "Predicted: 0.48, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2000, 0.2000])\n",
      "Predicted: 5.68, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.3500, 0.2100])\n",
      "Predicted: 8.88, Actual: 29.00\n",
      "tensor([1.0000, 1.0000, 0.8500, 0.9900])\n",
      "Predicted: 2.56, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.8100, 0.8400])\n",
      "Predicted: 4.03, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.1400, 0.5100])\n",
      "Predicted: 1.63, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2600, 0.0000])\n",
      "Predicted: 10.88, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.2300, 0.4000])\n",
      "Predicted: 4.22, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.9131\n",
      "tensor([0.0000, 1.0000, 0.7700, 0.5900])\n",
      "Predicted: 11.34, Actual: 20.00\n",
      "tensor([1.0000, 1.0000, 0.8000, 0.4800])\n",
      "Predicted: 15.38, Actual: 1.00\n",
      "tensor([1.0000, 1.0000, 0.1400, 0.8100])\n",
      "Predicted: 0.86, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.0100, 0.8300])\n",
      "Predicted: 0.30, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.5400, 0.9700])\n",
      "Predicted: 1.11, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.4100, 0.7200])\n",
      "Predicted: 3.12, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.3400, 0.9400])\n",
      "Predicted: 0.56, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.5000, 0.7700])\n",
      "Predicted: 2.64, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4200, 0.0400])\n",
      "Predicted: 13.80, Actual: 19.00\n",
      "tensor([0.0000, 1.0000, 0.6300, 0.7800])\n",
      "Predicted: 3.86, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.4000, 0.8400])\n",
      "Predicted: 1.73, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.3900])\n",
      "Predicted: 15.52, Actual: 20.00\n",
      "tensor([0.0000, 1.0000, 0.3700, 0.9400])\n",
      "Predicted: 0.81, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6700, 0.0100])\n",
      "Predicted: 15.12, Actual: 8.00\n",
      "tensor([1.0000, 0.0000, 0.8900, 0.5500])\n",
      "Predicted: 15.16, Actual: 16.00\n",
      "tensor([1.0000, 0.0000, 0.2500, 0.4100])\n",
      "Predicted: 4.29, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.8896\n",
      "tensor([1.0000, 1.0000, 0.8300, 0.8600])\n",
      "Predicted: 4.81, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.6100, 0.3000])\n",
      "Predicted: 14.84, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.3400, 0.7100])\n",
      "Predicted: 2.12, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.7700, 0.3300])\n",
      "Predicted: 15.57, Actual: 27.00\n",
      "tensor([1.0000, 0.0000, 0.8200, 0.5000])\n",
      "Predicted: 15.21, Actual: 13.00\n",
      "tensor([1.0000, 0.0000, 0.4200, 0.4700])\n",
      "Predicted: 8.86, Actual: 21.00\n",
      "tensor([1.0000, 0.0000, 0.3100, 0.0300])\n",
      "Predicted: 10.50, Actual: 24.00\n",
      "tensor([1.0000, 0.0000, 0.7900, 0.4300])\n",
      "Predicted: 15.37, Actual: 15.00\n",
      "tensor([0.0000, 0.0000, 0.8700, 0.8800])\n",
      "Predicted: 3.79, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.8500, 0.0100])\n",
      "Predicted: 15.99, Actual: 5.00\n",
      "tensor([0.0000, 0.0000, 0.3100, 0.8100])\n",
      "Predicted: 1.06, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.9500, 0.1200])\n",
      "Predicted: 15.89, Actual: 5.00\n",
      "tensor([0.0000, 1.0000, 0.4200, 0.8600])\n",
      "Predicted: 1.48, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.2300, 0.9900])\n",
      "Predicted: 0.27, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.4700, 0.9700])\n",
      "Predicted: 0.72, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.1700])\n",
      "Predicted: 16.22, Actual: 22.00\n",
      "Average loss on the testing dataset: 5.8984\n",
      "tensor([1.0000, 1.0000, 0.2200, 0.5900])\n",
      "Predicted: 2.64, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.5800, 0.2400])\n",
      "Predicted: 14.79, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.6400, 0.9100])\n",
      "Predicted: 1.82, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.3400, 0.2100])\n",
      "Predicted: 9.94, Actual: 17.00\n",
      "tensor([1.0000, 1.0000, 0.3700, 0.2000])\n",
      "Predicted: 9.79, Actual: 1.00\n",
      "tensor([0.0000, 0.0000, 0.7900, 0.5300])\n",
      "Predicted: 14.67, Actual: 10.00\n",
      "tensor([0.0000, 1.0000, 0.6300, 0.4100])\n",
      "Predicted: 14.95, Actual: 22.00\n",
      "tensor([1.0000, 1.0000, 0.1200, 0.2400])\n",
      "Predicted: 2.60, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.1000, 0.2600])\n",
      "Predicted: 2.25, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 0.1400, 0.1000])\n",
      "Predicted: 3.89, Actual: 0.00\n",
      "tensor([1.0000, 1.0000, 0.7400, 0.0100])\n",
      "Predicted: 15.59, Actual: 15.00\n",
      "tensor([0.0000, 0.0000, 0.1000, 0.2700])\n",
      "Predicted: 2.52, Actual: 0.00\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.9400])\n",
      "Predicted: 4.65, Actual: 0.00\n",
      "tensor([0.0000, 0.0000, 0.7600, 0.0400])\n",
      "Predicted: 15.41, Actual: 9.00\n",
      "tensor([0.0000, 0.0000, 0.8300, 0.7100])\n",
      "Predicted: 7.97, Actual: 0.00\n",
      "tensor([0.0000, 1.0000, 0.1800, 0.3700])\n",
      "Predicted: 3.51, Actual: 0.00\n",
      "Average loss on the testing dataset: 5.8845\n"
     ]
    }
   ],
   "source": [
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    # Iterate through the testing data loader\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        for idx, test_inputs in enumerate(inputs):\n",
    "            print(test_inputs)\n",
    "            outputs = model1(test_inputs)\n",
    "            # Optionally calculate the loss (if you want to evaluate performance)\n",
    "            loss = loss_fn(outputs.squeeze(), targets[idx])\n",
    "            \n",
    "            # Accumulate the loss\n",
    "            total_loss += loss.item()\n",
    "            num_samples += 1\n",
    "            \n",
    "            # Print the predictions and the actual targets\n",
    "            print(f\"Predicted: {outputs.item()*30:.2f}, Actual: {targets[idx].item()*30:.2f}\")\n",
    "    \n",
    "    # Calculate the average loss\n",
    "        avg_loss = total_loss / num_samples\n",
    "        print(f\"Average loss on the testing dataset: {avg_loss*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218a6971-e14c-4b3b-ae7f-724bba84956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1, \"model/model2TopBotomData10000-25.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f335c7-12f0-4dfc-a88d-b0b310b912d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.0000, 0.9000, 0.2000])\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test1 = torch.tensor([1,0,90/100,20/100])\n",
    "print(test1)\n",
    "outputs = model1(test1)\n",
    "print(int(outputs.item()*30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
